module.exports = [
"[project]/node_modules/@langchain/langgraph/dist/setup/async_local_storage.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.initializeAsyncLocalStorageSingleton = initializeAsyncLocalStorageSingleton;
const singletons_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/singletons.cjs [app-route] (ecmascript)");
const node_async_hooks_1 = __turbopack_context__.r("[externals]/node:async_hooks [external] (node:async_hooks, cjs)");
function initializeAsyncLocalStorageSingleton() {
    singletons_1.AsyncLocalStorageProviderSingleton.initializeGlobalInstance(new node_async_hooks_1.AsyncLocalStorage());
} //# sourceMappingURL=async_local_storage.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getSubgraphsSeenSet = exports.RemoteException = exports.UnreachableNodeError = exports.MultipleSubgraphsError = exports.InvalidUpdateError = exports.EmptyChannelError = exports.EmptyInputError = exports.ParentCommand = exports.NodeInterrupt = exports.GraphInterrupt = exports.GraphValueError = exports.GraphRecursionError = exports.GraphBubbleUp = exports.BaseLangGraphError = void 0;
exports.isParentCommand = isParentCommand;
exports.isGraphBubbleUp = isGraphBubbleUp;
exports.isGraphInterrupt = isGraphInterrupt;
// TODO: Merge with base LangChain error class when we drop support for core@0.2.0
class BaseLangGraphError extends Error {
    constructor(message, fields){
        let finalMessage = message ?? "";
        if (fields?.lc_error_code) {
            finalMessage = `${finalMessage}\n\nTroubleshooting URL: https://langchain-ai.github.io/langgraphjs/troubleshooting/errors/${fields.lc_error_code}/\n`;
        }
        super(finalMessage);
        Object.defineProperty(this, "lc_error_code", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.lc_error_code = fields?.lc_error_code;
    }
}
exports.BaseLangGraphError = BaseLangGraphError;
class GraphBubbleUp extends BaseLangGraphError {
    get is_bubble_up() {
        return true;
    }
}
exports.GraphBubbleUp = GraphBubbleUp;
class GraphRecursionError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "GraphRecursionError";
    }
    static get unminifiable_name() {
        return "GraphRecursionError";
    }
}
exports.GraphRecursionError = GraphRecursionError;
class GraphValueError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "GraphValueError";
    }
    static get unminifiable_name() {
        return "GraphValueError";
    }
}
exports.GraphValueError = GraphValueError;
class GraphInterrupt extends GraphBubbleUp {
    constructor(interrupts, fields){
        super(JSON.stringify(interrupts, null, 2), fields);
        Object.defineProperty(this, "interrupts", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.name = "GraphInterrupt";
        this.interrupts = interrupts ?? [];
    }
    static get unminifiable_name() {
        return "GraphInterrupt";
    }
}
exports.GraphInterrupt = GraphInterrupt;
/** Raised by a node to interrupt execution. */ class NodeInterrupt extends GraphInterrupt {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    constructor(message, fields){
        super([
            {
                value: message
            }
        ], fields);
        this.name = "NodeInterrupt";
    }
    static get unminifiable_name() {
        return "NodeInterrupt";
    }
}
exports.NodeInterrupt = NodeInterrupt;
class ParentCommand extends GraphBubbleUp {
    constructor(command){
        super();
        Object.defineProperty(this, "command", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.name = "ParentCommand";
        this.command = command;
    }
    static get unminifiable_name() {
        return "ParentCommand";
    }
}
exports.ParentCommand = ParentCommand;
function isParentCommand(e) {
    return e !== undefined && e.name === ParentCommand.unminifiable_name;
}
function isGraphBubbleUp(e) {
    return e !== undefined && e.is_bubble_up === true;
}
function isGraphInterrupt(e) {
    return e !== undefined && [
        GraphInterrupt.unminifiable_name,
        NodeInterrupt.unminifiable_name
    ].includes(e.name);
}
class EmptyInputError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "EmptyInputError";
    }
    static get unminifiable_name() {
        return "EmptyInputError";
    }
}
exports.EmptyInputError = EmptyInputError;
class EmptyChannelError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "EmptyChannelError";
    }
    static get unminifiable_name() {
        return "EmptyChannelError";
    }
}
exports.EmptyChannelError = EmptyChannelError;
class InvalidUpdateError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "InvalidUpdateError";
    }
    static get unminifiable_name() {
        return "InvalidUpdateError";
    }
}
exports.InvalidUpdateError = InvalidUpdateError;
/**
 * @deprecated This exception type is no longer thrown.
 */ class MultipleSubgraphsError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "MultipleSubgraphError";
    }
    static get unminifiable_name() {
        return "MultipleSubgraphError";
    }
}
exports.MultipleSubgraphsError = MultipleSubgraphsError;
class UnreachableNodeError extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "UnreachableNodeError";
    }
    static get unminifiable_name() {
        return "UnreachableNodeError";
    }
}
exports.UnreachableNodeError = UnreachableNodeError;
/**
 * Exception raised when an error occurs in the remote graph.
 */ class RemoteException extends BaseLangGraphError {
    constructor(message, fields){
        super(message, fields);
        this.name = "RemoteException";
    }
    static get unminifiable_name() {
        return "RemoteException";
    }
}
exports.RemoteException = RemoteException;
/**
 * Used for subgraph detection.
 */ const getSubgraphsSeenSet = ()=>{
    if (// eslint-disable-next-line @typescript-eslint/no-explicit-any
    globalThis[Symbol.for("LG_CHECKPOINT_SEEN_NS_SET")] === undefined) {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        globalThis[Symbol.for("LG_CHECKPOINT_SEEN_NS_SET")] = new Set();
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    return globalThis[Symbol.for("LG_CHECKPOINT_SEEN_NS_SET")];
};
exports.getSubgraphsSeenSet = getSubgraphsSeenSet; //# sourceMappingURL=errors.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.BaseChannel = void 0;
exports.isBaseChannel = isBaseChannel;
exports.getOnlyChannels = getOnlyChannels;
exports.emptyChannels = emptyChannels;
exports.createCheckpoint = createCheckpoint;
const langgraph_checkpoint_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph-checkpoint/index.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
function isBaseChannel(obj) {
    return obj != null && obj.lg_is_channel === true;
}
class BaseChannel {
    constructor(){
        Object.defineProperty(this, "ValueType", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "UpdateType", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @ignore */ Object.defineProperty(this, "lg_is_channel", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
    }
    /**
     * Mark the current value of the channel as consumed. By default, no-op.
     * A channel can use this method to modify its state, preventing the value
     * from being consumed again.
     *
     * Returns True if the channel was updated, False otherwise.
     */ consume() {
        return false;
    }
    /**
     * Notify the channel that the Pregel run is finishing. By default, no-op.
     * A channel can use this method to modify its state, preventing finish.
     *
     * Returns True if the channel was updated, False otherwise.
     */ finish() {
        return false;
    }
    /**
     * Return True if the channel is available (not empty), False otherwise.
     * Subclasses should override this method to provide a more efficient
     * implementation than calling get() and catching EmptyChannelError.
     */ isAvailable() {
        try {
            this.get();
            return true;
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        } catch (error) {
            if (error.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                return false;
            }
            throw error;
        }
    }
}
exports.BaseChannel = BaseChannel;
const IS_ONLY_BASE_CHANNEL = Symbol.for("LG_IS_ONLY_BASE_CHANNEL");
function getOnlyChannels(channels) {
    // @ts-expect-error - we know it's a record of base channels
    if (channels[IS_ONLY_BASE_CHANNEL] === true) return channels;
    const newChannels = {};
    for(const k in channels){
        if (!Object.prototype.hasOwnProperty.call(channels, k)) continue;
        const value = channels[k];
        if (isBaseChannel(value)) newChannels[k] = value;
    }
    Object.assign(newChannels, {
        [IS_ONLY_BASE_CHANNEL]: true
    });
    return newChannels;
}
function emptyChannels(channels, checkpoint) {
    const filteredChannels = getOnlyChannels(channels);
    const newChannels = {};
    for(const k in filteredChannels){
        if (!Object.prototype.hasOwnProperty.call(filteredChannels, k)) continue;
        const channelValue = checkpoint.channel_values[k];
        newChannels[k] = filteredChannels[k].fromCheckpoint(channelValue);
    }
    Object.assign(newChannels, {
        [IS_ONLY_BASE_CHANNEL]: true
    });
    return newChannels;
}
function createCheckpoint(checkpoint, channels, step, options) {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    let values;
    if (channels === undefined) {
        values = checkpoint.channel_values;
    } else {
        values = {};
        for(const k in channels){
            if (!Object.prototype.hasOwnProperty.call(channels, k)) continue;
            try {
                values[k] = channels[k].checkpoint();
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            } catch (error) {
                if (error.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                // no-op
                } else {
                    throw error; // Rethrow unexpected errors
                }
            }
        }
    }
    const newVersionsSeen = {};
    for(const k in checkpoint.versions_seen){
        if (!Object.prototype.hasOwnProperty.call(checkpoint.versions_seen, k)) continue;
        newVersionsSeen[k] = {
            ...checkpoint.versions_seen[k]
        };
    }
    return {
        v: 4,
        id: options?.id ?? (0, langgraph_checkpoint_1.uuid6)(step),
        ts: new Date().toISOString(),
        channel_values: values,
        channel_versions: {
            ...checkpoint.channel_versions
        },
        versions_seen: newVersionsSeen
    };
} //# sourceMappingURL=base.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/binop.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.BinaryOperatorAggregate = void 0;
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
/**
 * Stores the result of applying a binary operator to the current value and each new value.
 */ class BinaryOperatorAggregate extends base_js_1.BaseChannel {
    constructor(operator, initialValueFactory){
        super();
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "BinaryOperatorAggregate"
        });
        Object.defineProperty(this, "value", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "operator", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "initialValueFactory", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.operator = operator;
        this.initialValueFactory = initialValueFactory;
        this.value = initialValueFactory?.();
    }
    fromCheckpoint(checkpoint) {
        const empty = new BinaryOperatorAggregate(this.operator, this.initialValueFactory);
        if (typeof checkpoint !== "undefined") {
            empty.value = checkpoint;
        }
        return empty;
    }
    update(values) {
        let newValues = values;
        if (!newValues.length) return false;
        if (this.value === undefined) {
            [this.value] = newValues;
            newValues = newValues.slice(1);
        }
        for (const value of newValues){
            if (this.value !== undefined) {
                this.value = this.operator(this.value, value);
            }
        }
        return true;
    }
    get() {
        if (this.value === undefined) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value;
    }
    checkpoint() {
        if (this.value === undefined) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value;
    }
    isAvailable() {
        return this.value !== undefined;
    }
}
exports.BinaryOperatorAggregate = BinaryOperatorAggregate; //# sourceMappingURL=binop.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/last_value.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.LastValueAfterFinish = exports.LastValue = void 0;
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
/**
 * Stores the last value received, can receive at most one value per step.
 *
 * Since `update` is only called once per step and value can only be of length 1,
 * LastValue always stores the last value of a single node. If multiple nodes attempt to
 * write to this channel in a single step, an error will be thrown.
 * @internal
 */ class LastValue extends base_js_1.BaseChannel {
    constructor(){
        super(...arguments);
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "LastValue"
        });
        // value is an array so we don't misinterpret an update to undefined as no write
        Object.defineProperty(this, "value", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
    }
    fromCheckpoint(checkpoint) {
        const empty = new LastValue();
        if (typeof checkpoint !== "undefined") {
            empty.value = [
                checkpoint
            ];
        }
        return empty;
    }
    update(values) {
        if (values.length === 0) {
            return false;
        }
        if (values.length !== 1) {
            throw new errors_js_1.InvalidUpdateError("LastValue can only receive one value per step.", {
                lc_error_code: "INVALID_CONCURRENT_GRAPH_UPDATE"
            });
        }
        // eslint-disable-next-line prefer-destructuring
        this.value = [
            values[values.length - 1]
        ];
        return true;
    }
    get() {
        if (this.value.length === 0) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value[0];
    }
    checkpoint() {
        if (this.value.length === 0) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value[0];
    }
    isAvailable() {
        return this.value.length !== 0;
    }
}
exports.LastValue = LastValue;
/**
 * Stores the last value received, but only made available after finish().
 * Once made available, clears the value.
 * @internal
 */ class LastValueAfterFinish extends base_js_1.BaseChannel {
    constructor(){
        super(...arguments);
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "LastValueAfterFinish"
        });
        // value is an array so we don't misinterpret an update to undefined as no write
        Object.defineProperty(this, "value", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "finished", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
    }
    fromCheckpoint(checkpoint) {
        const empty = new LastValueAfterFinish();
        if (typeof checkpoint !== "undefined") {
            const [value, finished] = checkpoint;
            empty.value = [
                value
            ];
            empty.finished = finished;
        }
        return empty;
    }
    update(values) {
        if (values.length === 0) {
            return false;
        }
        this.finished = false;
        // eslint-disable-next-line prefer-destructuring
        this.value = [
            values[values.length - 1]
        ];
        return true;
    }
    get() {
        if (this.value.length === 0 || !this.finished) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value[0];
    }
    checkpoint() {
        if (this.value.length === 0) return undefined;
        return [
            this.value[0],
            this.finished
        ];
    }
    consume() {
        if (this.finished) {
            this.finished = false;
            this.value = [];
            return true;
        }
        return false;
    }
    finish() {
        if (!this.finished && this.value.length > 0) {
            this.finished = true;
            return true;
        }
        return false;
    }
    isAvailable() {
        return this.value.length !== 0 && this.finished;
    }
}
exports.LastValueAfterFinish = LastValueAfterFinish; //# sourceMappingURL=last_value.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/annotation.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Annotation = exports.AnnotationRoot = void 0;
exports.getChannel = getChannel;
const binop_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/binop.cjs [app-route] (ecmascript)");
const last_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/last_value.cjs [app-route] (ecmascript)");
/**
 * Should not be instantiated directly. See {@link Annotation}.
 */ class AnnotationRoot {
    constructor(s){
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "AnnotationRoot"
        });
        Object.defineProperty(this, "spec", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.spec = s;
    }
}
exports.AnnotationRoot = AnnotationRoot;
/**
 * Helper that instantiates channels within a StateGraph state.
 *
 * Can be used as a field in an {@link Annotation.Root} wrapper in one of two ways:
 * 1. **Directly**: Creates a channel that stores the most recent value returned from a node.
 * 2. **With a reducer**: Creates a channel that applies the reducer on a node's return value.
 *
 * @example
 * ```ts
 * import { StateGraph, Annotation } from "@langchain/langgraph";
 *
 * // Define a state with a single string key named "currentOutput"
 * const SimpleAnnotation = Annotation.Root({
 *   currentOutput: Annotation<string>,
 * });
 *
 * const graphBuilder = new StateGraph(SimpleAnnotation);
 *
 * // A node in the graph that returns an object with a "currentOutput" key
 * // replaces the value in the state. You can get the state type as shown below:
 * const myNode = (state: typeof SimpleAnnotation.State) => {
 *   return {
 *     currentOutput: "some_new_value",
 *   };
 * }
 *
 * const graph = graphBuilder
 *   .addNode("myNode", myNode)
 *   ...
 *   .compile();
 * ```
 *
 * @example
 * ```ts
 * import { type BaseMessage, AIMessage } from "@langchain/core/messages";
 * import { StateGraph, Annotation } from "@langchain/langgraph";
 *
 * // Define a state with a single key named "messages" that will
 * // combine a returned BaseMessage or arrays of BaseMessages
 * const AnnotationWithReducer = Annotation.Root({
 *   messages: Annotation<BaseMessage[]>({
 *     // Different types are allowed for updates
 *     reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {
 *       if (Array.isArray(right)) {
 *         return left.concat(right);
 *       }
 *       return left.concat([right]);
 *     },
 *     default: () => [],
 *   }),
 * });
 *
 * const graphBuilder = new StateGraph(AnnotationWithReducer);
 *
 * // A node in the graph that returns an object with a "messages" key
 * // will update the state by combining the existing value with the returned one.
 * const myNode = (state: typeof AnnotationWithReducer.State) => {
 *   return {
 *     messages: [new AIMessage("Some new response")],
 *   };
 * };
 *
 * const graph = graphBuilder
 *   .addNode("myNode", myNode)
 *   ...
 *   .compile();
 * ```
 * @namespace
 * @property Root
 * Helper function that instantiates a StateGraph state. See {@link Annotation} for usage.
 */ exports.Annotation = function(annotation) {
    if (annotation) {
        return getChannel(annotation);
    } else {
        // @ts-expect-error - Annotation without reducer
        return new last_value_js_1.LastValue();
    }
};
exports.Annotation.Root = (sd)=>new AnnotationRoot(sd);
function getChannel(reducer) {
    if (typeof reducer === "object" && reducer && "reducer" in reducer && reducer.reducer) {
        return new binop_js_1.BinaryOperatorAggregate(reducer.reducer, reducer.default);
    }
    if (typeof reducer === "object" && reducer && "value" in reducer && reducer.value) {
        return new binop_js_1.BinaryOperatorAggregate(reducer.value, reducer.default);
    }
    // @ts-expect-error - Annotation without reducer
    return new last_value_js_1.LastValue();
} //# sourceMappingURL=annotation.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

var _a;
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Command = exports.Send = exports.CommandInstance = exports.CHECKPOINT_NAMESPACE_END = exports.CHECKPOINT_NAMESPACE_SEPARATOR = exports.RESERVED = exports.NULL_TASK_ID = exports.TASK_NAMESPACE = exports.PULL = exports.PUSH = exports.TASKS = exports.SELF = exports.TAG_NOSTREAM = exports.TAG_HIDDEN = exports.RECURSION_LIMIT_DEFAULT = exports.RUNTIME_PLACEHOLDER = exports.PREVIOUS = exports.RETURN = exports.NO_WRITES = exports.RESUME = exports.INTERRUPT = exports.CONFIG_KEY_ABORT_SIGNALS = exports.CONFIG_KEY_CHECKPOINT_MAP = exports.CONFIG_KEY_NODE_FINISHED = exports.CONFIG_KEY_CHECKPOINT_NS = exports.CONFIG_KEY_CHECKPOINT_ID = exports.CONFIG_KEY_DURABILITY = exports.CONFIG_KEY_PREVIOUS_STATE = exports.CONFIG_KEY_SCRATCHPAD = exports.CONFIG_KEY_RESUME_MAP = exports.CONFIG_KEY_RESUME_VALUE = exports.CONFIG_KEY_STREAM = exports.CONFIG_KEY_TASK_ID = exports.CONFIG_KEY_RESUMING = exports.CONFIG_KEY_CHECKPOINTER = exports.CONFIG_KEY_READ = exports.CONFIG_KEY_CALL = exports.CONFIG_KEY_SEND = exports.CACHE_NS_WRITES = exports.ERROR = exports.COPY = exports.INPUT = exports.END = exports.START = void 0;
exports._isSendInterface = _isSendInterface;
exports._isSend = _isSend;
exports.isInterrupted = isInterrupted;
exports.isCommand = isCommand;
exports._deserializeCommandSendObjectGraph = _deserializeCommandSendObjectGraph;
/** Special reserved node name denoting the start of a graph. */ exports.START = "__start__";
/** Special reserved node name denoting the end of a graph. */ exports.END = "__end__";
exports.INPUT = "__input__";
exports.COPY = "__copy__";
exports.ERROR = "__error__";
/** Special reserved cache namespaces */ exports.CACHE_NS_WRITES = "__pregel_ns_writes";
exports.CONFIG_KEY_SEND = "__pregel_send";
/** config key containing function used to call a node (push task) */ exports.CONFIG_KEY_CALL = "__pregel_call";
exports.CONFIG_KEY_READ = "__pregel_read";
exports.CONFIG_KEY_CHECKPOINTER = "__pregel_checkpointer";
exports.CONFIG_KEY_RESUMING = "__pregel_resuming";
exports.CONFIG_KEY_TASK_ID = "__pregel_task_id";
exports.CONFIG_KEY_STREAM = "__pregel_stream";
exports.CONFIG_KEY_RESUME_VALUE = "__pregel_resume_value";
exports.CONFIG_KEY_RESUME_MAP = "__pregel_resume_map";
exports.CONFIG_KEY_SCRATCHPAD = "__pregel_scratchpad";
/** config key containing state from previous invocation of graph for the given thread */ exports.CONFIG_KEY_PREVIOUS_STATE = "__pregel_previous";
exports.CONFIG_KEY_DURABILITY = "__pregel_durability";
exports.CONFIG_KEY_CHECKPOINT_ID = "checkpoint_id";
exports.CONFIG_KEY_CHECKPOINT_NS = "checkpoint_ns";
exports.CONFIG_KEY_NODE_FINISHED = "__pregel_node_finished";
// this one is part of public API
exports.CONFIG_KEY_CHECKPOINT_MAP = "checkpoint_map";
exports.CONFIG_KEY_ABORT_SIGNALS = "__pregel_abort_signals";
/** Special channel reserved for graph interrupts */ exports.INTERRUPT = "__interrupt__";
/** Special channel reserved for graph resume */ exports.RESUME = "__resume__";
/** Special channel reserved for cases when a task exits without any writes */ exports.NO_WRITES = "__no_writes__";
/** Special channel reserved for graph return */ exports.RETURN = "__return__";
/** Special channel reserved for graph previous state */ exports.PREVIOUS = "__previous__";
exports.RUNTIME_PLACEHOLDER = "__pregel_runtime_placeholder__";
exports.RECURSION_LIMIT_DEFAULT = 25;
exports.TAG_HIDDEN = "langsmith:hidden";
exports.TAG_NOSTREAM = "langsmith:nostream";
exports.SELF = "__self__";
exports.TASKS = "__pregel_tasks";
exports.PUSH = "__pregel_push";
exports.PULL = "__pregel_pull";
exports.TASK_NAMESPACE = "6ba7b831-9dad-11d1-80b4-00c04fd430c8";
exports.NULL_TASK_ID = "00000000-0000-0000-0000-000000000000";
exports.RESERVED = [
    exports.TAG_HIDDEN,
    exports.INPUT,
    exports.INTERRUPT,
    exports.RESUME,
    exports.ERROR,
    exports.NO_WRITES,
    // reserved config.configurable keys
    exports.CONFIG_KEY_SEND,
    exports.CONFIG_KEY_READ,
    exports.CONFIG_KEY_CHECKPOINTER,
    exports.CONFIG_KEY_DURABILITY,
    exports.CONFIG_KEY_STREAM,
    exports.CONFIG_KEY_RESUMING,
    exports.CONFIG_KEY_TASK_ID,
    exports.CONFIG_KEY_CALL,
    exports.CONFIG_KEY_RESUME_VALUE,
    exports.CONFIG_KEY_SCRATCHPAD,
    exports.CONFIG_KEY_PREVIOUS_STATE,
    exports.CONFIG_KEY_CHECKPOINT_MAP,
    exports.CONFIG_KEY_CHECKPOINT_NS,
    exports.CONFIG_KEY_CHECKPOINT_ID
];
exports.CHECKPOINT_NAMESPACE_SEPARATOR = "|";
exports.CHECKPOINT_NAMESPACE_END = ":";
/** @internal */ const COMMAND_SYMBOL = Symbol.for("langgraph.command");
/**
 * Instance of a {@link Command} class.
 *
 * This is used to avoid IntelliSense suggesting public fields
 * of {@link Command} class when a plain object is expected.
 *
 * @see {@link Command}
 * @internal
 */ class CommandInstance {
    constructor(){
        Object.defineProperty(this, _a, {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
    }
}
exports.CommandInstance = CommandInstance;
_a = COMMAND_SYMBOL;
function _isSendInterface(x) {
    const operation = x;
    return operation !== null && operation !== undefined && typeof operation.node === "string" && operation.args !== undefined;
}
/**
 *
 * A message or packet to send to a specific node in the graph.
 *
 * The `Send` class is used within a `StateGraph`'s conditional edges to
 * dynamically invoke a node with a custom state at the next step.
 *
 * Importantly, the sent state can differ from the core graph's state,
 * allowing for flexible and dynamic workflow management.
 *
 * One such example is a "map-reduce" workflow where your graph invokes
 * the same node multiple times in parallel with different states,
 * before aggregating the results back into the main graph's state.
 *
 * @example
 * ```typescript
 * import { Annotation, Send, StateGraph } from "@langchain/langgraph";
 *
 * const ChainState = Annotation.Root({
 *   subjects: Annotation<string[]>,
 *   jokes: Annotation<string[]>({
 *     reducer: (a, b) => a.concat(b),
 *   }),
 * });
 *
 * const continueToJokes = async (state: typeof ChainState.State) => {
 *   return state.subjects.map((subject) => {
 *     return new Send("generate_joke", { subjects: [subject] });
 *   });
 * };
 *
 * const graph = new StateGraph(ChainState)
 *   .addNode("generate_joke", (state) => ({
 *     jokes: [`Joke about ${state.subjects}`],
 *   }))
 *   .addConditionalEdges("__start__", continueToJokes)
 *   .addEdge("generate_joke", "__end__")
 *   .compile();
 *
 * const res = await graph.invoke({ subjects: ["cats", "dogs"] });
 * console.log(res);
 *
 * // Invoking with two subjects results in a generated joke for each
 * // { subjects: ["cats", "dogs"], jokes: [`Joke about cats`, `Joke about dogs`] }
 * ```
 */ // eslint-disable-next-line @typescript-eslint/no-explicit-any
class Send {
    constructor(node, args){
        Object.defineProperty(this, "lg_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "Send"
        });
        Object.defineProperty(this, "node", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "args", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.node = node;
        this.args = _deserializeCommandSendObjectGraph(args);
    }
    toJSON() {
        return {
            lg_name: this.lg_name,
            node: this.node,
            args: this.args
        };
    }
}
exports.Send = Send;
function _isSend(x) {
    // eslint-disable-next-line no-instanceof/no-instanceof
    return x instanceof Send;
}
/**
 * Checks if the given graph invoke / stream chunk contains interrupt.
 *
 * @example
 * ```ts
 * import { INTERRUPT, isInterrupted } from "@langchain/langgraph";
 *
 * const values = await graph.invoke({ foo: "bar" });
 * if (isInterrupted<string>(values)) {
 *   const interrupt = values[INTERRUPT][0].value;
 * }
 * ```
 *
 * @param values - The values to check.
 * @returns `true` if the values contain an interrupt, `false` otherwise.
 */ function isInterrupted(values) {
    if (!values || typeof values !== "object") return false;
    if (!(exports.INTERRUPT in values)) return false;
    return Array.isArray(values[exports.INTERRUPT]);
}
/**
 * One or more commands to update the graph's state and send messages to nodes.
 * Can be used to combine routing logic with state updates in lieu of conditional edges
 *
 * @example
 * ```ts
 * import { Annotation, Command } from "@langchain/langgraph";
 *
 * // Define graph state
 * const StateAnnotation = Annotation.Root({
 *   foo: Annotation<string>,
 * });
 *
 * // Define the nodes
 * const nodeA = async (_state: typeof StateAnnotation.State) => {
 *   console.log("Called A");
 *   // this is a replacement for a real conditional edge function
 *   const goto = Math.random() > .5 ? "nodeB" : "nodeC";
 *   // note how Command allows you to BOTH update the graph state AND route to the next node
 *   return new Command({
 *     // this is the state update
 *     update: {
 *       foo: "a",
 *     },
 *     // this is a replacement for an edge
 *     goto,
 *   });
 * };
 *
 * // Nodes B and C are unchanged
 * const nodeB = async (state: typeof StateAnnotation.State) => {
 *   console.log("Called B");
 *   return {
 *     foo: state.foo + "|b",
 *   };
 * }
 *
 * const nodeC = async (state: typeof StateAnnotation.State) => {
 *   console.log("Called C");
 *   return {
 *     foo: state.foo + "|c",
 *   };
 * }
 *
 * import { StateGraph } from "@langchain/langgraph";

 * // NOTE: there are no edges between nodes A, B and C!
 * const graph = new StateGraph(StateAnnotation)
 *   .addNode("nodeA", nodeA, {
 *     ends: ["nodeB", "nodeC"],
 *   })
 *   .addNode("nodeB", nodeB)
 *   .addNode("nodeC", nodeC)
 *   .addEdge("__start__", "nodeA")
 *   .compile();
 *
 * await graph.invoke({ foo: "" });
 *
 * // Randomly oscillates between
 * // { foo: 'a|c' } and { foo: 'a|b' }
 * ```
 */ class Command extends CommandInstance {
    constructor(args){
        super();
        Object.defineProperty(this, "lg_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "Command"
        });
        Object.defineProperty(this, "lc_direct_tool_output", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        /**
         * Graph to send the command to. Supported values are:
         *   - None: the current graph (default)
         *   - The specific name of the graph to send the command to
         *   - {@link Command.PARENT}: closest parent graph (only supported when returned from a node in a subgraph)
         */ Object.defineProperty(this, "graph", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Update to apply to the graph's state as a result of executing the node that is returning the command.
         * Written to the state as if the node had simply returned this value instead of the Command object.
         */ Object.defineProperty(this, "update", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Value to resume execution with. To be used together with {@link interrupt}.
         */ Object.defineProperty(this, "resume", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Can be one of the following:
         *   - name of the node to navigate to next (any node that belongs to the specified `graph`)
         *   - sequence of node names to navigate to next
         *   - {@link Send} object (to execute a node with the exact input provided in the {@link Send} object)
         *   - sequence of {@link Send} objects
         */ Object.defineProperty(this, "goto", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        this.resume = args.resume;
        this.graph = args.graph;
        this.update = args.update;
        if (args.goto) {
            this.goto = Array.isArray(args.goto) ? _deserializeCommandSendObjectGraph(args.goto) : [
                _deserializeCommandSendObjectGraph(args.goto)
            ];
        }
    }
    /**
     * Convert the update field to a list of {@link PendingWrite} tuples
     * @returns List of {@link PendingWrite} tuples of the form `[channelKey, value]`.
     * @internal
     */ _updateAsTuples() {
        if (this.update && typeof this.update === "object" && !Array.isArray(this.update)) {
            return Object.entries(this.update);
        } else if (Array.isArray(this.update) && this.update.every((t)=>Array.isArray(t) && t.length === 2 && typeof t[0] === "string")) {
            return this.update;
        } else {
            return [
                [
                    "__root__",
                    this.update
                ]
            ];
        }
    }
    toJSON() {
        let serializedGoto;
        if (typeof this.goto === "string") {
            serializedGoto = this.goto;
        } else if (_isSend(this.goto)) {
            serializedGoto = this.goto.toJSON();
        } else {
            serializedGoto = this.goto?.map((innerGoto)=>{
                if (typeof innerGoto === "string") {
                    return innerGoto;
                } else {
                    return innerGoto.toJSON();
                }
            });
        }
        return {
            lg_name: this.lg_name,
            update: this.update,
            resume: this.resume,
            goto: serializedGoto
        };
    }
}
exports.Command = Command;
Object.defineProperty(Command, "PARENT", {
    enumerable: true,
    configurable: true,
    writable: true,
    value: "__parent__"
});
/**
 * A type guard to check if the given value is a {@link Command}.
 *
 * Useful for type narrowing when working with the {@link Command} object.
 *
 * @param x - The value to check.
 * @returns `true` if the value is a {@link Command}, `false` otherwise.
 */ function isCommand(x) {
    if (typeof x !== "object") {
        return false;
    }
    if (x === null || x === undefined) {
        return false;
    }
    if ("lg_name" in x && x.lg_name === "Command") {
        return true;
    }
    return false;
}
/**
 * Reconstructs Command and Send objects from a deeply nested tree of anonymous objects
 * matching their interfaces.
 *
 * This is only exported for testing purposes. It is NOT intended to be used outside of
 * the Command and Send classes.
 *
 * @internal
 *
 * @param x - The command send tree to convert.
 * @param seen - A map of seen objects to avoid infinite loops.
 * @returns The converted command send tree.
 */ function _deserializeCommandSendObjectGraph(x, seen = new Map()) {
    if (x !== undefined && x !== null && typeof x === "object") {
        // If we've already processed this object, return the transformed version
        if (seen.has(x)) {
            return seen.get(x);
        }
        let result;
        if (Array.isArray(x)) {
            // Create the array first, then populate it
            result = [];
            // Add to seen map before processing elements to handle self-references
            seen.set(x, result);
            // Now populate the array
            x.forEach((item, index)=>{
                result[index] = _deserializeCommandSendObjectGraph(item, seen);
            });
        // eslint-disable-next-line no-instanceof/no-instanceof
        } else if (isCommand(x) && !(x instanceof Command)) {
            result = new Command(x);
            seen.set(x, result);
        // eslint-disable-next-line no-instanceof/no-instanceof
        } else if (_isSendInterface(x) && !(x instanceof Send)) {
            result = new Send(x.node, x.args);
            seen.set(x, result);
        } else if (isCommand(x) || _isSend(x)) {
            result = x;
            seen.set(x, result);
        } else if ("lc_serializable" in x && x.lc_serializable) {
            result = x;
            seen.set(x, result);
        } else {
            // Create empty object first
            result = {};
            // Add to seen map before processing properties to handle self-references
            seen.set(x, result);
            // Now populate the object
            for (const [key, value] of Object.entries(x)){
                result[key] = _deserializeCommandSendObjectGraph(value, seen);
            }
        }
        return result;
    }
    return x;
} //# sourceMappingURL=constants.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/utils/config.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ensureLangGraphConfig = ensureLangGraphConfig;
exports.getStore = getStore;
exports.getWriter = getWriter;
exports.getConfig = getConfig;
exports.getCurrentTaskInput = getCurrentTaskInput;
exports.recastCheckpointNamespace = recastCheckpointNamespace;
exports.getParentCheckpointNamespace = getParentCheckpointNamespace;
const singletons_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/singletons.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const COPIABLE_KEYS = [
    "tags",
    "metadata",
    "callbacks",
    "configurable"
];
const CONFIG_KEYS = [
    "tags",
    "metadata",
    "callbacks",
    "runName",
    "maxConcurrency",
    "recursionLimit",
    "configurable",
    "runId",
    "outputKeys",
    "streamMode",
    "store",
    "writer",
    "context",
    "interruptBefore",
    "interruptAfter",
    "checkpointDuring",
    "durability",
    "signal"
];
const DEFAULT_RECURSION_LIMIT = 25;
function ensureLangGraphConfig(...configs) {
    const empty = {
        tags: [],
        metadata: {},
        callbacks: undefined,
        recursionLimit: DEFAULT_RECURSION_LIMIT,
        configurable: {}
    };
    const implicitConfig = singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    if (implicitConfig !== undefined) {
        for (const [k, v] of Object.entries(implicitConfig)){
            if (v !== undefined) {
                if (COPIABLE_KEYS.includes(k)) {
                    let copiedValue;
                    if (Array.isArray(v)) {
                        copiedValue = [
                            ...v
                        ];
                    } else if (typeof v === "object") {
                        if (k === "callbacks" && "copy" in v && typeof v.copy === "function") {
                            copiedValue = v.copy();
                        } else {
                            copiedValue = {
                                ...v
                            };
                        }
                    } else {
                        copiedValue = v;
                    }
                    empty[k] = copiedValue;
                } else {
                    empty[k] = v;
                }
            }
        }
    }
    for (const config of configs){
        if (config === undefined) {
            continue;
        }
        for (const [k, v] of Object.entries(config)){
            if (v !== undefined && CONFIG_KEYS.includes(k)) {
                empty[k] = v;
            }
        }
    }
    for (const [key, value] of Object.entries(empty.configurable)){
        empty.metadata = empty.metadata ?? {};
        if (!key.startsWith("__") && (typeof value === "string" || typeof value === "number" || typeof value === "boolean") && !(key in empty.metadata)) {
            empty.metadata[key] = value;
        }
    }
    return empty;
}
/**
 * A helper utility function that returns the {@link BaseStore} that was set when the graph was initialized
 *
 * @returns a reference to the {@link BaseStore} that was set when the graph was initialized
 */ function getStore(config) {
    const runConfig = config ?? singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    if (runConfig === undefined) {
        throw new Error([
            "Config not retrievable. This is likely because you are running in an environment without support for AsyncLocalStorage.",
            "If you're running `getStore` in such environment, pass the `config` from the node function directly."
        ].join("\n"));
    }
    return runConfig?.store;
}
/**
 * A helper utility function that returns the {@link LangGraphRunnableConfig#writer} if "custom" stream mode is enabled, otherwise undefined.
 *
 * @returns a reference to the {@link LangGraphRunnableConfig#writer} if "custom" stream mode is enabled, otherwise undefined
 */ function getWriter(config) {
    const runConfig = config ?? singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    if (runConfig === undefined) {
        throw new Error([
            "Config not retrievable. This is likely because you are running in an environment without support for AsyncLocalStorage.",
            "If you're running `getWriter` in such environment, pass the `config` from the node function directly."
        ].join("\n"));
    }
    return runConfig?.writer || runConfig?.configurable?.writer;
}
/**
 * A helper utility function that returns the {@link LangGraphRunnableConfig} that was set when the graph was initialized.
 *
 * Note: This only works when running in an environment that supports node:async_hooks and AsyncLocalStorage. If you're running this in a
 * web environment, access the LangGraphRunnableConfig from the node function directly.
 *
 * @returns the {@link LangGraphRunnableConfig} that was set when the graph was initialized
 */ function getConfig() {
    return singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
}
/**
 * A helper utility function that returns the input for the currently executing task
 *
 * @returns the input for the currently executing task
 */ function getCurrentTaskInput(config) {
    const runConfig = config ?? singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    if (runConfig === undefined) {
        throw new Error([
            "Config not retrievable. This is likely because you are running in an environment without support for AsyncLocalStorage.",
            "If you're running `getCurrentTaskInput` in such environment, pass the `config` from the node function directly."
        ].join("\n"));
    }
    if (runConfig.configurable?.[constants_js_1.CONFIG_KEY_SCRATCHPAD]?.currentTaskInput === undefined) {
        throw new Error("BUG: internal scratchpad not initialized.");
    }
    return runConfig.configurable[constants_js_1.CONFIG_KEY_SCRATCHPAD].currentTaskInput;
}
function recastCheckpointNamespace(namespace) {
    return namespace.split(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR).filter((part)=>!part.match(/^\d+$/)).map((part)=>part.split(constants_js_1.CHECKPOINT_NAMESPACE_END)[0]).join(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR);
}
function getParentCheckpointNamespace(namespace) {
    const parts = namespace.split(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR);
    while(parts.length > 1 && parts[parts.length - 1].match(/^\d+$/)){
        parts.pop();
    }
    return parts.slice(0, -1).join(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR);
} //# sourceMappingURL=config.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.RunnableCallable = void 0;
exports.prefixGenerator = prefixGenerator;
exports.gatherIterator = gatherIterator;
exports.gatherIteratorSync = gatherIteratorSync;
exports.patchConfigurable = patchConfigurable;
exports.isAsyncGeneratorFunction = isAsyncGeneratorFunction;
exports.isGeneratorFunction = isGeneratorFunction;
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const singletons_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/singletons.cjs [app-route] (ecmascript)");
const config_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/config.cjs [app-route] (ecmascript)");
class RunnableCallable extends runnables_1.Runnable {
    constructor(fields){
        super();
        Object.defineProperty(this, "lc_namespace", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: [
                "langgraph"
            ]
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "func", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "tags", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "config", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "trace", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        Object.defineProperty(this, "recurse", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        this.name = fields.name ?? fields.func.name;
        this.func = fields.func;
        this.config = fields.tags ? {
            tags: fields.tags
        } : undefined;
        this.trace = fields.trace ?? this.trace;
        this.recurse = fields.recurse ?? this.recurse;
    }
    async _tracedInvoke(input, config, runManager) {
        return new Promise((resolve, reject)=>{
            const childConfig = (0, runnables_1.patchConfig)(config, {
                callbacks: runManager?.getChild()
            });
            void singletons_1.AsyncLocalStorageProviderSingleton.runWithConfig(childConfig, async ()=>{
                try {
                    const output = await this.func(input, childConfig);
                    resolve(output);
                } catch (e) {
                    reject(e);
                }
            });
        });
    }
    async invoke(// eslint-disable-next-line @typescript-eslint/no-explicit-any
    input, options) {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        let returnValue;
        const config = (0, config_js_1.ensureLangGraphConfig)(options);
        const mergedConfig = (0, runnables_1.mergeConfigs)(this.config, config);
        if (this.trace) {
            returnValue = await this._callWithConfig(this._tracedInvoke, input, mergedConfig);
        } else {
            returnValue = await singletons_1.AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async ()=>this.func(input, mergedConfig));
        }
        if (runnables_1.Runnable.isRunnable(returnValue) && this.recurse) {
            return await singletons_1.AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async ()=>returnValue.invoke(input, mergedConfig));
        }
        return returnValue;
    }
}
exports.RunnableCallable = RunnableCallable;
function* prefixGenerator(generator, prefix) {
    if (prefix === undefined) {
        yield* generator;
    } else {
        for (const value of generator){
            yield [
                prefix,
                value
            ];
        }
    }
}
// https://github.com/tc39/proposal-array-from-async
async function gatherIterator(i) {
    const out = [];
    for await (const item of (await i)){
        out.push(item);
    }
    return out;
}
function gatherIteratorSync(i) {
    const out = [];
    for (const item of i){
        out.push(item);
    }
    return out;
}
function patchConfigurable(config, // eslint-disable-next-line @typescript-eslint/no-explicit-any
patch) {
    if (!config) {
        return {
            configurable: patch
        };
    } else if (!("configurable" in config)) {
        return {
            ...config,
            configurable: patch
        };
    } else {
        return {
            ...config,
            configurable: {
                ...config.configurable,
                ...patch
            }
        };
    }
}
function isAsyncGeneratorFunction(val) {
    return val != null && typeof val === "function" && // eslint-disable-next-line no-instanceof/no-instanceof
    val instanceof Object.getPrototypeOf(async function*() {}).constructor;
}
function isGeneratorFunction(val) {
    return val != null && typeof val === "function" && // eslint-disable-next-line no-instanceof/no-instanceof
    val instanceof Object.getPrototypeOf(function*() {}).constructor;
} //# sourceMappingURL=utils.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ChannelWrite = exports.PASSTHROUGH = exports.SKIP_WRITE = void 0;
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
exports.SKIP_WRITE = {
    [Symbol.for("LG_SKIP_WRITE")]: true
};
function _isSkipWrite(x) {
    return typeof x === "object" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
    x?.[Symbol.for("LG_SKIP_WRITE")] !== undefined;
}
exports.PASSTHROUGH = {
    [Symbol.for("LG_PASSTHROUGH")]: true
};
function _isPassthrough(x) {
    return typeof x === "object" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
    x?.[Symbol.for("LG_PASSTHROUGH")] !== undefined;
}
const IS_WRITER = Symbol("IS_WRITER");
/**
 * Mapping of write channels to Runnables that return the value to be written,
 * or None to skip writing.
 */ class ChannelWrite extends utils_js_1.RunnableCallable {
    constructor(writes, tags){
        const name = `ChannelWrite<${writes.map((packet)=>{
            if ((0, constants_js_1._isSend)(packet)) {
                return packet.node;
            } else if ("channel" in packet) {
                return packet.channel;
            }
            return "...";
        }).join(",")}>`;
        super({
            ...{
                writes,
                name,
                tags
            },
            func: async (input, config)=>{
                return this._write(input, config ?? {});
            }
        });
        Object.defineProperty(this, "writes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.writes = writes;
    }
    async _write(input, config) {
        const writes = this.writes.map((write)=>{
            if (_isChannelWriteTupleEntry(write) && _isPassthrough(write.value)) {
                return {
                    mapper: write.mapper,
                    value: input
                };
            } else if (_isChannelWriteEntry(write) && _isPassthrough(write.value)) {
                return {
                    channel: write.channel,
                    value: input,
                    skipNone: write.skipNone,
                    mapper: write.mapper
                };
            } else {
                return write;
            }
        });
        await ChannelWrite.doWrite(config, writes);
        return input;
    }
    // TODO: Support requireAtLeastOneOf
    static async doWrite(config, writes) {
        // validate
        for (const w of writes){
            if (_isChannelWriteEntry(w)) {
                if (w.channel === constants_js_1.TASKS) {
                    throw new errors_js_1.InvalidUpdateError("Cannot write to the reserved channel TASKS");
                }
                if (_isPassthrough(w.value)) {
                    throw new errors_js_1.InvalidUpdateError("PASSTHROUGH value must be replaced");
                }
            }
            if (_isChannelWriteTupleEntry(w)) {
                if (_isPassthrough(w.value)) {
                    throw new errors_js_1.InvalidUpdateError("PASSTHROUGH value must be replaced");
                }
            }
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const writeEntries = [];
        for (const w of writes){
            if ((0, constants_js_1._isSend)(w)) {
                writeEntries.push([
                    constants_js_1.TASKS,
                    w
                ]);
            } else if (_isChannelWriteTupleEntry(w)) {
                const mappedResult = await w.mapper.invoke(w.value, config);
                if (mappedResult != null && mappedResult.length > 0) {
                    writeEntries.push(...mappedResult);
                }
            } else if (_isChannelWriteEntry(w)) {
                const mappedValue = w.mapper !== undefined ? await w.mapper.invoke(w.value, config) : w.value;
                if (_isSkipWrite(mappedValue)) {
                    continue;
                }
                if (w.skipNone && mappedValue === undefined) {
                    continue;
                }
                writeEntries.push([
                    w.channel,
                    mappedValue
                ]);
            } else {
                throw new Error(`Invalid write entry: ${JSON.stringify(w)}`);
            }
        }
        const write = config.configurable?.[constants_js_1.CONFIG_KEY_SEND];
        write(writeEntries);
    }
    static isWriter(runnable) {
        return(// eslint-disable-next-line no-instanceof/no-instanceof
        runnable instanceof ChannelWrite || IS_WRITER in runnable && !!runnable[IS_WRITER]);
    }
    static registerWriter(runnable) {
        return Object.defineProperty(runnable, IS_WRITER, {
            value: true
        });
    }
}
exports.ChannelWrite = ChannelWrite;
function _isChannelWriteEntry(x) {
    return x !== undefined && typeof x.channel === "string";
}
function _isChannelWriteTupleEntry(x) {
    return x !== undefined && !_isChannelWriteEntry(x) && runnables_1.Runnable.isRunnable(x.mapper);
} //# sourceMappingURL=write.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/read.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.PregelNode = exports.ChannelRead = void 0;
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const write_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
class ChannelRead extends utils_js_1.RunnableCallable {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    constructor(channel, // eslint-disable-next-line @typescript-eslint/no-explicit-any
    mapper, fresh = false){
        super({
            func: (_, config)=>ChannelRead.doRead(config, this.channel, this.fresh, this.mapper)
        });
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "ChannelRead"
        });
        Object.defineProperty(this, "channel", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "fresh", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "mapper", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.fresh = fresh;
        this.mapper = mapper;
        this.channel = channel;
        this.name = Array.isArray(channel) ? `ChannelRead<${channel.join(",")}>` : `ChannelRead<${channel}>`;
    }
    static doRead(config, channel, fresh, mapper) {
        const read = config.configurable?.[constants_js_1.CONFIG_KEY_READ];
        if (!read) {
            throw new Error("Runnable is not configured with a read function. Make sure to call in the context of a Pregel process");
        }
        if (mapper) {
            return mapper(read(channel, fresh));
        } else {
            return read(channel, fresh);
        }
    }
}
exports.ChannelRead = ChannelRead;
const defaultRunnableBound = /* #__PURE__ */ new runnables_1.RunnablePassthrough();
class PregelNode extends runnables_1.RunnableBinding {
    constructor(fields){
        const { channels, triggers, mapper, writers, bound, kwargs, metadata, retryPolicy, cachePolicy, tags, subgraphs, ends } = fields;
        const mergedTags = [
            ...fields.config?.tags ? fields.config.tags : [],
            ...tags ?? []
        ];
        super({
            ...fields,
            bound: fields.bound ?? defaultRunnableBound,
            config: {
                ...fields.config ? fields.config : {},
                tags: mergedTags
            }
        });
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "PregelNode"
        });
        Object.defineProperty(this, "channels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "triggers", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "mapper", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "writers", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "bound", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: defaultRunnableBound
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "kwargs", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        Object.defineProperty(this, "metadata", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        Object.defineProperty(this, "tags", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "retryPolicy", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "cachePolicy", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "subgraphs", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "ends", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.channels = channels;
        this.triggers = triggers;
        this.mapper = mapper;
        this.writers = writers ?? this.writers;
        this.bound = bound ?? this.bound;
        this.kwargs = kwargs ?? this.kwargs;
        this.metadata = metadata ?? this.metadata;
        this.tags = mergedTags;
        this.retryPolicy = retryPolicy;
        this.cachePolicy = cachePolicy;
        this.subgraphs = subgraphs;
        this.ends = ends;
    }
    getWriters() {
        const newWriters = [
            ...this.writers
        ];
        while(newWriters.length > 1 && // eslint-disable-next-line no-instanceof/no-instanceof
        newWriters[newWriters.length - 1] instanceof write_js_1.ChannelWrite && // eslint-disable-next-line no-instanceof/no-instanceof
        newWriters[newWriters.length - 2] instanceof write_js_1.ChannelWrite){
            // we can combine writes if they are consecutive
            // careful to not modify the original writers list or ChannelWrite
            const endWriters = newWriters.slice(-2);
            const combinedWrites = endWriters[0].writes.concat(endWriters[1].writes);
            newWriters[newWriters.length - 2] = new write_js_1.ChannelWrite(combinedWrites, endWriters[0].config?.tags);
            newWriters.pop();
        }
        return newWriters;
    }
    getNode() {
        const writers = this.getWriters();
        if (this.bound === defaultRunnableBound && writers.length === 0) {
            return undefined;
        } else if (this.bound === defaultRunnableBound && writers.length === 1) {
            return writers[0];
        } else if (this.bound === defaultRunnableBound) {
            return new runnables_1.RunnableSequence({
                first: writers[0],
                middle: writers.slice(1, writers.length - 1),
                last: writers[writers.length - 1],
                omitSequenceTags: true
            });
        } else if (writers.length > 0) {
            return new runnables_1.RunnableSequence({
                first: this.bound,
                middle: writers.slice(0, writers.length - 1),
                last: writers[writers.length - 1],
                omitSequenceTags: true
            });
        } else {
            return this.bound;
        }
    }
    join(channels) {
        if (!Array.isArray(channels)) {
            throw new Error("channels must be a list");
        }
        if (typeof this.channels !== "object") {
            throw new Error("all channels must be named when using .join()");
        }
        return new PregelNode({
            channels: {
                ...this.channels,
                ...Object.fromEntries(channels.map((chan)=>[
                        chan,
                        chan
                    ]))
            },
            triggers: this.triggers,
            mapper: this.mapper,
            writers: this.writers,
            bound: this.bound,
            kwargs: this.kwargs,
            config: this.config,
            retryPolicy: this.retryPolicy,
            cachePolicy: this.cachePolicy
        });
    }
    pipe(coerceable) {
        if (write_js_1.ChannelWrite.isWriter(coerceable)) {
            return new PregelNode({
                channels: this.channels,
                triggers: this.triggers,
                mapper: this.mapper,
                writers: [
                    ...this.writers,
                    coerceable
                ],
                bound: this.bound,
                config: this.config,
                kwargs: this.kwargs,
                retryPolicy: this.retryPolicy,
                cachePolicy: this.cachePolicy
            });
        } else if (this.bound === defaultRunnableBound) {
            return new PregelNode({
                channels: this.channels,
                triggers: this.triggers,
                mapper: this.mapper,
                writers: this.writers,
                bound: (0, runnables_1._coerceToRunnable)(coerceable),
                config: this.config,
                kwargs: this.kwargs,
                retryPolicy: this.retryPolicy,
                cachePolicy: this.cachePolicy
            });
        } else {
            return new PregelNode({
                channels: this.channels,
                triggers: this.triggers,
                mapper: this.mapper,
                writers: this.writers,
                bound: this.bound.pipe(coerceable),
                config: this.config,
                kwargs: this.kwargs,
                retryPolicy: this.retryPolicy,
                cachePolicy: this.cachePolicy
            });
        }
    }
}
exports.PregelNode = PregelNode; //# sourceMappingURL=read.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/hash.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/* Converted from https://github.com/i404788/xxh3-ts

BSD 2-Clause License

Copyright (c) 2019, i404788
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.XXH3 = XXH3;
exports.isXXH3 = isXXH3;
const n = (n)=>BigInt(n);
const view = (data, offset = 0)=>new DataView(data.buffer, data.byteOffset + offset, data.byteLength - offset);
const PRIME32_1 = n("0x9E3779B1"); // 0b10011110001101110111100110110001
const PRIME32_2 = n("0x85EBCA77"); // 0b10000101111010111100101001110111
const PRIME32_3 = n("0xC2B2AE3D"); // 0b11000010101100101010111000111101
const PRIME64_1 = n("0x9E3779B185EBCA87"); // 0b1001111000110111011110011011000110000101111010111100101010000111
const PRIME64_2 = n("0xC2B2AE3D27D4EB4F"); // 0b1100001010110010101011100011110100100111110101001110101101001111
const PRIME64_3 = n("0x165667B19E3779F9"); // 0b0001011001010110011001111011000110011110001101110111100111111001
const PRIME64_4 = n("0x85EBCA77C2B2AE63"); // 0b1000010111101011110010100111011111000010101100101010111001100011
const PRIME64_5 = n("0x27D4EB2F165667C5"); // 0b0010011111010100111010110010111100010110010101100110011111000101
const PRIME_MX1 = n("0x165667919E3779F9"); // 0b0001011001010110011001111001000110011110001101110111100111111001
const PRIME_MX2 = n("0x9FB21C651E98DF25"); // 0b1001111110110010000111000110010100011110100110001101111100100101
const hexToUint8Array = (hex)=>{
    const strLen = hex.length;
    if (strLen % 2 !== 0) {
        throw new Error("String should have an even number of characters");
    }
    const maxLength = strLen / 2;
    const bytes = new Uint8Array(maxLength);
    let read = 0;
    let write = 0;
    while(write < maxLength){
        const slice = hex.slice(read, read += 2);
        bytes[write] = Number.parseInt(slice, 16);
        write += 1;
    }
    return view(bytes);
};
const kkey = hexToUint8Array("b8fe6c3923a44bbe7c01812cf721ad1cded46de9839097db7240a4a4b7b3671fcb79e64eccc0e578825ad07dccff7221b8084674f743248ee03590e6813a264c3c2852bb91c300cb88d0658b1b532ea371644897a20df94e3819ef46a9deacd8a8fa763fe39c343ff9dcbbc7c70b4f1d8a51e04bcdb45931c89f7ec9d9787364eac5ac8334d3ebc3c581a0fffa1363eb170ddd51b7f0da49d316552629d4689e2b16be587d47a1fc8ff8b8d17ad031ce45cb3a8f95160428afd7fbcabb4b407e");
const mask128 = (n(1) << n(128)) - n(1);
const mask64 = (n(1) << n(64)) - n(1);
const mask32 = (n(1) << n(32)) - n(1);
const STRIPE_LEN = 64;
const ACC_NB = STRIPE_LEN / 8;
const _U64 = 8;
const _U32 = 4;
function assert(a) {
    if (!a) throw new Error("Assert failed");
}
function bswap64(a) {
    const scratchbuf = new DataView(new ArrayBuffer(8));
    scratchbuf.setBigUint64(0, a, true);
    return scratchbuf.getBigUint64(0, false);
}
function bswap32(input) {
    let a = input;
    a = (a & n(0x0000ffff)) << n(16) | (a & n(0xffff0000)) >> n(16);
    a = (a & n(0x00ff00ff)) << n(8) | (a & n(0xff00ff00)) >> n(8);
    return a; // 32-bit
}
function XXH_mult32to64(a, b) {
    return (a & mask32) * (b & mask32) & mask64;
}
function rotl32(a, b) {
    return (a << b | a >> n(32) - b) & mask32;
}
function XXH3_accumulate_512(acc, dataView, keyView) {
    for(let i = 0; i < ACC_NB; i += 1){
        const data_val = dataView.getBigUint64(i * 8, true);
        const data_key = data_val ^ keyView.getBigUint64(i * 8, true);
        acc[i ^ 1] += data_val;
        acc[i] += XXH_mult32to64(data_key, data_key >> n(32));
    }
    return acc;
}
function XXH3_accumulate(acc, dataView, keyView, nbStripes) {
    for(let n = 0; n < nbStripes; n += 1){
        XXH3_accumulate_512(acc, view(dataView, n * STRIPE_LEN), view(keyView, n * 8));
    }
    return acc;
}
function XXH3_scrambleAcc(acc, key) {
    for(let i = 0; i < ACC_NB; i += 1){
        const key64 = key.getBigUint64(i * 8, true);
        let acc64 = acc[i];
        acc64 = xorshift64(acc64, n(47));
        acc64 ^= key64;
        acc64 *= PRIME32_1;
        acc[i] = acc64 & mask64;
    }
    return acc;
}
function XXH3_mix2Accs(acc, key) {
    return XXH3_mul128_fold64(acc[0] ^ key.getBigUint64(0, true), acc[1] ^ key.getBigUint64(_U64, true));
}
function XXH3_mergeAccs(acc, key, start) {
    let result64 = start;
    result64 += XXH3_mix2Accs(acc.slice(0), view(key, 0 * _U32));
    result64 += XXH3_mix2Accs(acc.slice(2), view(key, 4 * _U32));
    result64 += XXH3_mix2Accs(acc.slice(4), view(key, 8 * _U32));
    result64 += XXH3_mix2Accs(acc.slice(6), view(key, 12 * _U32));
    return XXH3_avalanche(result64 & mask64);
}
function XXH3_hashLong(input, data, secret, f_acc, f_scramble) {
    let acc = input;
    const nbStripesPerBlock = Math.floor((secret.byteLength - STRIPE_LEN) / 8);
    const block_len = STRIPE_LEN * nbStripesPerBlock;
    const nb_blocks = Math.floor((data.byteLength - 1) / block_len);
    for(let n = 0; n < nb_blocks; n += 1){
        acc = XXH3_accumulate(acc, view(data, n * block_len), secret, nbStripesPerBlock);
        acc = f_scramble(acc, view(secret, secret.byteLength - STRIPE_LEN));
    }
    {
        // Partial block
        const nbStripes = Math.floor((data.byteLength - 1 - block_len * nb_blocks) / STRIPE_LEN);
        acc = XXH3_accumulate(acc, view(data, nb_blocks * block_len), secret, nbStripes);
        // Last Stripe
        acc = f_acc(acc, view(data, data.byteLength - STRIPE_LEN), view(secret, secret.byteLength - STRIPE_LEN - 7));
    }
    return acc;
}
function XXH3_hashLong_128b(data, secret) {
    let acc = new BigUint64Array([
        PRIME32_3,
        PRIME64_1,
        PRIME64_2,
        PRIME64_3,
        PRIME64_4,
        PRIME32_2,
        PRIME64_5,
        PRIME32_1
    ]);
    assert(data.byteLength > 128);
    acc = XXH3_hashLong(acc, data, secret, XXH3_accumulate_512, XXH3_scrambleAcc);
    /* converge into final hash */ assert(acc.length * 8 === 64);
    {
        const low64 = XXH3_mergeAccs(acc, view(secret, 11), n(data.byteLength) * PRIME64_1 & mask64);
        const high64 = XXH3_mergeAccs(acc, view(secret, secret.byteLength - STRIPE_LEN - 11), ~(n(data.byteLength) * PRIME64_2) & mask64);
        return high64 << n(64) | low64;
    }
}
function XXH3_mul128_fold64(a, b) {
    const lll = a * b & mask128;
    return lll & mask64 ^ lll >> n(64);
}
function XXH3_mix16B(dataView, keyView, seed) {
    return XXH3_mul128_fold64((dataView.getBigUint64(0, true) ^ keyView.getBigUint64(0, true) + seed) & mask64, (dataView.getBigUint64(8, true) ^ keyView.getBigUint64(8, true) - seed) & mask64);
}
function XXH3_mix32B(acc, data1, data2, key, seed) {
    let accl = acc & mask64;
    let acch = acc >> n(64) & mask64;
    accl += XXH3_mix16B(data1, key, seed);
    accl ^= data2.getBigUint64(0, true) + data2.getBigUint64(8, true);
    accl &= mask64;
    acch += XXH3_mix16B(data2, view(key, 16), seed);
    acch ^= data1.getBigUint64(0, true) + data1.getBigUint64(8, true);
    acch &= mask64;
    return acch << n(64) | accl;
}
function XXH3_avalanche(input) {
    let h64 = input;
    h64 ^= h64 >> n(37);
    h64 *= PRIME_MX1;
    h64 &= mask64;
    h64 ^= h64 >> n(32);
    return h64;
}
function XXH3_avalanche64(input) {
    let h64 = input;
    h64 ^= h64 >> n(33);
    h64 *= PRIME64_2;
    h64 &= mask64; // 64-bit
    h64 ^= h64 >> n(29);
    h64 *= PRIME64_3;
    h64 &= mask64;
    h64 ^= h64 >> n(32);
    return h64;
}
function XXH3_len_1to3_128b(data, key32, seed) {
    const len = data.byteLength;
    assert(len > 0 && len <= 3);
    const combined = n(data.getUint8(len - 1)) | n(len << 8) | n(data.getUint8(0) << 16) | n(data.getUint8(len >> 1) << 24);
    const blow = (n(key32.getUint32(0, true)) ^ n(key32.getUint32(4, true))) + seed;
    const low = (combined ^ blow) & mask64;
    const bhigh = (n(key32.getUint32(8, true)) ^ n(key32.getUint32(12, true))) - seed;
    const high = (rotl32(bswap32(combined), n(13)) ^ bhigh) & mask64;
    return (XXH3_avalanche64(high) & mask64) << n(64) | XXH3_avalanche64(low);
}
function xorshift64(b, shift) {
    return b ^ b >> shift;
}
function XXH3_len_4to8_128b(data, key32, seed) {
    const len = data.byteLength;
    assert(len >= 4 && len <= 8);
    {
        const l1 = data.getUint32(0, true);
        const l2 = data.getUint32(len - 4, true);
        const l64 = n(l1) | n(l2) << n(32);
        const bitflip = (key32.getBigUint64(16, true) ^ key32.getBigUint64(24, true)) + seed & mask64;
        const keyed = l64 ^ bitflip;
        let m128 = keyed * (PRIME64_1 + (n(len) << n(2))) & mask128;
        m128 += (m128 & mask64) << n(65);
        m128 &= mask128;
        m128 ^= m128 >> n(67);
        return xorshift64(xorshift64(m128 & mask64, n(35)) * PRIME_MX2 & mask64, n(28)) | XXH3_avalanche(m128 >> n(64)) << n(64);
    }
}
function XXH3_len_9to16_128b(data, key64, seed) {
    const len = data.byteLength;
    assert(len >= 9 && len <= 16);
    {
        const bitflipl = (key64.getBigUint64(32, true) ^ key64.getBigUint64(40, true)) + seed & mask64;
        const bitfliph = (key64.getBigUint64(48, true) ^ key64.getBigUint64(56, true)) - seed & mask64;
        const ll1 = data.getBigUint64(0, true);
        let ll2 = data.getBigUint64(len - 8, true);
        let m128 = (ll1 ^ ll2 ^ bitflipl) * PRIME64_1;
        const m128_l = (m128 & mask64) + (n(len - 1) << n(54));
        m128 = m128 & (mask128 ^ mask64) | m128_l; // eqv. to adding only to lower 64b
        ll2 ^= bitfliph;
        m128 += ll2 + (ll2 & mask32) * (PRIME32_2 - n(1)) << n(64);
        m128 &= mask128;
        m128 ^= bswap64(m128 >> n(64));
        let h128 = (m128 & mask64) * PRIME64_2;
        h128 += (m128 >> n(64)) * PRIME64_2 << n(64);
        h128 &= mask128;
        return XXH3_avalanche(h128 & mask64) | XXH3_avalanche(h128 >> n(64)) << n(64);
    }
}
function XXH3_len_0to16_128b(data, seed) {
    const len = data.byteLength;
    assert(len <= 16);
    if (len > 8) return XXH3_len_9to16_128b(data, kkey, seed);
    if (len >= 4) return XXH3_len_4to8_128b(data, kkey, seed);
    if (len > 0) return XXH3_len_1to3_128b(data, kkey, seed);
    return XXH3_avalanche64(seed ^ kkey.getBigUint64(64, true) ^ kkey.getBigUint64(72, true)) | XXH3_avalanche64(seed ^ kkey.getBigUint64(80, true) ^ kkey.getBigUint64(88, true)) << n(64);
}
function inv64(x) {
    // NOTE: `AND` fixes signedness (but because of 2's complement we need to re-add 1)
    return ~x + n(1) & mask64;
}
function XXH3_len_17to128_128b(data, secret, seed) {
    let acc = n(data.byteLength) * PRIME64_1 & mask64;
    let i = n(data.byteLength - 1) / n(32);
    while(i >= 0){
        const ni = Number(i);
        acc = XXH3_mix32B(acc, view(data, 16 * ni), view(data, data.byteLength - 16 * (ni + 1)), view(secret, 32 * ni), seed);
        i -= n(1);
    }
    let h128l = acc + (acc >> n(64)) & mask64;
    h128l = XXH3_avalanche(h128l);
    let h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;
    h128h &= mask64;
    h128h = inv64(XXH3_avalanche(h128h));
    return h128l | h128h << n(64);
}
function XXH3_len_129to240_128b(data, secret, seed) {
    let acc = n(data.byteLength) * PRIME64_1 & mask64;
    for(let i = 32; i < 160; i += 32){
        acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, i - 32), seed);
    }
    acc = XXH3_avalanche(acc & mask64) | XXH3_avalanche(acc >> n(64)) << n(64);
    for(let i = 160; i <= data.byteLength; i += 32){
        acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, 3 + i - 160), seed);
    }
    acc = XXH3_mix32B(acc, view(data, data.byteLength - 16), view(data, data.byteLength - 32), view(secret, 136 - 17 - 16), inv64(seed));
    let h128l = acc + (acc >> n(64)) & mask64;
    h128l = XXH3_avalanche(h128l);
    let h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;
    h128h &= mask64;
    h128h = inv64(XXH3_avalanche(h128h));
    return h128l | h128h << n(64);
}
// 16 byte min input
function XXH3(input, seed = n(0)) {
    const encoder = new TextEncoder();
    const data = view(typeof input === "string" ? encoder.encode(input) : input);
    const len = data.byteLength;
    const hexDigest = (data)=>data.toString(16).padStart(32, "0");
    if (len <= 16) return hexDigest(XXH3_len_0to16_128b(data, seed));
    if (len <= 128) return hexDigest(XXH3_len_17to128_128b(data, kkey, seed));
    if (len <= 240) return hexDigest(XXH3_len_129to240_128b(data, kkey, seed));
    return hexDigest(XXH3_hashLong_128b(data, kkey));
}
function isXXH3(value) {
    // Check if the given string matches the format of XXH3 (128 bit hex digest).
    return /^[0-9a-f]{32}$/.test(value);
} //# sourceMappingURL=hash.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/io.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.readChannel = readChannel;
exports.readChannels = readChannels;
exports.mapCommand = mapCommand;
exports.mapInput = mapInput;
exports.mapOutputValues = mapOutputValues;
exports.mapOutputUpdates = mapOutputUpdates;
exports.single = single;
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const hash_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/hash.cjs [app-route] (ecmascript)");
function readChannel(channels, chan, catchErrors = true, returnException = false) {
    try {
        return channels[chan].get();
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    } catch (e) {
        if (e.name === errors_js_1.EmptyChannelError.unminifiable_name) {
            if (returnException) {
                return e;
            } else if (catchErrors) {
                return null;
            }
        }
        throw e;
    }
}
function readChannels(channels, select, skipEmpty = true) {
    if (Array.isArray(select)) {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const values = {};
        for (const k of select){
            try {
                values[k] = readChannel(channels, k, !skipEmpty);
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            } catch (e) {
                if (e.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                    continue;
                }
            }
        }
        return values;
    } else {
        return readChannel(channels, select);
    }
}
/**
 * Map input chunk to a sequence of pending writes in the form (channel, value).
 */ function* mapCommand(cmd, pendingWrites) {
    if (cmd.graph === constants_js_1.Command.PARENT) {
        throw new errors_js_1.InvalidUpdateError("There is no parent graph.");
    }
    if (cmd.goto) {
        let sends;
        if (Array.isArray(cmd.goto)) {
            sends = cmd.goto;
        } else {
            sends = [
                cmd.goto
            ];
        }
        for (const send of sends){
            if ((0, constants_js_1._isSend)(send)) {
                yield [
                    constants_js_1.NULL_TASK_ID,
                    constants_js_1.TASKS,
                    send
                ];
            } else if (typeof send === "string") {
                yield [
                    constants_js_1.NULL_TASK_ID,
                    `branch:to:${send}`,
                    "__start__"
                ];
            } else {
                throw new Error(`In Command.send, expected Send or string, got ${typeof send}`);
            }
        }
    }
    if (cmd.resume) {
        if (typeof cmd.resume === "object" && Object.keys(cmd.resume).length && Object.keys(cmd.resume).every(hash_js_1.isXXH3)) {
            for (const [tid, resume] of Object.entries(cmd.resume)){
                const existing = pendingWrites.filter((w)=>w[0] === tid && w[1] === constants_js_1.RESUME).map((w)=>w[2]).slice(0, 1) ?? [];
                existing.push(resume);
                yield [
                    tid,
                    constants_js_1.RESUME,
                    existing
                ];
            }
        } else {
            yield [
                constants_js_1.NULL_TASK_ID,
                constants_js_1.RESUME,
                cmd.resume
            ];
        }
    }
    if (cmd.update) {
        if (typeof cmd.update !== "object" || !cmd.update) {
            throw new Error("Expected cmd.update to be a dict mapping channel names to update values");
        }
        if (Array.isArray(cmd.update)) {
            for (const [k, v] of cmd.update){
                yield [
                    constants_js_1.NULL_TASK_ID,
                    k,
                    v
                ];
            }
        } else {
            for (const [k, v] of Object.entries(cmd.update)){
                yield [
                    constants_js_1.NULL_TASK_ID,
                    k,
                    v
                ];
            }
        }
    }
}
/**
 * Map input chunk to a sequence of pending writes in the form [channel, value].
 */ function* mapInput(inputChannels, // eslint-disable-next-line @typescript-eslint/no-explicit-any
chunk) {
    if (chunk !== undefined && chunk !== null) {
        if (Array.isArray(inputChannels) && typeof chunk === "object" && !Array.isArray(chunk)) {
            for(const k in chunk){
                if (inputChannels.includes(k)) {
                    yield [
                        k,
                        chunk[k]
                    ];
                }
            }
        } else if (Array.isArray(inputChannels)) {
            throw new Error(`Input chunk must be an object when "inputChannels" is an array`);
        } else {
            yield [
                inputChannels,
                chunk
            ];
        }
    }
}
/**
 * Map pending writes (a sequence of tuples (channel, value)) to output chunk.
 */ function* mapOutputValues(outputChannels, pendingWrites, channels) {
    if (Array.isArray(outputChannels)) {
        if (pendingWrites === true || pendingWrites.find(([chan, _])=>outputChannels.includes(chan))) {
            yield readChannels(channels, outputChannels);
        }
    } else {
        if (pendingWrites === true || pendingWrites.some(([chan, _])=>chan === outputChannels)) {
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            yield readChannel(channels, outputChannels);
        }
    }
}
/**
 * Map pending writes (a sequence of tuples (channel, value)) to output chunk.
 * @internal
 *
 * @param outputChannels - The channels to output.
 * @param tasks - The tasks to output.
 * @param cached - Whether the output is cached.
 *
 * @returns A generator that yields the output chunk (if any).
 */ function* mapOutputUpdates(outputChannels, tasks, cached) {
    const outputTasks = tasks.filter(([task, ww])=>{
        return (task.config === undefined || !task.config.tags?.includes(constants_js_1.TAG_HIDDEN)) && ww[0][0] !== constants_js_1.ERROR && ww[0][0] !== constants_js_1.INTERRUPT;
    });
    if (!outputTasks.length) {
        return;
    }
    let updated;
    if (outputTasks.some(([task])=>task.writes.some(([chan, _])=>chan === constants_js_1.RETURN))) {
        // TODO: probably should assert that RETURN is the only "non-special" channel (starts with "__")
        updated = outputTasks.flatMap(([task])=>task.writes.filter(([chan, _])=>chan === constants_js_1.RETURN).map(([_, value])=>[
                    task.name,
                    value
                ]));
    } else if (!Array.isArray(outputChannels)) {
        // special case where graph state is a single channel (MessageGraph)
        // probably using this in functional API, too
        updated = outputTasks.flatMap(([task])=>task.writes.filter(([chan, _])=>chan === outputChannels).map(([_, value])=>[
                    task.name,
                    value
                ]));
    } else {
        updated = outputTasks.flatMap(([task])=>{
            const { writes } = task;
            const counts = {};
            for (const [chan] of writes){
                if (outputChannels.includes(chan)) {
                    counts[chan] = (counts[chan] || 0) + 1;
                }
            }
            if (Object.values(counts).some((count)=>count > 1)) {
                // Multiple writes to the same channel: create separate entries
                return writes.filter(([chan])=>outputChannels.includes(chan)).map(([chan, value])=>[
                        task.name,
                        {
                            [chan]: value
                        }
                    ]);
            } else {
                // Single write to each channel: create a single combined entry
                return [
                    [
                        task.name,
                        Object.fromEntries(writes.filter(([chan])=>outputChannels.includes(chan)))
                    ]
                ];
            }
        });
    }
    const grouped = {};
    for (const [node, value] of updated){
        if (!(node in grouped)) {
            grouped[node] = [];
        }
        grouped[node].push(value);
    }
    const flattened = {};
    for(const node in grouped){
        if (grouped[node].length === 1) {
            const [write] = grouped[node];
            flattened[node] = write;
        } else {
            flattened[node] = grouped[node];
        }
    }
    if (cached) {
        flattened["__metadata__"] = {
            cached
        };
    }
    yield flattened;
}
function single(iter) {
    // eslint-disable-next-line no-unreachable-loop
    for (const value of iter){
        return value;
    }
    return null;
} //# sourceMappingURL=io.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/types.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Call = void 0;
exports.isCall = isCall;
class Call {
    constructor({ func, name, input, retry, cache, callbacks }){
        Object.defineProperty(this, "func", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "input", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "retry", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "cache", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "callbacks", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "__lg_type", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "call"
        });
        this.func = func;
        this.name = name;
        this.input = input;
        this.retry = retry;
        this.cache = cache;
        this.callbacks = callbacks;
    }
}
exports.Call = Call;
function isCall(value) {
    return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "call";
} //# sourceMappingURL=types.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/utils/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.combineCallbacks = void 0;
exports.getNullChannelVersion = getNullChannelVersion;
exports.getNewChannelVersions = getNewChannelVersions;
exports._coerceToDict = _coerceToDict;
exports.patchConfigurable = patchConfigurable;
exports.patchCheckpointMap = patchCheckpointMap;
exports.combineAbortSignals = combineAbortSignals;
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
function getNullChannelVersion(currentVersions) {
    // Short circuit for commonly used channels such as __start__
    // (used by StateGraph)
    const startVersion = typeof currentVersions[constants_js_1.START];
    if (startVersion === "number") return 0;
    if (startVersion === "string") return "";
    // Defer back to obtaining a first key from channel versions
    for(const key in currentVersions){
        if (!Object.prototype.hasOwnProperty.call(currentVersions, key)) continue;
        const versionType = typeof currentVersions[key];
        if (versionType === "number") return 0;
        if (versionType === "string") return "";
        break;
    }
    return undefined;
}
function getNewChannelVersions(previousVersions, currentVersions) {
    // Get new channel versions
    if (Object.keys(previousVersions).length > 0) {
        const nullVersion = getNullChannelVersion(currentVersions);
        return Object.fromEntries(Object.entries(currentVersions).filter(([k, v])=>v > (previousVersions[k] ?? nullVersion)));
    } else {
        return currentVersions;
    }
}
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function _coerceToDict(value, defaultKey) {
    return value && !Array.isArray(value) && // eslint-disable-next-line no-instanceof/no-instanceof
    !(value instanceof Date) && typeof value === "object" ? value : {
        [defaultKey]: value
    };
}
function patchConfigurable(config, // eslint-disable-next-line @typescript-eslint/no-explicit-any
patch) {
    if (config === null) {
        return {
            configurable: patch
        };
    } else if (config?.configurable === undefined) {
        return {
            ...config,
            configurable: patch
        };
    } else {
        return {
            ...config,
            configurable: {
                ...config.configurable,
                ...patch
            }
        };
    }
}
function patchCheckpointMap(config, metadata) {
    const parents = metadata?.parents ?? {};
    if (Object.keys(parents).length > 0) {
        return patchConfigurable(config, {
            [constants_js_1.CONFIG_KEY_CHECKPOINT_MAP]: {
                ...parents,
                [config.configurable?.checkpoint_ns ?? ""]: config.configurable?.checkpoint_id
            }
        });
    } else {
        return config;
    }
}
/**
 * Combine multiple abort signals into a single abort signal.
 * @param signals - The abort signals to combine.
 * @returns A combined abort signal and a dispose function to remove the abort listener if unused.
 */ function combineAbortSignals(...x) {
    const signals = [
        ...new Set(x.filter(Boolean))
    ];
    if (signals.length === 0) {
        return {
            signal: undefined,
            dispose: undefined
        };
    }
    if (signals.length === 1) {
        return {
            signal: signals[0],
            dispose: undefined
        };
    }
    const combinedController = new AbortController();
    const listener = ()=>{
        const reason = signals.find((s)=>s.aborted)?.reason;
        combinedController.abort(reason);
        signals.forEach((s)=>s.removeEventListener("abort", listener));
    };
    signals.forEach((s)=>s.addEventListener("abort", listener, {
            once: true
        }));
    const hasAlreadyAbortedSignal = signals.find((s)=>s.aborted);
    if (hasAlreadyAbortedSignal) {
        combinedController.abort(hasAlreadyAbortedSignal.reason);
    }
    return {
        signal: combinedController.signal,
        dispose: ()=>{
            signals.forEach((s)=>s.removeEventListener("abort", listener));
        }
    };
}
/**
 * Combine multiple callbacks into a single callback.
 * @param callback1 - The first callback to combine.
 * @param callback2 - The second callback to combine.
 * @returns A single callback that is a combination of the input callbacks.
 */ const combineCallbacks = (callback1, callback2)=>{
    if (!callback1 && !callback2) {
        return undefined;
    }
    if (!callback1) {
        return callback2;
    }
    if (!callback2) {
        return callback1;
    }
    if (Array.isArray(callback1) && Array.isArray(callback2)) {
        return [
            ...callback1,
            ...callback2
        ];
    }
    if (Array.isArray(callback1)) {
        return [
            ...callback1,
            callback2
        ];
    }
    if (Array.isArray(callback2)) {
        return [
            callback1,
            ...callback2
        ];
    }
    return [
        callback1,
        callback2
    ];
};
exports.combineCallbacks = combineCallbacks; //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/call.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getRunnableForFunc = getRunnableForFunc;
exports.getRunnableForEntrypoint = getRunnableForEntrypoint;
exports.call = call;
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const singletons_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/singletons.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const write_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
/**
 * Wraps a user function in a Runnable that writes the returned value to the RETURN channel.
 */ function getRunnableForFunc(name, func) {
    const run = new utils_js_1.RunnableCallable({
        func: (input)=>func(...input),
        name,
        trace: false,
        recurse: false
    });
    return new runnables_1.RunnableSequence({
        name,
        first: run,
        last: new write_js_1.ChannelWrite([
            {
                channel: constants_js_1.RETURN,
                value: write_js_1.PASSTHROUGH
            }
        ], [
            constants_js_1.TAG_HIDDEN
        ])
    });
}
function getRunnableForEntrypoint(name, func) {
    const run = new utils_js_1.RunnableCallable({
        func: (input, config)=>{
            return func(input, config);
        },
        name,
        trace: false,
        recurse: false
    });
    return run;
}
function call({ func, name, cache, retry }, ...args) {
    const config = singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    if (typeof config.configurable?.[constants_js_1.CONFIG_KEY_CALL] === "function") {
        return config.configurable[constants_js_1.CONFIG_KEY_CALL](func, name, args, {
            retry,
            cache,
            callbacks: config.callbacks
        });
    }
    throw new Error("Async local storage not initialized. Please call initializeAsyncLocalStorageSingleton() before using this function.");
} //# sourceMappingURL=call.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/algo.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.increment = void 0;
exports.shouldInterrupt = shouldInterrupt;
exports._localRead = _localRead;
exports._localWrite = _localWrite;
exports._applyWrites = _applyWrites;
exports._prepareNextTasks = _prepareNextTasks;
exports._prepareSingleTask = _prepareSingleTask;
/* eslint-disable no-param-reassign */ const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const langgraph_checkpoint_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph-checkpoint/index.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
const io_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/io.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const types_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/types.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/index.cjs [app-route] (ecmascript)");
const call_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/call.cjs [app-route] (ecmascript)");
const hash_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/hash.cjs [app-route] (ecmascript)");
const increment = (current)=>{
    return current !== undefined ? current + 1 : 1;
};
exports.increment = increment;
// Avoids unnecessary double iteration
function maxChannelMapVersion(channelVersions) {
    let maxVersion;
    for(const chan in channelVersions){
        if (!Object.prototype.hasOwnProperty.call(channelVersions, chan)) continue;
        if (maxVersion == null) {
            maxVersion = channelVersions[chan];
        } else {
            maxVersion = (0, langgraph_checkpoint_1.maxChannelVersion)(maxVersion, channelVersions[chan]);
        }
    }
    return maxVersion;
}
function shouldInterrupt(checkpoint, interruptNodes, tasks) {
    const nullVersion = (0, index_js_1.getNullChannelVersion)(checkpoint.channel_versions);
    const seen = checkpoint.versions_seen[constants_js_1.INTERRUPT] ?? {};
    let anyChannelUpdated = false;
    for(const chan in checkpoint.channel_versions){
        if (!Object.prototype.hasOwnProperty.call(checkpoint.channel_versions, chan)) continue;
        if (checkpoint.channel_versions[chan] > (seen[chan] ?? nullVersion)) {
            anyChannelUpdated = true;
            break;
        }
    }
    const anyTriggeredNodeInInterruptNodes = tasks.some((task)=>interruptNodes === "*" ? !task.config?.tags?.includes(constants_js_1.TAG_HIDDEN) : interruptNodes.includes(task.name));
    return anyChannelUpdated && anyTriggeredNodeInInterruptNodes;
}
function _localRead(checkpoint, channels, task, select, fresh = false) {
    let updated = new Set();
    if (!Array.isArray(select)) {
        for (const [c] of task.writes){
            if (c === select) {
                updated = new Set([
                    c
                ]);
                break;
            }
        }
        updated = updated || new Set();
    } else {
        updated = new Set(select.filter((c)=>task.writes.some(([key, _])=>key === c)));
    }
    let values;
    if (fresh && updated.size > 0) {
        const localChannels = Object.fromEntries(Object.entries(channels).filter(([k, _])=>updated.has(k)));
        const newCheckpoint = (0, base_js_1.createCheckpoint)(checkpoint, localChannels, -1);
        const newChannels = (0, base_js_1.emptyChannels)(localChannels, newCheckpoint);
        _applyWrites((0, langgraph_checkpoint_1.copyCheckpoint)(newCheckpoint), newChannels, [
            task
        ], undefined, undefined);
        values = (0, io_js_1.readChannels)({
            ...channels,
            ...newChannels
        }, select);
    } else {
        values = (0, io_js_1.readChannels)(channels, select);
    }
    return values;
}
function _localWrite(// eslint-disable-next-line @typescript-eslint/no-explicit-any
commit, processes, // eslint-disable-next-line @typescript-eslint/no-explicit-any
writes) {
    for (const [chan, value] of writes){
        if ([
            constants_js_1.PUSH,
            constants_js_1.TASKS
        ].includes(chan) && value != null) {
            if (!(0, constants_js_1._isSend)(value)) {
                throw new errors_js_1.InvalidUpdateError(`Invalid packet type, expected SendProtocol, got ${JSON.stringify(value)}`);
            }
            if (!(value.node in processes)) {
                throw new errors_js_1.InvalidUpdateError(`Invalid node name "${value.node}" in Send packet`);
            }
        }
    }
    commit(writes);
}
const IGNORE = new Set([
    constants_js_1.NO_WRITES,
    constants_js_1.PUSH,
    constants_js_1.RESUME,
    constants_js_1.INTERRUPT,
    constants_js_1.RETURN,
    constants_js_1.ERROR
]);
function _applyWrites(checkpoint, channels, tasks, // eslint-disable-next-line @typescript-eslint/no-explicit-any
getNextVersion, triggerToNodes) {
    // Sort tasks by first 3 path elements for deterministic order
    // Later path parts (like task IDs) are ignored for sorting
    tasks.sort((a, b)=>{
        const aPath = a.path?.slice(0, 3) || [];
        const bPath = b.path?.slice(0, 3) || [];
        // Compare each path element
        for(let i = 0; i < Math.min(aPath.length, bPath.length); i += 1){
            if (aPath[i] < bPath[i]) return -1;
            if (aPath[i] > bPath[i]) return 1;
        }
        // If one path is shorter, it comes first
        return aPath.length - bPath.length;
    });
    // if no task has triggers this is applying writes from the null task only
    // so we don't do anything other than update the channels written to
    const bumpStep = tasks.some((task)=>task.triggers.length > 0);
    // Filter out non instances of BaseChannel
    const onlyChannels = (0, base_js_1.getOnlyChannels)(channels);
    // Update seen versions
    for (const task of tasks){
        checkpoint.versions_seen[task.name] ??= {};
        for (const chan of task.triggers){
            if (chan in checkpoint.channel_versions) {
                checkpoint.versions_seen[task.name][chan] = checkpoint.channel_versions[chan];
            }
        }
    }
    // Find the highest version of all channels
    let maxVersion = maxChannelMapVersion(checkpoint.channel_versions);
    // Consume all channels that were read
    const channelsToConsume = new Set(tasks.flatMap((task)=>task.triggers).filter((chan)=>!constants_js_1.RESERVED.includes(chan)));
    for (const chan of channelsToConsume){
        if (chan in onlyChannels && onlyChannels[chan].consume()) {
            if (getNextVersion !== undefined) {
                checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
            }
        }
    }
    // Group writes by channel
    const pendingWritesByChannel = {};
    for (const task of tasks){
        for (const [chan, val] of task.writes){
            if (IGNORE.has(chan)) {
            // do nothing
            } else if (chan in onlyChannels) {
                pendingWritesByChannel[chan] ??= [];
                pendingWritesByChannel[chan].push(val);
            }
        }
    }
    // Find the highest version of all channels
    maxVersion = maxChannelMapVersion(checkpoint.channel_versions);
    const updatedChannels = new Set();
    // Apply writes to channels
    for (const [chan, vals] of Object.entries(pendingWritesByChannel)){
        if (chan in onlyChannels) {
            const channel = onlyChannels[chan];
            let updated;
            try {
                updated = channel.update(vals);
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            } catch (e) {
                if (e.name === errors_js_1.InvalidUpdateError.unminifiable_name) {
                    const wrappedError = new errors_js_1.InvalidUpdateError(`Invalid update for channel "${chan}" with values ${JSON.stringify(vals)}: ${e.message}`);
                    wrappedError.lc_error_code = e.lc_error_code;
                    throw wrappedError;
                } else {
                    throw e;
                }
            }
            if (updated && getNextVersion !== undefined) {
                checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
                // unavailable channels can't trigger tasks, so don't add them
                if (channel.isAvailable()) updatedChannels.add(chan);
            }
        }
    }
    // Channels that weren't updated in this step are notified of a new step
    if (bumpStep) {
        for(const chan in onlyChannels){
            if (!Object.prototype.hasOwnProperty.call(onlyChannels, chan)) continue;
            const channel = onlyChannels[chan];
            if (channel.isAvailable() && !updatedChannels.has(chan)) {
                const updated = channel.update([]);
                if (updated && getNextVersion !== undefined) {
                    checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
                    // unavailable channels can't trigger tasks, so don't add them
                    if (channel.isAvailable()) updatedChannels.add(chan);
                }
            }
        }
    }
    // If this is (tentatively) the last superstep, notify all channels of finish
    if (bumpStep && !Object.keys(triggerToNodes ?? {}).some((channel)=>updatedChannels.has(channel))) {
        for(const chan in onlyChannels){
            if (!Object.prototype.hasOwnProperty.call(onlyChannels, chan)) continue;
            const channel = onlyChannels[chan];
            if (channel.finish() && getNextVersion !== undefined) {
                checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
                // unavailable channels can't trigger tasks, so don't add them
                if (channel.isAvailable()) updatedChannels.add(chan);
            }
        }
    }
}
/**
 * Prepare the set of tasks that will make up the next Pregel step.
 * This is the union of all PUSH tasks (Sends) and PULL tasks (nodes triggered
 * by edges).
 */ function _prepareNextTasks(checkpoint, pendingWrites, processes, channels, config, forExecution, extra) {
    const tasks = {};
    // Consume pending tasks
    const tasksChannel = channels[constants_js_1.TASKS];
    if (tasksChannel?.isAvailable()) {
        const len = tasksChannel.get().length;
        for(let i = 0; i < len; i += 1){
            const task = _prepareSingleTask([
                constants_js_1.PUSH,
                i
            ], checkpoint, pendingWrites, processes, channels, config, forExecution, extra);
            if (task !== undefined) {
                tasks[task.id] = task;
            }
        }
    }
    // Check if any processes should be run in next step
    // If so, prepare the values to be passed to them
    for(const name in processes){
        if (!Object.prototype.hasOwnProperty.call(processes, name)) continue;
        const task = _prepareSingleTask([
            constants_js_1.PULL,
            name
        ], checkpoint, pendingWrites, processes, channels, config, forExecution, extra);
        if (task !== undefined) {
            tasks[task.id] = task;
        }
    }
    return tasks;
}
/**
 * Prepares a single task for the next Pregel step, given a task path, which
 * uniquely identifies a PUSH or PULL task within the graph.
 */ function _prepareSingleTask(taskPath, checkpoint, pendingWrites, processes, channels, config, forExecution, extra) {
    const { step, checkpointer, manager } = extra;
    const configurable = config.configurable ?? {};
    const parentNamespace = configurable.checkpoint_ns ?? "";
    if (taskPath[0] === constants_js_1.PUSH && (0, types_js_1.isCall)(taskPath[taskPath.length - 1])) {
        const call = taskPath[taskPath.length - 1];
        const proc = (0, call_js_1.getRunnableForFunc)(call.name, call.func);
        const triggers = [
            constants_js_1.PUSH
        ];
        const checkpointNamespace = parentNamespace === "" ? call.name : `${parentNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR}${call.name}`;
        const id = (0, langgraph_checkpoint_1.uuid5)(JSON.stringify([
            checkpointNamespace,
            step.toString(),
            call.name,
            constants_js_1.PUSH,
            taskPath[1],
            taskPath[2]
        ]), checkpoint.id);
        const taskCheckpointNamespace = `${checkpointNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_END}${id}`;
        // we append `true` to the task path to indicate that a call is being made
        // so we should not return interrupts from this task (responsibility lies with the parent)
        const outputTaskPath = [
            ...taskPath.slice(0, 3),
            true
        ];
        const metadata = {
            langgraph_step: step,
            langgraph_node: call.name,
            langgraph_triggers: triggers,
            langgraph_path: outputTaskPath,
            langgraph_checkpoint_ns: taskCheckpointNamespace
        };
        if (forExecution) {
            const writes = [];
            const task = {
                name: call.name,
                input: call.input,
                proc,
                writes,
                config: (0, runnables_1.patchConfig)((0, runnables_1.mergeConfigs)(config, {
                    metadata,
                    store: extra.store ?? config.store
                }), {
                    runName: call.name,
                    callbacks: manager?.getChild(`graph:step:${step}`),
                    configurable: {
                        [constants_js_1.CONFIG_KEY_TASK_ID]: id,
                        // eslint-disable-next-line @typescript-eslint/no-explicit-any
                        [constants_js_1.CONFIG_KEY_SEND]: (writes_)=>_localWrite((items)=>writes.push(...items), processes, writes_),
                        [constants_js_1.CONFIG_KEY_READ]: (select_, fresh_ = false)=>_localRead(checkpoint, channels, {
                                name: call.name,
                                writes: writes,
                                triggers,
                                path: outputTaskPath
                            }, select_, fresh_),
                        [constants_js_1.CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[constants_js_1.CONFIG_KEY_CHECKPOINTER],
                        [constants_js_1.CONFIG_KEY_CHECKPOINT_MAP]: {
                            ...configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP],
                            [parentNamespace]: checkpoint.id
                        },
                        [constants_js_1.CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                            pendingWrites: pendingWrites ?? [],
                            taskId: id,
                            currentTaskInput: call.input,
                            resumeMap: config.configurable?.[constants_js_1.CONFIG_KEY_RESUME_MAP],
                            namespaceHash: (0, hash_js_1.XXH3)(taskCheckpointNamespace)
                        }),
                        [constants_js_1.CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[constants_js_1.PREVIOUS],
                        checkpoint_id: undefined,
                        checkpoint_ns: taskCheckpointNamespace
                    }
                }),
                triggers,
                retry_policy: call.retry,
                cache_key: call.cache ? {
                    key: (0, hash_js_1.XXH3)((call.cache.keyFunc ?? JSON.stringify)([
                        call.input
                    ])),
                    ns: [
                        constants_js_1.CACHE_NS_WRITES,
                        call.name ?? "__dynamic__"
                    ],
                    ttl: call.cache.ttl
                } : undefined,
                id,
                path: outputTaskPath,
                writers: []
            };
            return task;
        } else {
            return {
                id,
                name: call.name,
                interrupts: [],
                path: outputTaskPath
            };
        }
    } else if (taskPath[0] === constants_js_1.PUSH) {
        const index = typeof taskPath[1] === "number" ? taskPath[1] : parseInt(taskPath[1], 10);
        if (!channels[constants_js_1.TASKS]?.isAvailable()) {
            return undefined;
        }
        const sends = channels[constants_js_1.TASKS].get();
        if (index < 0 || index >= sends.length) {
            return undefined;
        }
        const packet = (0, constants_js_1._isSendInterface)(sends[index]) && !(0, constants_js_1._isSend)(sends[index]) ? new constants_js_1.Send(sends[index].node, sends[index].args) : sends[index];
        if (!(0, constants_js_1._isSendInterface)(packet)) {
            console.warn(`Ignoring invalid packet ${JSON.stringify(packet)} in pending sends.`);
            return undefined;
        }
        if (!(packet.node in processes)) {
            console.warn(`Ignoring unknown node name ${packet.node} in pending sends.`);
            return undefined;
        }
        const triggers = [
            constants_js_1.PUSH
        ];
        const checkpointNamespace = parentNamespace === "" ? packet.node : `${parentNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR}${packet.node}`;
        const taskId = (0, langgraph_checkpoint_1.uuid5)(JSON.stringify([
            checkpointNamespace,
            step.toString(),
            packet.node,
            constants_js_1.PUSH,
            index.toString()
        ]), checkpoint.id);
        const taskCheckpointNamespace = `${checkpointNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_END}${taskId}`;
        let metadata = {
            langgraph_step: step,
            langgraph_node: packet.node,
            langgraph_triggers: triggers,
            langgraph_path: taskPath.slice(0, 3),
            langgraph_checkpoint_ns: taskCheckpointNamespace
        };
        if (forExecution) {
            const proc = processes[packet.node];
            const node = proc.getNode();
            if (node !== undefined) {
                if (proc.metadata !== undefined) {
                    metadata = {
                        ...metadata,
                        ...proc.metadata
                    };
                }
                const writes = [];
                return {
                    name: packet.node,
                    input: packet.args,
                    proc: node,
                    subgraphs: proc.subgraphs,
                    writes,
                    config: (0, runnables_1.patchConfig)((0, runnables_1.mergeConfigs)(config, {
                        metadata,
                        tags: proc.tags,
                        store: extra.store ?? config.store
                    }), {
                        runName: packet.node,
                        callbacks: manager?.getChild(`graph:step:${step}`),
                        configurable: {
                            [constants_js_1.CONFIG_KEY_TASK_ID]: taskId,
                            // eslint-disable-next-line @typescript-eslint/no-explicit-any
                            [constants_js_1.CONFIG_KEY_SEND]: (writes_)=>_localWrite((items)=>writes.push(...items), processes, writes_),
                            [constants_js_1.CONFIG_KEY_READ]: (select_, fresh_ = false)=>_localRead(checkpoint, channels, {
                                    name: packet.node,
                                    writes: writes,
                                    triggers,
                                    path: taskPath
                                }, select_, fresh_),
                            [constants_js_1.CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[constants_js_1.CONFIG_KEY_CHECKPOINTER],
                            [constants_js_1.CONFIG_KEY_CHECKPOINT_MAP]: {
                                ...configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP],
                                [parentNamespace]: checkpoint.id
                            },
                            [constants_js_1.CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                                pendingWrites: pendingWrites ?? [],
                                taskId,
                                currentTaskInput: packet.args,
                                resumeMap: config.configurable?.[constants_js_1.CONFIG_KEY_RESUME_MAP],
                                namespaceHash: (0, hash_js_1.XXH3)(taskCheckpointNamespace)
                            }),
                            [constants_js_1.CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[constants_js_1.PREVIOUS],
                            checkpoint_id: undefined,
                            checkpoint_ns: taskCheckpointNamespace
                        }
                    }),
                    triggers,
                    retry_policy: proc.retryPolicy,
                    cache_key: proc.cachePolicy ? {
                        key: (0, hash_js_1.XXH3)((proc.cachePolicy.keyFunc ?? JSON.stringify)([
                            packet.args
                        ])),
                        ns: [
                            constants_js_1.CACHE_NS_WRITES,
                            proc.name ?? "__dynamic__",
                            packet.node
                        ],
                        ttl: proc.cachePolicy.ttl
                    } : undefined,
                    id: taskId,
                    path: taskPath,
                    writers: proc.getWriters()
                };
            }
        } else {
            return {
                id: taskId,
                name: packet.node,
                interrupts: [],
                path: taskPath
            };
        }
    } else if (taskPath[0] === constants_js_1.PULL) {
        const name = taskPath[1].toString();
        const proc = processes[name];
        if (proc === undefined) {
            return undefined;
        }
        // Check if this task already has successful writes in the pending writes
        if (pendingWrites?.length) {
            // Find the task ID for this node/path
            const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
            const taskId = (0, langgraph_checkpoint_1.uuid5)(JSON.stringify([
                checkpointNamespace,
                step.toString(),
                name,
                constants_js_1.PULL,
                name
            ]), checkpoint.id);
            // Check if there are successful writes (not ERROR) for this task ID
            const hasSuccessfulWrites = pendingWrites.some((w)=>w[0] === taskId && w[1] !== constants_js_1.ERROR);
            // If task completed successfully, don't include it in next tasks
            if (hasSuccessfulWrites) {
                return undefined;
            }
        }
        const nullVersion = (0, index_js_1.getNullChannelVersion)(checkpoint.channel_versions);
        if (nullVersion === undefined) {
            return undefined;
        }
        const seen = checkpoint.versions_seen[name] ?? {};
        // Find the first trigger that is available and has a new version
        const trigger = proc.triggers.find((chan)=>{
            if (!channels[chan].isAvailable()) return false;
            return (checkpoint.channel_versions[chan] ?? nullVersion) > (seen[chan] ?? nullVersion);
        });
        // If any of the channels read by this process were updated
        if (trigger !== undefined) {
            const val = _procInput(proc, channels, forExecution);
            if (val === undefined) {
                return undefined;
            }
            const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
            const taskId = (0, langgraph_checkpoint_1.uuid5)(JSON.stringify([
                checkpointNamespace,
                step.toString(),
                name,
                constants_js_1.PULL,
                [
                    trigger
                ]
            ]), checkpoint.id);
            const taskCheckpointNamespace = `${checkpointNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_END}${taskId}`;
            let metadata = {
                langgraph_step: step,
                langgraph_node: name,
                langgraph_triggers: [
                    trigger
                ],
                langgraph_path: taskPath,
                langgraph_checkpoint_ns: taskCheckpointNamespace
            };
            if (forExecution) {
                const node = proc.getNode();
                if (node !== undefined) {
                    if (proc.metadata !== undefined) {
                        metadata = {
                            ...metadata,
                            ...proc.metadata
                        };
                    }
                    const writes = [];
                    return {
                        name,
                        input: val,
                        proc: node,
                        subgraphs: proc.subgraphs,
                        writes,
                        config: (0, runnables_1.patchConfig)((0, runnables_1.mergeConfigs)(config, {
                            metadata,
                            tags: proc.tags,
                            store: extra.store ?? config.store
                        }), {
                            runName: name,
                            callbacks: manager?.getChild(`graph:step:${step}`),
                            configurable: {
                                [constants_js_1.CONFIG_KEY_TASK_ID]: taskId,
                                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                                [constants_js_1.CONFIG_KEY_SEND]: (writes_)=>_localWrite((items)=>{
                                        writes.push(...items);
                                    }, processes, writes_),
                                [constants_js_1.CONFIG_KEY_READ]: (select_, fresh_ = false)=>_localRead(checkpoint, channels, {
                                        name,
                                        writes: writes,
                                        triggers: [
                                            trigger
                                        ],
                                        path: taskPath
                                    }, select_, fresh_),
                                [constants_js_1.CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[constants_js_1.CONFIG_KEY_CHECKPOINTER],
                                [constants_js_1.CONFIG_KEY_CHECKPOINT_MAP]: {
                                    ...configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP],
                                    [parentNamespace]: checkpoint.id
                                },
                                [constants_js_1.CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                                    pendingWrites: pendingWrites ?? [],
                                    taskId,
                                    currentTaskInput: val,
                                    resumeMap: config.configurable?.[constants_js_1.CONFIG_KEY_RESUME_MAP],
                                    namespaceHash: (0, hash_js_1.XXH3)(taskCheckpointNamespace)
                                }),
                                [constants_js_1.CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[constants_js_1.PREVIOUS],
                                checkpoint_id: undefined,
                                checkpoint_ns: taskCheckpointNamespace
                            }
                        }),
                        triggers: [
                            trigger
                        ],
                        retry_policy: proc.retryPolicy,
                        cache_key: proc.cachePolicy ? {
                            key: (0, hash_js_1.XXH3)((proc.cachePolicy.keyFunc ?? JSON.stringify)([
                                val
                            ])),
                            ns: [
                                constants_js_1.CACHE_NS_WRITES,
                                proc.name ?? "__dynamic__",
                                name
                            ],
                            ttl: proc.cachePolicy.ttl
                        } : undefined,
                        id: taskId,
                        path: taskPath,
                        writers: proc.getWriters()
                    };
                }
            } else {
                return {
                    id: taskId,
                    name,
                    interrupts: [],
                    path: taskPath
                };
            }
        }
    }
    return undefined;
}
/**
 *  Function injected under CONFIG_KEY_READ in task config, to read current state.
 *  Used by conditional edges to read a copy of the state with reflecting the writes
 *  from that node only.
 *
 * @internal
 */ function _procInput(proc, channels, forExecution) {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    let val;
    if (typeof proc.channels === "object" && !Array.isArray(proc.channels)) {
        val = {};
        for (const [k, chan] of Object.entries(proc.channels)){
            if (proc.triggers.includes(chan)) {
                try {
                    val[k] = (0, io_js_1.readChannel)(channels, chan, false);
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                } catch (e) {
                    if (e.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                        return undefined;
                    } else {
                        throw e;
                    }
                }
            } else if (chan in channels) {
                try {
                    val[k] = (0, io_js_1.readChannel)(channels, chan, false);
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                } catch (e) {
                    if (e.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                        continue;
                    } else {
                        throw e;
                    }
                }
            }
        }
    } else if (Array.isArray(proc.channels)) {
        let successfulRead = false;
        for (const chan of proc.channels){
            try {
                val = (0, io_js_1.readChannel)(channels, chan, false);
                successfulRead = true;
                break;
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            } catch (e) {
                if (e.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                    continue;
                } else {
                    throw e;
                }
            }
        }
        if (!successfulRead) {
            return undefined;
        }
    } else {
        throw new Error(`Invalid channels type, expected list or dict, got ${proc.channels}`);
    }
    // If the process has a mapper, apply it to the value
    if (forExecution && proc.mapper !== undefined) {
        val = proc.mapper(val);
    }
    return val;
}
function _scratchpad({ pendingWrites, taskId, currentTaskInput, resumeMap, namespaceHash }) {
    const nullResume = pendingWrites.find(([writeTaskId, chan])=>writeTaskId === constants_js_1.NULL_TASK_ID && chan === constants_js_1.RESUME)?.[2];
    const resume = (()=>{
        const result = pendingWrites.filter(([writeTaskId, chan])=>writeTaskId === taskId && chan === constants_js_1.RESUME).flatMap(([_writeTaskId, _chan, resume])=>resume);
        if (resumeMap != null && namespaceHash in resumeMap) {
            const mappedResume = resumeMap[namespaceHash];
            result.push(mappedResume);
        }
        return result;
    })();
    const scratchpad = {
        callCounter: 0,
        interruptCounter: -1,
        resume,
        nullResume,
        subgraphCounter: 0,
        currentTaskInput,
        consumeNullResume: ()=>{
            if (scratchpad.nullResume) {
                delete scratchpad.nullResume;
                pendingWrites.splice(pendingWrites.findIndex(([writeTaskId, chan])=>writeTaskId === constants_js_1.NULL_TASK_ID && chan === constants_js_1.RESUME), 1);
                return nullResume;
            }
            return undefined;
        }
    };
    return scratchpad;
} //# sourceMappingURL=algo.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.isPregelLike = isPregelLike;
exports.findSubgraphPregel = findSubgraphPregel;
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function isRunnableSequence(x) {
    return "steps" in x && Array.isArray(x.steps);
}
function isPregelLike(// eslint-disable-next-line @typescript-eslint/no-explicit-any
x) {
    return "lg_is_pregel" in x && x.lg_is_pregel === true;
}
function findSubgraphPregel(candidate) {
    const candidates = [
        candidate
    ];
    for (const candidate of candidates){
        if (isPregelLike(candidate)) {
            return candidate;
        } else if (isRunnableSequence(candidate)) {
            candidates.push(...candidate.steps);
        }
    }
    return undefined;
} //# sourceMappingURL=subgraph.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/debug.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.wrap = void 0;
exports.printCheckpoint = printCheckpoint;
exports._readChannels = _readChannels;
exports.mapDebugTasks = mapDebugTasks;
exports.mapDebugTaskResults = mapDebugTaskResults;
exports.mapDebugCheckpoint = mapDebugCheckpoint;
exports.tasksWithWrites = tasksWithWrites;
exports.printStepCheckpoint = printStepCheckpoint;
exports.printStepTasks = printStepTasks;
exports.printStepWrites = printStepWrites;
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const io_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/io.cjs [app-route] (ecmascript)");
const subgraph_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.cjs [app-route] (ecmascript)");
const COLORS_MAP = {
    blue: {
        start: "\x1b[34m",
        end: "\x1b[0m"
    },
    green: {
        start: "\x1b[32m",
        end: "\x1b[0m"
    },
    yellow: {
        start: "\x1b[33;1m",
        end: "\x1b[0m"
    }
};
/**
 * Wrap some text in a color for printing to the console.
 */ const wrap = (color, text)=>`${color.start}${text}${color.end}`;
exports.wrap = wrap;
function printCheckpoint(step, channels) {
    console.log([
        `${(0, exports.wrap)(COLORS_MAP.blue, "[langgraph/checkpoint]")}`,
        `Finishing step ${step}. Channel values:\n`,
        `\n${JSON.stringify(Object.fromEntries(_readChannels(channels)), null, 2)}`
    ].join(""));
}
function* _readChannels(channels) {
    for (const [name, channel] of Object.entries(channels)){
        try {
            yield [
                name,
                channel.get()
            ];
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        } catch (error) {
            if (error.name === errors_js_1.EmptyChannelError.unminifiable_name) {
                continue;
            } else {
                throw error; // Re-throw the error if it's not an EmptyChannelError
            }
        }
    }
}
function* mapDebugTasks(tasks) {
    for (const { id, name, input, config, triggers, writes } of tasks){
        if (config?.tags?.includes(constants_js_1.TAG_HIDDEN)) continue;
        const interrupts = writes.filter(([writeId, n])=>{
            return writeId === id && n === constants_js_1.INTERRUPT;
        }).map(([, v])=>{
            return v;
        });
        yield {
            id,
            name,
            input,
            triggers,
            interrupts
        };
    }
}
function isMultipleChannelWrite(value) {
    if (typeof value !== "object" || value === null) return false;
    return "$writes" in value && Array.isArray(value.$writes);
}
function mapTaskResultWrites(writes) {
    const result = {};
    for (const [channel, value] of writes){
        const strChannel = String(channel);
        if (strChannel in result) {
            const channelWrites = isMultipleChannelWrite(result[strChannel]) ? result[strChannel].$writes : [
                result[strChannel]
            ];
            channelWrites.push(value);
            result[strChannel] = {
                $writes: channelWrites
            };
        } else {
            result[strChannel] = value;
        }
    }
    return result;
}
function* mapDebugTaskResults(tasks, streamChannels) {
    for (const [{ id, name, config }, writes] of tasks){
        if (config?.tags?.includes(constants_js_1.TAG_HIDDEN)) continue;
        yield {
            id,
            name,
            result: mapTaskResultWrites(writes.filter(([channel])=>{
                return Array.isArray(streamChannels) ? streamChannels.includes(channel) : channel === streamChannels;
            })),
            interrupts: writes.filter((w)=>w[0] === constants_js_1.INTERRUPT).map((w)=>w[1])
        };
    }
}
function* mapDebugCheckpoint(config, channels, streamChannels, metadata, tasks, pendingWrites, parentConfig, outputKeys) {
    function formatConfig(config) {
        // make sure the config is consistent with Python
        const pyConfig = {};
        if (config.callbacks != null) pyConfig.callbacks = config.callbacks;
        if (config.configurable != null) pyConfig.configurable = config.configurable;
        if (config.maxConcurrency != null) pyConfig.max_concurrency = config.maxConcurrency;
        if (config.metadata != null) pyConfig.metadata = config.metadata;
        if (config.recursionLimit != null) pyConfig.recursion_limit = config.recursionLimit;
        if (config.runId != null) pyConfig.run_id = config.runId;
        if (config.runName != null) pyConfig.run_name = config.runName;
        if (config.tags != null) pyConfig.tags = config.tags;
        return pyConfig;
    }
    const parentNs = config.configurable?.checkpoint_ns;
    const taskStates = {};
    for (const task of tasks){
        const candidates = task.subgraphs?.length ? task.subgraphs : [
            task.proc
        ];
        if (!candidates.find(subgraph_js_1.findSubgraphPregel)) continue;
        let taskNs = `${task.name}:${task.id}`;
        if (parentNs) taskNs = `${parentNs}|${taskNs}`;
        taskStates[task.id] = {
            configurable: {
                thread_id: config.configurable?.thread_id,
                checkpoint_ns: taskNs
            }
        };
    }
    yield {
        config: formatConfig(config),
        values: (0, io_js_1.readChannels)(channels, streamChannels),
        metadata,
        next: tasks.map((task)=>task.name),
        tasks: tasksWithWrites(tasks, pendingWrites, taskStates, outputKeys),
        parentConfig: parentConfig ? formatConfig(parentConfig) : undefined
    };
}
function tasksWithWrites(tasks, pendingWrites, states, outputKeys) {
    return tasks.map((task)=>{
        const error = pendingWrites.find(([id, n])=>id === task.id && n === constants_js_1.ERROR)?.[2];
        const interrupts = pendingWrites.filter(([id, n])=>id === task.id && n === constants_js_1.INTERRUPT).map(([, , v])=>v);
        const result = (()=>{
            if (error || interrupts.length || !pendingWrites.length) return undefined;
            const idx = pendingWrites.findIndex(([tid, n])=>tid === task.id && n === constants_js_1.RETURN);
            if (idx >= 0) return pendingWrites[idx][2];
            if (typeof outputKeys === "string") {
                return pendingWrites.find(([tid, n])=>tid === task.id && n === outputKeys)?.[2];
            }
            if (Array.isArray(outputKeys)) {
                const results = pendingWrites.filter(([tid, n])=>tid === task.id && outputKeys.includes(n)).map(([, n, v])=>[
                        n,
                        v
                    ]);
                if (!results.length) return undefined;
                return mapTaskResultWrites(results);
            }
            return undefined;
        })();
        if (error) {
            return {
                id: task.id,
                name: task.name,
                path: task.path,
                error,
                interrupts,
                result
            };
        }
        const taskState = states?.[task.id];
        return {
            id: task.id,
            name: task.name,
            path: task.path,
            interrupts,
            ...taskState !== undefined ? {
                state: taskState
            } : {},
            result
        };
    });
}
function printStepCheckpoint(step, channels, whitelist) {
    console.log([
        `${(0, exports.wrap)(COLORS_MAP.blue, `[${step}:checkpoint]`)}`,
        `\x1b[1m State at the end of step ${step}:\x1b[0m\n`,
        JSON.stringify((0, io_js_1.readChannels)(channels, whitelist), null, 2)
    ].join(""));
}
function printStepTasks(step, nextTasks) {
    const nTasks = nextTasks.length;
    console.log([
        `${(0, exports.wrap)(COLORS_MAP.blue, `[${step}:tasks]`)}`,
        `\x1b[1m Starting step ${step} with ${nTasks} task${nTasks === 1 ? "" : "s"}:\x1b[0m\n`,
        nextTasks.map((task)=>`- ${(0, exports.wrap)(COLORS_MAP.green, String(task.name))} -> ${JSON.stringify(task.input, null, 2)}`).join("\n")
    ].join(""));
}
function printStepWrites(step, writes, whitelist) {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const byChannel = {};
    for (const [channel, value] of writes){
        if (whitelist.includes(channel)) {
            if (!byChannel[channel]) {
                byChannel[channel] = [];
            }
            byChannel[channel].push(value);
        }
    }
    console.log([
        `${(0, exports.wrap)(COLORS_MAP.blue, `[${step}:writes]`)}`,
        `\x1b[1m Finished step ${step} with writes to ${Object.keys(byChannel).length} channel${Object.keys(byChannel).length !== 1 ? "s" : ""}:\x1b[0m\n`,
        Object.entries(byChannel).map(([name, vals])=>`- ${(0, exports.wrap)(COLORS_MAP.yellow, name)} -> ${vals.map((v)=>JSON.stringify(v)).join(", ")}`).join("\n")
    ].join(""));
} //# sourceMappingURL=debug.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/stream.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.IterableReadableWritableStream = exports.IterableReadableStreamWithAbortSignal = void 0;
const stream_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/utils/stream.cjs [app-route] (ecmascript)");
/**
 * A wrapper around an IterableReadableStream that allows for aborting the stream when
 * {@link cancel} is called.
 */ class IterableReadableStreamWithAbortSignal extends stream_1.IterableReadableStream {
    /**
     * @param readableStream - The stream to wrap.
     * @param abortController - The abort controller to use. Optional. One will be created if not provided.
     */ constructor(readableStream, abortController){
        const reader = readableStream.getReader();
        const ac = abortController ?? new AbortController();
        super({
            start (controller) {
                return pump();
                //TURBOPACK unreachable
                ;
                function pump() {
                    return reader.read().then(({ done, value })=>{
                        // When no more data needs to be consumed, close the stream
                        if (done) {
                            controller.close();
                            return;
                        }
                        // Enqueue the next data chunk into our target stream
                        controller.enqueue(value);
                        return pump();
                    });
                }
            }
        });
        Object.defineProperty(this, "_abortController", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "_innerReader", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this._abortController = ac;
        this._innerReader = reader;
    }
    /**
     * Aborts the stream, abandoning any pending operations in progress. Calling this triggers an
     * {@link AbortSignal} that is propagated to the tasks that are producing the data for this stream.
     * @param reason - The reason for aborting the stream. Optional.
     */ async cancel(reason) {
        this._abortController.abort(reason);
        this._innerReader.releaseLock();
    }
    /**
     * The {@link AbortSignal} for the stream. Aborted when {@link cancel} is called.
     */ get signal() {
        return this._abortController.signal;
    }
}
exports.IterableReadableStreamWithAbortSignal = IterableReadableStreamWithAbortSignal;
class IterableReadableWritableStream extends stream_1.IterableReadableStream {
    get closed() {
        return this._closed;
    }
    constructor(params){
        let streamControllerPromiseResolver;
        const streamControllerPromise = new Promise((resolve)=>{
            streamControllerPromiseResolver = resolve;
        });
        super({
            start: (controller)=>{
                streamControllerPromiseResolver(controller);
            }
        });
        Object.defineProperty(this, "modes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "controller", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "passthroughFn", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "_closed", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        // .start() will always be called before the stream can be interacted
        // with anyway
        void streamControllerPromise.then((controller)=>{
            this.controller = controller;
        });
        this.passthroughFn = params.passthroughFn;
        this.modes = params.modes;
    }
    push(chunk) {
        this.passthroughFn?.(chunk);
        this.controller.enqueue(chunk);
    }
    close() {
        try {
            this.controller.close();
        } catch (e) {
        // pass
        } finally{
            this._closed = true;
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    error(e) {
        this.controller.error(e);
    }
}
exports.IterableReadableWritableStream = IterableReadableWritableStream; //# sourceMappingURL=stream.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/loop.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.PregelLoop = void 0;
const langgraph_checkpoint_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph-checkpoint/index.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const algo_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/algo.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const io_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/io.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/index.cjs [app-route] (ecmascript)");
const debug_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/debug.cjs [app-route] (ecmascript)");
const stream_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/stream.cjs [app-route] (ecmascript)");
const hash_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/hash.cjs [app-route] (ecmascript)");
const INPUT_DONE = Symbol.for("INPUT_DONE");
const INPUT_RESUMING = Symbol.for("INPUT_RESUMING");
const DEFAULT_LOOP_LIMIT = 25;
function createDuplexStream(...streams) {
    return new stream_js_1.IterableReadableWritableStream({
        passthroughFn: (value)=>{
            for (const stream of streams){
                if (stream.modes.has(value[1])) {
                    stream.push(value);
                }
            }
        },
        modes: new Set(streams.flatMap((s)=>Array.from(s.modes)))
    });
}
class AsyncBatchedCache extends langgraph_checkpoint_1.BaseCache {
    constructor(cache){
        super();
        Object.defineProperty(this, "cache", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "queue", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: Promise.resolve()
        });
        this.cache = cache;
    }
    async get(keys) {
        return this.enqueueOperation("get", keys);
    }
    async set(pairs) {
        return this.enqueueOperation("set", pairs);
    }
    async clear(namespaces) {
        return this.enqueueOperation("clear", namespaces);
    }
    async stop() {
        await this.queue;
    }
    enqueueOperation(type, ...args) {
        const newPromise = this.queue.then(()=>{
            // @ts-expect-error Tuple type warning
            return this.cache[type](...args);
        });
        this.queue = newPromise.then(()=>void 0, ()=>void 0);
        return newPromise;
    }
}
class PregelLoop {
    get isResuming() {
        let hasChannelVersions = false;
        if (constants_js_1.START in this.checkpoint.channel_versions) {
            // For common channels, we can short-circuit the check
            hasChannelVersions = true;
        } else {
            for(const chan in this.checkpoint.channel_versions){
                if (Object.prototype.hasOwnProperty.call(this.checkpoint.channel_versions, chan)) {
                    hasChannelVersions = true;
                    break;
                }
            }
        }
        const configHasResumingFlag = this.config.configurable?.[constants_js_1.CONFIG_KEY_RESUMING] !== undefined;
        const configIsResuming = configHasResumingFlag && this.config.configurable?.[constants_js_1.CONFIG_KEY_RESUMING];
        const inputIsNullOrUndefined = this.input === null || this.input === undefined;
        const inputIsCommandResuming = (0, constants_js_1.isCommand)(this.input) && this.input.resume != null;
        const inputIsResuming = this.input === INPUT_RESUMING;
        const runIdMatchesPrevious = !this.isNested && this.config.metadata?.run_id !== undefined && this.checkpointMetadata?.run_id !== undefined && this.config.metadata.run_id === this.checkpointMetadata?.run_id;
        return hasChannelVersions && (configIsResuming || inputIsNullOrUndefined || inputIsCommandResuming || inputIsResuming || runIdMatchesPrevious);
    }
    constructor(params){
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "input", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "output", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "config", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointer", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointerGetNextVersion", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "channels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpoint", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointIdSaved", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointConfig", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointMetadata", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointNamespace", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointPendingWrites", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "checkpointPreviousVersions", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "step", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "stop", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "durability", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "outputKeys", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "streamKeys", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "nodes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "skipDoneTasks", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "prevCheckpointConfig", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "status", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "pending"
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "tasks", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "stream", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "checkpointerPromises", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "isNested", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "_checkpointerChainedPromise", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: Promise.resolve()
        });
        Object.defineProperty(this, "store", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "cache", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "manager", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "interruptAfter", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "interruptBefore", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "toInterrupt", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        Object.defineProperty(this, "debug", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        Object.defineProperty(this, "triggerToNodes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.input = params.input;
        this.checkpointer = params.checkpointer;
        // TODO: if managed values no longer needs graph we can replace with
        // managed_specs, channel_specs
        if (this.checkpointer !== undefined) {
            this.checkpointerGetNextVersion = this.checkpointer.getNextVersion.bind(this.checkpointer);
        } else {
            this.checkpointerGetNextVersion = algo_js_1.increment;
        }
        this.checkpoint = params.checkpoint;
        this.checkpointMetadata = params.checkpointMetadata;
        this.checkpointPreviousVersions = params.checkpointPreviousVersions;
        this.channels = params.channels;
        this.checkpointPendingWrites = params.checkpointPendingWrites;
        this.step = params.step;
        this.stop = params.stop;
        this.config = params.config;
        this.checkpointConfig = params.checkpointConfig;
        this.isNested = params.isNested;
        this.manager = params.manager;
        this.outputKeys = params.outputKeys;
        this.streamKeys = params.streamKeys;
        this.nodes = params.nodes;
        this.skipDoneTasks = params.skipDoneTasks;
        this.store = params.store;
        this.cache = params.cache ? new AsyncBatchedCache(params.cache) : undefined;
        this.stream = params.stream;
        this.checkpointNamespace = params.checkpointNamespace;
        this.prevCheckpointConfig = params.prevCheckpointConfig;
        this.interruptAfter = params.interruptAfter;
        this.interruptBefore = params.interruptBefore;
        this.durability = params.durability;
        this.debug = params.debug;
        this.triggerToNodes = params.triggerToNodes;
    }
    static async initialize(params) {
        let { config, stream } = params;
        if (stream !== undefined && config.configurable?.[constants_js_1.CONFIG_KEY_STREAM] !== undefined) {
            stream = createDuplexStream(stream, config.configurable[constants_js_1.CONFIG_KEY_STREAM]);
        }
        const skipDoneTasks = config.configurable ? !("checkpoint_id" in config.configurable) : true;
        const scratchpad = config.configurable?.[constants_js_1.CONFIG_KEY_SCRATCHPAD];
        if (config.configurable && scratchpad) {
            if (scratchpad.subgraphCounter > 0) {
                config = (0, index_js_1.patchConfigurable)(config, {
                    [constants_js_1.CONFIG_KEY_CHECKPOINT_NS]: [
                        config.configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_NS],
                        scratchpad.subgraphCounter.toString()
                    ].join(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR)
                });
            }
            scratchpad.subgraphCounter += 1;
        }
        const isNested = constants_js_1.CONFIG_KEY_READ in (config.configurable ?? {});
        if (!isNested && config.configurable?.checkpoint_ns !== undefined && config.configurable?.checkpoint_ns !== "") {
            config = (0, index_js_1.patchConfigurable)(config, {
                checkpoint_ns: "",
                checkpoint_id: undefined
            });
        }
        let checkpointConfig = config;
        if (config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP] !== undefined && config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP]?.[config.configurable?.checkpoint_ns]) {
            checkpointConfig = (0, index_js_1.patchConfigurable)(config, {
                checkpoint_id: config.configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP][config.configurable?.checkpoint_ns]
            });
        }
        const checkpointNamespace = config.configurable?.checkpoint_ns?.split(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR) ?? [];
        const saved = await params.checkpointer?.getTuple(checkpointConfig) ?? {
            config,
            checkpoint: (0, langgraph_checkpoint_1.emptyCheckpoint)(),
            metadata: {
                source: "input",
                step: -2,
                parents: {}
            },
            pendingWrites: []
        };
        checkpointConfig = {
            ...config,
            ...saved.config,
            configurable: {
                checkpoint_ns: "",
                ...config.configurable,
                ...saved.config.configurable
            }
        };
        const prevCheckpointConfig = saved.parentConfig;
        const checkpoint = (0, langgraph_checkpoint_1.copyCheckpoint)(saved.checkpoint);
        const checkpointMetadata = {
            ...saved.metadata
        };
        const checkpointPendingWrites = saved.pendingWrites ?? [];
        const channels = (0, base_js_1.emptyChannels)(params.channelSpecs, checkpoint);
        const step = (checkpointMetadata.step ?? 0) + 1;
        const stop = step + (config.recursionLimit ?? DEFAULT_LOOP_LIMIT) + 1;
        const checkpointPreviousVersions = {
            ...checkpoint.channel_versions
        };
        const store = params.store ? new langgraph_checkpoint_1.AsyncBatchedStore(params.store) : undefined;
        if (store) {
            // Start the store. This is a batch store, so it will run continuously
            await store.start();
        }
        return new PregelLoop({
            input: params.input,
            config,
            checkpointer: params.checkpointer,
            checkpoint,
            checkpointMetadata,
            checkpointConfig,
            prevCheckpointConfig,
            checkpointNamespace,
            channels,
            isNested,
            manager: params.manager,
            skipDoneTasks,
            step,
            stop,
            checkpointPreviousVersions,
            checkpointPendingWrites,
            outputKeys: params.outputKeys ?? [],
            streamKeys: params.streamKeys ?? [],
            nodes: params.nodes,
            stream,
            store,
            cache: params.cache,
            interruptAfter: params.interruptAfter,
            interruptBefore: params.interruptBefore,
            durability: params.durability,
            debug: params.debug,
            triggerToNodes: params.triggerToNodes
        });
    }
    _checkpointerPutAfterPrevious(input) {
        this._checkpointerChainedPromise = this._checkpointerChainedPromise.then(()=>{
            return this.checkpointer?.put(input.config, input.checkpoint, input.metadata, input.newVersions);
        });
        this.checkpointerPromises.push(this._checkpointerChainedPromise);
    }
    /**
     * Put writes for a task, to be read by the next tick.
     * @param taskId
     * @param writes
     */ putWrites(taskId, writes) {
        let writesCopy = writes;
        if (writesCopy.length === 0) return;
        // deduplicate writes to special channels, last write wins
        if (writesCopy.every(([key])=>key in langgraph_checkpoint_1.WRITES_IDX_MAP)) {
            writesCopy = Array.from(new Map(writesCopy.map((w)=>[
                    w[0],
                    w
                ])).values());
        }
        // remove existing writes for this task
        this.checkpointPendingWrites = this.checkpointPendingWrites.filter((w)=>w[0] !== taskId);
        // save writes
        for (const [c, v] of writesCopy){
            this.checkpointPendingWrites.push([
                taskId,
                c,
                v
            ]);
        }
        const config = (0, index_js_1.patchConfigurable)(this.checkpointConfig, {
            [constants_js_1.CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? "",
            [constants_js_1.CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id
        });
        if (this.durability !== "exit" && this.checkpointer != null) {
            this.checkpointerPromises.push(this.checkpointer.putWrites(config, writesCopy, taskId));
        }
        if (this.tasks) {
            this._outputWrites(taskId, writesCopy);
        }
        if (!writes.length || !this.cache || !this.tasks) {
            return;
        }
        // only cache tasks with a cache key
        const task = this.tasks[taskId];
        if (task == null || task.cache_key == null) {
            return;
        }
        // only cache successful tasks
        if (writes[0][0] === constants_js_1.ERROR || writes[0][0] === constants_js_1.INTERRUPT) {
            return;
        }
        void this.cache.set([
            {
                key: [
                    task.cache_key.ns,
                    task.cache_key.key
                ],
                value: task.writes,
                ttl: task.cache_key.ttl
            }
        ]);
    }
    _outputWrites(taskId, writes, cached = false) {
        const task = this.tasks[taskId];
        if (task !== undefined) {
            if (task.config !== undefined && (task.config.tags ?? []).includes(constants_js_1.TAG_HIDDEN)) {
                return;
            }
            if (writes.length > 0) {
                if (writes[0][0] === constants_js_1.INTERRUPT) {
                    // in `algo.ts` we append a bool to the task path to indicate
                    // whether or not a call was present. If so, we don't emit the
                    // the interrupt as it'll be emitted by the parent.
                    if (task.path?.[0] === constants_js_1.PUSH && task.path?.at(-1) === true) return;
                    const interruptWrites = writes.filter((w)=>w[0] === constants_js_1.INTERRUPT).flatMap((w)=>w[1]);
                    this._emit([
                        [
                            "updates",
                            {
                                [constants_js_1.INTERRUPT]: interruptWrites
                            }
                        ],
                        [
                            "values",
                            {
                                [constants_js_1.INTERRUPT]: interruptWrites
                            }
                        ]
                    ]);
                } else if (writes[0][0] !== constants_js_1.ERROR) {
                    this._emit((0, utils_js_1.gatherIteratorSync)((0, utils_js_1.prefixGenerator)((0, io_js_1.mapOutputUpdates)(this.outputKeys, [
                        [
                            task,
                            writes
                        ]
                    ], cached), "updates")));
                }
            }
            if (!cached) {
                this._emit((0, utils_js_1.gatherIteratorSync)((0, utils_js_1.prefixGenerator)((0, debug_js_1.mapDebugTaskResults)([
                    [
                        task,
                        writes
                    ]
                ], this.streamKeys), "tasks")));
            }
        }
    }
    async _matchCachedWrites() {
        if (!this.cache) return [];
        const matched = [];
        const serializeKey = ([ns, key])=>{
            return `ns:${ns.join(",")}|key:${key}`;
        };
        const keys = [];
        const keyMap = {};
        for (const task of Object.values(this.tasks)){
            if (task.cache_key != null && !task.writes.length) {
                keys.push([
                    task.cache_key.ns,
                    task.cache_key.key
                ]);
                keyMap[serializeKey([
                    task.cache_key.ns,
                    task.cache_key.key
                ])] = task;
            }
        }
        if (keys.length === 0) return [];
        const cache = await this.cache.get(keys);
        for (const { key, value } of cache){
            const task = keyMap[serializeKey(key)];
            if (task != null) {
                // update the task with the cached writes
                task.writes.push(...value);
                matched.push({
                    task,
                    result: value
                });
            }
        }
        return matched;
    }
    /**
     * Execute a single iteration of the Pregel loop.
     * Returns true if more iterations are needed.
     * @param params
     */ async tick(params) {
        if (this.store && !this.store.isRunning) {
            await this.store?.start();
        }
        const { inputKeys = [] } = params;
        if (this.status !== "pending") {
            throw new Error(`Cannot tick when status is no longer "pending". Current status: "${this.status}"`);
        }
        if (![
            INPUT_DONE,
            INPUT_RESUMING
        ].includes(this.input)) {
            await this._first(inputKeys);
        } else if (this.toInterrupt.length > 0) {
            this.status = "interrupt_before";
            throw new errors_js_1.GraphInterrupt();
        } else if (Object.values(this.tasks).every((task)=>task.writes.length > 0)) {
            // finish superstep
            const writes = Object.values(this.tasks).flatMap((t)=>t.writes);
            // All tasks have finished
            (0, algo_js_1._applyWrites)(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
            // produce values output
            const valuesOutput = await (0, utils_js_1.gatherIterator)((0, utils_js_1.prefixGenerator)((0, io_js_1.mapOutputValues)(this.outputKeys, writes, this.channels), "values"));
            this._emit(valuesOutput);
            // clear pending writes
            this.checkpointPendingWrites = [];
            await this._putCheckpoint({
                source: "loop"
            });
            // after execution, check if we should interrupt
            if ((0, algo_js_1.shouldInterrupt)(this.checkpoint, this.interruptAfter, Object.values(this.tasks))) {
                this.status = "interrupt_after";
                throw new errors_js_1.GraphInterrupt();
            }
            // unset resuming flag
            if (this.config.configurable?.[constants_js_1.CONFIG_KEY_RESUMING] !== undefined) {
                delete this.config.configurable?.[constants_js_1.CONFIG_KEY_RESUMING];
            }
        } else {
            return false;
        }
        if (this.step > this.stop) {
            this.status = "out_of_steps";
            return false;
        }
        const nextTasks = (0, algo_js_1._prepareNextTasks)(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, {
            step: this.step,
            checkpointer: this.checkpointer,
            isResuming: this.isResuming,
            manager: this.manager,
            store: this.store,
            stream: this.stream
        });
        this.tasks = nextTasks;
        // Produce debug output
        if (this.checkpointer) {
            this._emit(await (0, utils_js_1.gatherIterator)((0, utils_js_1.prefixGenerator)((0, debug_js_1.mapDebugCheckpoint)(this.checkpointConfig, this.channels, this.streamKeys, this.checkpointMetadata, Object.values(this.tasks), this.checkpointPendingWrites, this.prevCheckpointConfig, this.outputKeys), "checkpoints")));
        }
        if (Object.values(this.tasks).length === 0) {
            this.status = "done";
            return false;
        }
        // if there are pending writes from a previous loop, apply them
        if (this.skipDoneTasks && this.checkpointPendingWrites.length > 0) {
            for (const [tid, k, v] of this.checkpointPendingWrites){
                if (k === constants_js_1.ERROR || k === constants_js_1.INTERRUPT || k === constants_js_1.RESUME) {
                    continue;
                }
                const task = Object.values(this.tasks).find((t)=>t.id === tid);
                if (task) {
                    task.writes.push([
                        k,
                        v
                    ]);
                }
            }
            for (const task of Object.values(this.tasks)){
                if (task.writes.length > 0) {
                    this._outputWrites(task.id, task.writes, true);
                }
            }
        }
        // if all tasks have finished, re-tick
        if (Object.values(this.tasks).every((task)=>task.writes.length > 0)) {
            return this.tick({
                inputKeys
            });
        }
        // Before execution, check if we should interrupt
        if ((0, algo_js_1.shouldInterrupt)(this.checkpoint, this.interruptBefore, Object.values(this.tasks))) {
            this.status = "interrupt_before";
            throw new errors_js_1.GraphInterrupt();
        }
        // Produce debug output
        const debugOutput = await (0, utils_js_1.gatherIterator)((0, utils_js_1.prefixGenerator)((0, debug_js_1.mapDebugTasks)(Object.values(this.tasks)), "tasks"));
        this._emit(debugOutput);
        return true;
    }
    async finishAndHandleError(error) {
        // persist current checkpoint and writes
        if (this.durability === "exit" && // if it's a top graph
        (!this.isNested || // or a nested graph with error or interrupt
        typeof error !== "undefined" || // or a nested graph with checkpointer: true
        this.checkpointNamespace.every((part)=>!part.includes(constants_js_1.CHECKPOINT_NAMESPACE_END)))) {
            this._putCheckpoint(this.checkpointMetadata);
            this._flushPendingWrites();
        }
        const suppress = this._suppressInterrupt(error);
        if (suppress || error === undefined) {
            this.output = (0, io_js_1.readChannels)(this.channels, this.outputKeys);
        }
        if (suppress) {
            // emit one last "values" event, with pending writes applied
            if (this.tasks !== undefined && this.checkpointPendingWrites.length > 0 && Object.values(this.tasks).some((task)=>task.writes.length > 0)) {
                (0, algo_js_1._applyWrites)(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
                this._emit((0, utils_js_1.gatherIteratorSync)((0, utils_js_1.prefixGenerator)((0, io_js_1.mapOutputValues)(this.outputKeys, Object.values(this.tasks).flatMap((t)=>t.writes), this.channels), "values")));
            }
            // Emit INTERRUPT event
            if ((0, errors_js_1.isGraphInterrupt)(error) && !error.interrupts.length) {
                this._emit([
                    [
                        "updates",
                        {
                            [constants_js_1.INTERRUPT]: []
                        }
                    ],
                    [
                        "values",
                        {
                            [constants_js_1.INTERRUPT]: []
                        }
                    ]
                ]);
            }
        }
        return suppress;
    }
    async acceptPush(task, writeIdx, call) {
        if (this.interruptAfter?.length > 0 && (0, algo_js_1.shouldInterrupt)(this.checkpoint, this.interruptAfter, [
            task
        ])) {
            this.toInterrupt.push(task);
            return;
        }
        const pushed = (0, algo_js_1._prepareSingleTask)([
            constants_js_1.PUSH,
            task.path ?? [],
            writeIdx,
            task.id,
            call
        ], this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, task.config ?? {}, true, {
            step: this.step,
            checkpointer: this.checkpointer,
            manager: this.manager,
            store: this.store,
            stream: this.stream
        });
        if (!pushed) return;
        if (this.interruptBefore?.length > 0 && (0, algo_js_1.shouldInterrupt)(this.checkpoint, this.interruptBefore, [
            pushed
        ])) {
            this.toInterrupt.push(pushed);
            return;
        }
        this._emit((0, utils_js_1.gatherIteratorSync)((0, utils_js_1.prefixGenerator)((0, debug_js_1.mapDebugTasks)([
            pushed
        ]), "tasks")));
        if (this.debug) (0, debug_js_1.printStepTasks)(this.step, [
            pushed
        ]);
        this.tasks[pushed.id] = pushed;
        if (this.skipDoneTasks) this._matchWrites({
            [pushed.id]: pushed
        });
        const tasks = await this._matchCachedWrites();
        for (const { task } of tasks){
            this._outputWrites(task.id, task.writes, true);
        }
        return pushed;
    }
    _suppressInterrupt(e) {
        return (0, errors_js_1.isGraphInterrupt)(e) && !this.isNested;
    }
    async _first(inputKeys) {
        /*
         * Resuming from previous checkpoint requires
         * - finding a previous checkpoint
         * - receiving null input (outer graph) or RESUMING flag (subgraph)
         */ const { configurable } = this.config;
        // take resume value from parent
        const scratchpad = configurable?.[constants_js_1.CONFIG_KEY_SCRATCHPAD];
        if (scratchpad && scratchpad.nullResume !== undefined) {
            this.putWrites(constants_js_1.NULL_TASK_ID, [
                [
                    constants_js_1.RESUME,
                    scratchpad.nullResume
                ]
            ]);
        }
        // map command to writes
        if ((0, constants_js_1.isCommand)(this.input)) {
            const hasResume = this.input.resume != null;
            if (this.input.resume != null && typeof this.input.resume === "object" && Object.keys(this.input.resume).every(hash_js_1.isXXH3)) {
                this.config.configurable ??= {};
                this.config.configurable[constants_js_1.CONFIG_KEY_RESUME_MAP] = this.input.resume;
            }
            if (hasResume && this.checkpointer == null) {
                throw new Error("Cannot use Command(resume=...) without checkpointer");
            }
            const writes = {};
            // group writes by task id
            for (const [tid, key, value] of (0, io_js_1.mapCommand)(this.input, this.checkpointPendingWrites)){
                writes[tid] ??= [];
                writes[tid].push([
                    key,
                    value
                ]);
            }
            if (Object.keys(writes).length === 0) {
                throw new errors_js_1.EmptyInputError("Received empty Command input");
            }
            // save writes
            for (const [tid, ws] of Object.entries(writes)){
                this.putWrites(tid, ws);
            }
        }
        // apply null writes
        const nullWrites = (this.checkpointPendingWrites ?? []).filter((w)=>w[0] === constants_js_1.NULL_TASK_ID).map((w)=>w.slice(1));
        if (nullWrites.length > 0) {
            (0, algo_js_1._applyWrites)(this.checkpoint, this.channels, [
                {
                    name: constants_js_1.INPUT,
                    writes: nullWrites,
                    triggers: []
                }
            ], this.checkpointerGetNextVersion, this.triggerToNodes);
        }
        const isCommandUpdateOrGoto = (0, constants_js_1.isCommand)(this.input) && nullWrites.length > 0;
        if (this.isResuming || isCommandUpdateOrGoto) {
            for(const channelName in this.channels){
                if (!Object.prototype.hasOwnProperty.call(this.channels, channelName)) continue;
                if (this.checkpoint.channel_versions[channelName] !== undefined) {
                    const version = this.checkpoint.channel_versions[channelName];
                    this.checkpoint.versions_seen[constants_js_1.INTERRUPT] = {
                        ...this.checkpoint.versions_seen[constants_js_1.INTERRUPT],
                        [channelName]: version
                    };
                }
            }
            // produce values output
            const valuesOutput = await (0, utils_js_1.gatherIterator)((0, utils_js_1.prefixGenerator)((0, io_js_1.mapOutputValues)(this.outputKeys, true, this.channels), "values"));
            this._emit(valuesOutput);
        }
        if (this.isResuming) {
            this.input = INPUT_RESUMING;
        } else if (isCommandUpdateOrGoto) {
            // we need to create a new checkpoint for Command(update=...) or Command(goto=...)
            // in case the result of Command(goto=...) is an interrupt.
            // If not done, the checkpoint containing the interrupt will be lost.
            await this._putCheckpoint({
                source: "input"
            });
            this.input = INPUT_DONE;
        } else {
            // map inputs to channel updates
            const inputWrites = await (0, utils_js_1.gatherIterator)((0, io_js_1.mapInput)(inputKeys, this.input));
            if (inputWrites.length > 0) {
                const discardTasks = (0, algo_js_1._prepareNextTasks)(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, {
                    step: this.step
                });
                (0, algo_js_1._applyWrites)(this.checkpoint, this.channels, Object.values(discardTasks).concat([
                    {
                        name: constants_js_1.INPUT,
                        writes: inputWrites,
                        triggers: []
                    }
                ]), this.checkpointerGetNextVersion, this.triggerToNodes);
                // save input checkpoint
                await this._putCheckpoint({
                    source: "input"
                });
                this.input = INPUT_DONE;
            } else if (!(constants_js_1.CONFIG_KEY_RESUMING in (this.config.configurable ?? {}))) {
                throw new errors_js_1.EmptyInputError(`Received no input writes for ${JSON.stringify(inputKeys, null, 2)}`);
            } else {
                // done with input
                this.input = INPUT_DONE;
            }
        }
        if (!this.isNested) {
            this.config = (0, index_js_1.patchConfigurable)(this.config, {
                [constants_js_1.CONFIG_KEY_RESUMING]: this.isResuming
            });
        }
    }
    _emit(values) {
        for (const [mode, payload] of values){
            if (this.stream.modes.has(mode)) {
                this.stream.push([
                    this.checkpointNamespace,
                    mode,
                    payload
                ]);
            }
            // debug mode is a "checkpoints" or "tasks" wrapped in an object
            // TODO: consider deprecating this in 1.x
            if ((mode === "checkpoints" || mode === "tasks") && this.stream.modes.has("debug")) {
                const step = mode === "checkpoints" ? this.step - 1 : this.step;
                const timestamp = new Date().toISOString();
                const type = (()=>{
                    if (mode === "checkpoints") {
                        return "checkpoint";
                    } else if (typeof payload === "object" && payload != null && "result" in payload) {
                        return "task_result";
                    } else {
                        return "task";
                    }
                })();
                this.stream.push([
                    this.checkpointNamespace,
                    "debug",
                    {
                        step,
                        type,
                        timestamp,
                        payload
                    }
                ]);
            }
        }
    }
    _putCheckpoint(inputMetadata) {
        const exiting = this.checkpointMetadata === inputMetadata;
        const doCheckpoint = this.checkpointer != null && (this.durability !== "exit" || exiting);
        const storeCheckpoint = (checkpoint)=>{
            // store the previous checkpoint config for debug events
            this.prevCheckpointConfig = this.checkpointConfig?.configurable?.checkpoint_id ? this.checkpointConfig : undefined;
            // child graphs keep at most one checkpoint per parent checkpoint
            // this is achieved by writing child checkpoints as progress is made
            // (so that error recovery / resuming from interrupt don't lose work)
            // but doing so always with an id equal to that of the parent checkpoint
            this.checkpointConfig = (0, index_js_1.patchConfigurable)(this.checkpointConfig, {
                [constants_js_1.CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? ""
            });
            const channelVersions = {
                ...this.checkpoint.channel_versions
            };
            const newVersions = (0, index_js_1.getNewChannelVersions)(this.checkpointPreviousVersions, channelVersions);
            this.checkpointPreviousVersions = channelVersions;
            // save it, without blocking
            // if there's a previous checkpoint save in progress, wait for it
            // ensuring checkpointers receive checkpoints in order
            void this._checkpointerPutAfterPrevious({
                config: {
                    ...this.checkpointConfig
                },
                checkpoint: (0, langgraph_checkpoint_1.copyCheckpoint)(checkpoint),
                metadata: {
                    ...this.checkpointMetadata
                },
                newVersions
            });
            this.checkpointConfig = {
                ...this.checkpointConfig,
                configurable: {
                    ...this.checkpointConfig.configurable,
                    checkpoint_id: this.checkpoint.id
                }
            };
        };
        if (!exiting) {
            this.checkpointMetadata = {
                ...inputMetadata,
                step: this.step,
                parents: this.config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINT_MAP] ?? {}
            };
        }
        // create new checkpoint
        this.checkpoint = (0, base_js_1.createCheckpoint)(this.checkpoint, doCheckpoint ? this.channels : undefined, this.step, exiting ? {
            id: this.checkpoint.id
        } : undefined);
        // Bail if no checkpointer
        if (doCheckpoint) storeCheckpoint(this.checkpoint);
        if (!exiting) {
            // increment step
            this.step += 1;
        }
    }
    _flushPendingWrites() {
        if (this.checkpointer == null) return;
        if (this.checkpointPendingWrites.length === 0) return;
        // patch config
        const config = (0, index_js_1.patchConfigurable)(this.checkpointConfig, {
            [constants_js_1.CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? "",
            [constants_js_1.CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id
        });
        // group writes by task id
        const byTask = {};
        for (const [tid, key, value] of this.checkpointPendingWrites){
            byTask[tid] ??= [];
            byTask[tid].push([
                key,
                value
            ]);
        }
        // submit writes to checkpointer
        for (const [tid, ws] of Object.entries(byTask)){
            this.checkpointerPromises.push(this.checkpointer.putWrites(config, ws, tid));
        }
    }
    _matchWrites(tasks) {
        for (const [tid, k, v] of this.checkpointPendingWrites){
            if (k === constants_js_1.ERROR || k === constants_js_1.INTERRUPT || k === constants_js_1.RESUME) {
                continue;
            }
            const task = Object.values(tasks).find((t)=>t.id === tid);
            if (task) {
                task.writes.push([
                    k,
                    v
                ]);
            }
        }
        for (const task of Object.values(tasks)){
            if (task.writes.length > 0) {
                this._outputWrites(task.id, task.writes, true);
            }
        }
    }
}
exports.PregelLoop = PregelLoop; //# sourceMappingURL=loop.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/messages.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.StreamMessagesHandler = void 0;
const base_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/callbacks/base.cjs [app-route] (ecmascript)");
const messages_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/messages.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
function isChatGenerationChunk(x) {
    return (0, messages_1.isBaseMessage)(x?.message);
}
/**
 * A callback handler that implements stream_mode=messages.
 * Collects messages from (1) chat model stream events and (2) node outputs.
 */ // TODO: Make this import and explicitly implement the
// CallbackHandlerPrefersStreaming interface once we drop support for core 0.2
class StreamMessagesHandler extends base_1.BaseCallbackHandler {
    constructor(streamFn){
        super();
        Object.defineProperty(this, "name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "StreamMessagesHandler"
        });
        Object.defineProperty(this, "streamFn", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "metadatas", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        Object.defineProperty(this, "seen", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        Object.defineProperty(this, "emittedChatModelRunIds", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        Object.defineProperty(this, "stableMessageIdMap", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        Object.defineProperty(this, "lc_prefer_streaming", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        this.streamFn = streamFn;
    }
    _emit(meta, message, runId, dedupe = false) {
        if (dedupe && message.id !== undefined && this.seen[message.id] !== undefined) {
            return;
        }
        let messageId = message.id;
        if (runId != null) {
            if ((0, messages_1.isToolMessage)(message)) {
                // Distinguish tool messages by tool call ID.
                messageId ??= `run-${runId}-tool-${message.tool_call_id}`;
            } else {
                // For instance in ChatAnthropic, the first chunk has an message ID
                // but the subsequent chunks do not. To avoid clients seeing two messages
                // we rename the message ID if it's being auto-set to `run-${runId}`
                // (see https://github.com/langchain-ai/langchainjs/pull/6646).
                if (messageId == null || messageId === `run-${runId}`) {
                    messageId = this.stableMessageIdMap[runId] ?? messageId ?? `run-${runId}`;
                }
                this.stableMessageIdMap[runId] ??= messageId;
            }
        }
        if (messageId !== message.id) {
            // eslint-disable-next-line no-param-reassign
            message.id = messageId;
            // eslint-disable-next-line no-param-reassign
            message.lc_kwargs.id = messageId;
        }
        if (message.id != null) this.seen[message.id] = message;
        this.streamFn([
            meta[0],
            "messages",
            [
                message,
                meta[1]
            ]
        ]);
    }
    handleChatModelStart(_llm, _messages, runId, _parentRunId, _extraParams, tags, metadata, name) {
        if (metadata && // Include legacy LangGraph SDK tag
        (!tags || !tags.includes(constants_js_1.TAG_NOSTREAM) && !tags.includes("nostream"))) {
            this.metadatas[runId] = [
                metadata.langgraph_checkpoint_ns.split("|"),
                {
                    tags,
                    name,
                    ...metadata
                }
            ];
        }
    }
    handleLLMNewToken(token, _idx, runId, _parentRunId, _tags, fields) {
        const chunk = fields?.chunk;
        this.emittedChatModelRunIds[runId] = true;
        if (this.metadatas[runId] !== undefined) {
            if (isChatGenerationChunk(chunk)) {
                this._emit(this.metadatas[runId], chunk.message, runId);
            } else {
                this._emit(this.metadatas[runId], new messages_1.AIMessageChunk({
                    content: token
                }), runId);
            }
        }
    }
    handleLLMEnd(output, runId) {
        // Filter out runs that we do not have metadata for
        if (this.metadatas[runId] === undefined) return;
        // In JS, non-streaming runs do not call handleLLMNewToken at the model level
        if (!this.emittedChatModelRunIds[runId]) {
            const chatGeneration = output.generations?.[0]?.[0];
            if ((0, messages_1.isBaseMessage)(chatGeneration?.message)) {
                this._emit(this.metadatas[runId], chatGeneration?.message, runId, true);
            }
            delete this.emittedChatModelRunIds[runId];
        }
        delete this.metadatas[runId];
        delete this.stableMessageIdMap[runId];
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    handleLLMError(_err, runId) {
        delete this.metadatas[runId];
    }
    handleChainStart(_chain, inputs, runId, _parentRunId, tags, metadata, _runType, name) {
        if (metadata !== undefined && name === metadata.langgraph_node && (tags === undefined || !tags.includes(constants_js_1.TAG_HIDDEN))) {
            this.metadatas[runId] = [
                metadata.langgraph_checkpoint_ns.split("|"),
                {
                    tags,
                    name,
                    ...metadata
                }
            ];
            if (typeof inputs === "object") {
                for (const value of Object.values(inputs)){
                    if (((0, messages_1.isBaseMessage)(value) || (0, messages_1.isBaseMessageChunk)(value)) && value.id !== undefined) {
                        this.seen[value.id] = value;
                    } else if (Array.isArray(value)) {
                        for (const item of value){
                            if (((0, messages_1.isBaseMessage)(item) || (0, messages_1.isBaseMessageChunk)(item)) && item.id !== undefined) {
                                this.seen[item.id] = item;
                            }
                        }
                    }
                }
            }
        }
    }
    handleChainEnd(outputs, runId) {
        const metadata = this.metadatas[runId];
        delete this.metadatas[runId];
        if (metadata !== undefined) {
            if ((0, messages_1.isBaseMessage)(outputs)) {
                this._emit(metadata, outputs, runId, true);
            } else if (Array.isArray(outputs)) {
                for (const value of outputs){
                    if ((0, messages_1.isBaseMessage)(value)) {
                        this._emit(metadata, value, runId, true);
                    }
                }
            } else if (outputs != null && typeof outputs === "object") {
                for (const value of Object.values(outputs)){
                    if ((0, messages_1.isBaseMessage)(value)) {
                        this._emit(metadata, value, runId, true);
                    } else if (Array.isArray(value)) {
                        for (const item of value){
                            if ((0, messages_1.isBaseMessage)(item)) {
                                this._emit(metadata, item, runId, true);
                            }
                        }
                    }
                }
            }
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    handleChainError(_err, runId) {
        delete this.metadatas[runId];
    }
}
exports.StreamMessagesHandler = StreamMessagesHandler; //# sourceMappingURL=messages.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/retry.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.DEFAULT_MAX_RETRIES = exports.DEFAULT_MAX_INTERVAL = exports.DEFAULT_BACKOFF_FACTOR = exports.DEFAULT_INITIAL_INTERVAL = void 0;
exports._runWithRetry = _runWithRetry;
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const config_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/config.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/index.cjs [app-route] (ecmascript)");
exports.DEFAULT_INITIAL_INTERVAL = 500;
exports.DEFAULT_BACKOFF_FACTOR = 2;
exports.DEFAULT_MAX_INTERVAL = 128000;
exports.DEFAULT_MAX_RETRIES = 3;
const DEFAULT_STATUS_NO_RETRY = [
    400,
    401,
    402,
    403,
    404,
    405,
    406,
    407,
    409
];
// eslint-disable-next-line @typescript-eslint/no-explicit-any
const DEFAULT_RETRY_ON_HANDLER = (error)=>{
    if (error.message.startsWith("Cancel") || error.message.startsWith("AbortError") || error.name === "AbortError") {
        return false;
    }
    // Thrown when interrupt is called without a checkpointer
    if (error.name === "GraphValueError") {
        return false;
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    if (error?.code === "ECONNABORTED") {
        return false;
    }
    const status = // eslint-disable-next-line @typescript-eslint/no-explicit-any
    error?.response?.status ?? error?.status;
    if (status && DEFAULT_STATUS_NO_RETRY.includes(+status)) {
        return false;
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    if (error?.error?.code === "insufficient_quota") {
        return false;
    }
    return true;
};
async function _runWithRetry(// eslint-disable-next-line @typescript-eslint/no-explicit-any
pregelTask, retryPolicy, configurable, signal) {
    const resolvedRetryPolicy = pregelTask.retry_policy ?? retryPolicy;
    let interval = resolvedRetryPolicy !== undefined ? resolvedRetryPolicy.initialInterval ?? exports.DEFAULT_INITIAL_INTERVAL : 0;
    let attempts = 0;
    let error;
    let result;
    let { config } = pregelTask;
    if (configurable) config = (0, index_js_1.patchConfigurable)(config, configurable);
    config = {
        ...config,
        signal
    };
    // eslint-disable-next-line no-constant-condition
    while(true){
        if (signal?.aborted) {
            break;
        }
        // Clear any writes from previous attempts
        pregelTask.writes.splice(0, pregelTask.writes.length);
        error = undefined;
        try {
            result = await pregelTask.proc.invoke(pregelTask.input, config);
            break;
        } catch (e) {
            error = e;
            error.pregelTaskId = pregelTask.id;
            if ((0, errors_js_1.isParentCommand)(error)) {
                const ns = config?.configurable?.checkpoint_ns;
                const cmd = error.command;
                if (cmd.graph === ns) {
                    // this command is for the current graph, handle it
                    for (const writer of pregelTask.writers){
                        await writer.invoke(cmd, config);
                    }
                    error = undefined;
                    break;
                } else if (cmd.graph === constants_js_1.Command.PARENT) {
                    // this command is for the parent graph, assign it to the parent
                    const parentNs = (0, config_js_1.getParentCheckpointNamespace)(ns);
                    error.command = new constants_js_1.Command({
                        ...error.command,
                        graph: parentNs
                    });
                }
            }
            if ((0, errors_js_1.isGraphBubbleUp)(error)) {
                break;
            }
            if (resolvedRetryPolicy === undefined) {
                break;
            }
            attempts += 1;
            // check if we should give up
            if (attempts >= (resolvedRetryPolicy.maxAttempts ?? exports.DEFAULT_MAX_RETRIES)) {
                break;
            }
            const retryOn = resolvedRetryPolicy.retryOn ?? DEFAULT_RETRY_ON_HANDLER;
            if (!retryOn(error)) {
                break;
            }
            interval = Math.min(resolvedRetryPolicy.maxInterval ?? exports.DEFAULT_MAX_INTERVAL, interval * (resolvedRetryPolicy.backoffFactor ?? exports.DEFAULT_BACKOFF_FACTOR));
            const intervalWithJitter = resolvedRetryPolicy.jitter ? Math.floor(interval + Math.random() * 1000) : interval;
            // sleep before retrying
            // eslint-disable-next-line no-promise-executor-return
            await new Promise((resolve)=>setTimeout(resolve, intervalWithJitter));
            // log the retry
            const errorName = error.name ?? // eslint-disable-next-line @typescript-eslint/no-explicit-any
            error.constructor.unminifiable_name ?? error.constructor.name;
            if (resolvedRetryPolicy?.logWarning ?? true) {
                console.log(`Retrying task "${String(pregelTask.name)}" after ${interval.toFixed(2)}ms (attempt ${attempts}) after ${errorName}: ${error}`);
            }
            // signal subgraphs to resume (if available)
            config = (0, index_js_1.patchConfigurable)(config, {
                [constants_js_1.CONFIG_KEY_RESUMING]: true
            });
        }
    }
    return {
        task: pregelTask,
        result,
        error: error,
        signalAborted: signal?.aborted
    };
} //# sourceMappingURL=retry.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/runner.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.PregelRunner = void 0;
const types_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/types.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/index.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const retry_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/retry.cjs [app-route] (ecmascript)");
const PROMISE_ADDED_SYMBOL = Symbol.for("promiseAdded");
function createPromiseBarrier() {
    const barrier = {
        next: ()=>void 0,
        wait: Promise.resolve(PROMISE_ADDED_SYMBOL)
    };
    function waitHandler(resolve) {
        barrier.next = ()=>{
            barrier.wait = new Promise(waitHandler);
            resolve(PROMISE_ADDED_SYMBOL);
        };
    }
    barrier.wait = new Promise(waitHandler);
    return barrier;
}
/**
 * Responsible for handling task execution on each tick of the {@link PregelLoop}.
 */ class PregelRunner {
    /**
     * Construct a new PregelRunner, which executes tasks from the provided PregelLoop.
     * @param loop - The PregelLoop that produces tasks for this runner to execute.
     */ constructor({ loop, nodeFinished }){
        Object.defineProperty(this, "nodeFinished", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "loop", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.loop = loop;
        this.nodeFinished = nodeFinished;
    }
    /**
     * Execute tasks from the current step of the PregelLoop.
     *
     * Note: this method does NOT call {@link PregelLoop}#tick. That must be handled externally.
     * @param options - Options for the execution.
     */ async tick(options = {}) {
        const { timeout, retryPolicy, onStepWrite, maxConcurrency } = options;
        const nodeErrors = new Set();
        let graphBubbleUp;
        const exceptionSignalController = new AbortController();
        const exceptionSignal = exceptionSignalController.signal;
        const stepTimeoutSignal = timeout ? AbortSignal.timeout(timeout) : undefined;
        // Start task execution
        const pendingTasks = Object.values(this.loop.tasks).filter((t)=>t.writes.length === 0);
        const { signals, disposeCombinedSignal } = this._initializeAbortSignals({
            exceptionSignal,
            stepTimeoutSignal,
            signal: options.signal
        });
        const taskStream = this._executeTasksWithRetry(pendingTasks, {
            signals,
            retryPolicy,
            maxConcurrency
        });
        for await (const { task, error, signalAborted } of taskStream){
            this._commit(task, error);
            if ((0, errors_js_1.isGraphInterrupt)(error)) {
                graphBubbleUp = error;
            } else if ((0, errors_js_1.isGraphBubbleUp)(error) && !(0, errors_js_1.isGraphInterrupt)(graphBubbleUp)) {
                graphBubbleUp = error;
            } else if (error && (nodeErrors.size === 0 || !signalAborted)) {
                /*
                 * The goal here is to capture the exception that causes the graph to terminate early. In
                 * theory it's possible for multiple nodes to throw, so this also handles the edge case of
                 * capturing concurrent exceptions thrown before the node saw an abort. This is checked via
                 * the signalAborted flag, which records the state of the abort signal at the time the node
                 * execution finished.
                 *
                 * There is a case however where one node throws some error causing us to trigger an abort,
                 * which then causes other concurrently executing nodes to throw their own AbortErrors. In
                 * this case we don't care about reporting the abort errors thrown by the other nodes,
                 * because they don't tell the user anything about what caused the graph execution to
                 * terminate early, so we ignore them (and any other errors that occur after the node sees
                 * an abort signal).
                 */ exceptionSignalController.abort();
                nodeErrors.add(error);
            }
        }
        disposeCombinedSignal?.();
        onStepWrite?.(this.loop.step, Object.values(this.loop.tasks).map((task)=>task.writes).flat());
        if (nodeErrors.size === 1) {
            throw Array.from(nodeErrors)[0];
        } else if (nodeErrors.size > 1) {
            throw new AggregateError(Array.from(nodeErrors), `Multiple errors occurred during superstep ${this.loop.step}. See the "errors" field of this exception for more details.`);
        }
        if ((0, errors_js_1.isGraphInterrupt)(graphBubbleUp)) {
            throw graphBubbleUp;
        }
        if ((0, errors_js_1.isGraphBubbleUp)(graphBubbleUp) && this.loop.isNested) {
            throw graphBubbleUp;
        }
    }
    /**
     * Initializes the current AbortSignals for the PregelRunner, handling the various ways that
     * AbortSignals must be chained together so that the PregelLoop can be interrupted if necessary
     * while still allowing nodes to gracefully exit.
     *
     * This method must only be called once per PregelRunner#tick. It has the side effect of updating
     * the PregelLoop#config with the new AbortSignals so they may be propagated correctly to future
     * ticks and subgraph calls.
     *
     * @param options - Options for the initialization.
     * @returns The current abort signals.
     * @internal
     */ _initializeAbortSignals({ exceptionSignal, stepTimeoutSignal, signal }) {
        const previousSignals = this.loop.config.configurable?.[constants_js_1.CONFIG_KEY_ABORT_SIGNALS] ?? {};
        // We always inherit the external abort signal from AsyncLocalStorage,
        // since that's the only way the signal is inherited by the subgraph calls.
        const externalAbortSignal = previousSignals.externalAbortSignal ?? signal;
        // inherit the step timeout signal from parent graph
        const timeoutAbortSignal = stepTimeoutSignal ?? previousSignals.timeoutAbortSignal;
        const { signal: composedAbortSignal, dispose: disposeCombinedSignal } = (0, index_js_1.combineAbortSignals)(externalAbortSignal, timeoutAbortSignal, exceptionSignal);
        const signals = {
            externalAbortSignal,
            timeoutAbortSignal,
            composedAbortSignal
        };
        this.loop.config = (0, index_js_1.patchConfigurable)(this.loop.config, {
            [constants_js_1.CONFIG_KEY_ABORT_SIGNALS]: signals
        });
        return {
            signals,
            disposeCombinedSignal
        };
    }
    /**
     * Concurrently executes tasks with the requested retry policy, yielding a {@link SettledPregelTask} for each task as it completes.
     * @param tasks - The tasks to execute.
     * @param options - Options for the execution.
     */ async *_executeTasksWithRetry(tasks, options) {
        const { retryPolicy, maxConcurrency, signals } = options ?? {};
        const barrier = createPromiseBarrier();
        const executingTasksMap = {};
        const thisCall = {
            executingTasksMap,
            barrier,
            retryPolicy,
            scheduleTask: async (task, writeIdx, call)=>this.loop.acceptPush(task, writeIdx, call)
        };
        if (signals?.composedAbortSignal?.aborted) {
            // note: don't use throwIfAborted here because it throws a DOMException,
            // which isn't consistent with how we throw on abort below.
            throw new Error("Abort");
        }
        let startedTasksCount = 0;
        let listener;
        const timeoutOrCancelSignal = (0, index_js_1.combineAbortSignals)(signals?.externalAbortSignal, signals?.timeoutAbortSignal);
        const abortPromise = timeoutOrCancelSignal.signal ? new Promise((_resolve, reject)=>{
            listener = ()=>reject(new Error("Abort"));
            timeoutOrCancelSignal.signal?.addEventListener("abort", listener, {
                once: true
            });
        }) : undefined;
        while((startedTasksCount === 0 || Object.keys(executingTasksMap).length > 0) && tasks.length){
            for(; Object.values(executingTasksMap).length < (maxConcurrency ?? tasks.length) && startedTasksCount < tasks.length; startedTasksCount += 1){
                const task = tasks[startedTasksCount];
                executingTasksMap[task.id] = (0, retry_js_1._runWithRetry)(task, retryPolicy, {
                    [constants_js_1.CONFIG_KEY_CALL]: call?.bind(thisCall, this, task)
                }, signals?.composedAbortSignal).catch((error)=>{
                    return {
                        task,
                        error,
                        signalAborted: signals?.composedAbortSignal?.aborted
                    };
                });
            }
            const settledTask = await Promise.race([
                ...Object.values(executingTasksMap),
                ...abortPromise ? [
                    abortPromise
                ] : [],
                barrier.wait
            ]);
            if (settledTask === PROMISE_ADDED_SYMBOL) {
                continue;
            }
            yield settledTask;
            if (listener != null) {
                timeoutOrCancelSignal.signal?.removeEventListener("abort", listener);
                timeoutOrCancelSignal.dispose?.();
            }
            delete executingTasksMap[settledTask.task.id];
        }
    }
    /**
     * Determines what writes to apply based on whether the task completed successfully, and what type of error occurred.
     *
     * Throws an error if the error is a {@link GraphBubbleUp} error and {@link PregelLoop}#isNested is true.
     *
     * @param task - The task to commit.
     * @param error - The error that occurred, if any.
     */ _commit(task, error) {
        if (error !== undefined) {
            if ((0, errors_js_1.isGraphInterrupt)(error)) {
                if (error.interrupts.length) {
                    const interrupts = error.interrupts.map((interrupt)=>[
                            constants_js_1.INTERRUPT,
                            interrupt
                        ]);
                    const resumes = task.writes.filter((w)=>w[0] === constants_js_1.RESUME);
                    if (resumes.length) {
                        interrupts.push(...resumes);
                    }
                    this.loop.putWrites(task.id, interrupts);
                }
            } else if ((0, errors_js_1.isGraphBubbleUp)(error) && task.writes.length) {
                this.loop.putWrites(task.id, task.writes);
            } else {
                this.loop.putWrites(task.id, [
                    [
                        constants_js_1.ERROR,
                        {
                            message: error.message,
                            name: error.name
                        }
                    ]
                ]);
            }
        } else {
            if (this.nodeFinished && (task.config?.tags == null || !task.config.tags.includes(constants_js_1.TAG_HIDDEN))) {
                this.nodeFinished(String(task.name));
            }
            if (task.writes.length === 0) {
                // Add no writes marker
                task.writes.push([
                    constants_js_1.NO_WRITES,
                    null
                ]);
            }
            // Save task writes to checkpointer
            this.loop.putWrites(task.id, task.writes);
        }
    }
}
exports.PregelRunner = PregelRunner;
async function call(runner, task, func, name, input, options = {}) {
    // Schedule PUSH tasks, collect promises
    const scratchpad = task.config?.configurable?.[constants_js_1.CONFIG_KEY_SCRATCHPAD];
    if (!scratchpad) {
        throw new Error(`BUG: No scratchpad found on task ${task.name}__${task.id}`);
    }
    const cnt = scratchpad.callCounter;
    scratchpad.callCounter += 1;
    // schedule the next task, if the callback returns one
    const wcall = new types_js_1.Call({
        func,
        name,
        input,
        cache: options.cache,
        retry: options.retry,
        callbacks: options.callbacks
    });
    const nextTask = await this.scheduleTask(task, cnt, wcall);
    if (!nextTask) return undefined;
    // Check if this task is already running
    const existingPromise = this.executingTasksMap[nextTask.id];
    if (existingPromise !== undefined) {
        // If the parent task was retried, the next task might already be running
        return existingPromise;
    }
    if (nextTask.writes.length > 0) {
        // If it already ran, return the result
        const returns = nextTask.writes.filter(([c])=>c === constants_js_1.RETURN);
        const errors = nextTask.writes.filter(([c])=>c === constants_js_1.ERROR);
        if (returns.length > 0) {
            // Task completed successfully
            if (returns.length === 1) return Promise.resolve(returns[0][1]);
            // should be unreachable
            throw new Error(`BUG: multiple returns found for task ${nextTask.name}__${nextTask.id}`);
        }
        if (errors.length > 0) {
            // Task failed
            if (errors.length === 1) {
                const errorValue = errors[0][1];
                const error = // eslint-disable-next-line no-instanceof/no-instanceof
                errorValue instanceof Error ? errorValue : new Error(String(errorValue));
                return Promise.reject(error);
            }
            // the only way this should happen is if the task executes multiple times and writes aren't cleared
            throw new Error(`BUG: multiple errors found for task ${nextTask.name}__${nextTask.id}`);
        }
        return undefined;
    } else {
        // Schedule the next task with retry
        const prom = (0, retry_js_1._runWithRetry)(nextTask, options.retry, {
            [constants_js_1.CONFIG_KEY_CALL]: call.bind(this, runner, nextTask)
        });
        this.executingTasksMap[nextTask.id] = prom;
        this.barrier.next();
        return prom.then(({ result, error })=>{
            if (error) return Promise.reject(error);
            return result;
        });
    }
} //# sourceMappingURL=runner.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/validate.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.GraphValidationError = void 0;
exports.validateGraph = validateGraph;
exports.validateKeys = validateKeys;
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const read_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/read.cjs [app-route] (ecmascript)");
class GraphValidationError extends Error {
    constructor(message){
        super(message);
        this.name = "GraphValidationError";
    }
}
exports.GraphValidationError = GraphValidationError;
function validateGraph({ nodes, channels, inputChannels, outputChannels, streamChannels, interruptAfterNodes, interruptBeforeNodes }) {
    if (!channels) {
        throw new GraphValidationError("Channels not provided");
    }
    const subscribedChannels = new Set();
    const allOutputChannels = new Set();
    for (const [name, node] of Object.entries(nodes)){
        if (name === constants_js_1.INTERRUPT) {
            throw new GraphValidationError(`"Node name ${constants_js_1.INTERRUPT} is reserved"`);
        }
        if (node.constructor === read_js_1.PregelNode) {
            node.triggers.forEach((trigger)=>subscribedChannels.add(trigger));
        } else {
            throw new GraphValidationError(`Invalid node type ${typeof node}, expected PregelNode`);
        }
    }
    // side effect: update channels
    for (const chan of subscribedChannels){
        if (!(chan in channels)) {
            throw new GraphValidationError(`Subscribed channel '${String(chan)}' not in channels`);
        }
    }
    if (!Array.isArray(inputChannels)) {
        if (!subscribedChannels.has(inputChannels)) {
            throw new GraphValidationError(`Input channel ${String(inputChannels)} is not subscribed to by any node`);
        }
    } else {
        if (inputChannels.every((channel)=>!subscribedChannels.has(channel))) {
            throw new GraphValidationError(`None of the input channels ${inputChannels} are subscribed to by any node`);
        }
    }
    if (!Array.isArray(outputChannels)) {
        allOutputChannels.add(outputChannels);
    } else {
        outputChannels.forEach((chan)=>allOutputChannels.add(chan));
    }
    if (streamChannels && !Array.isArray(streamChannels)) {
        allOutputChannels.add(streamChannels);
    } else if (Array.isArray(streamChannels)) {
        streamChannels.forEach((chan)=>allOutputChannels.add(chan));
    }
    for (const chan of allOutputChannels){
        if (!(chan in channels)) {
            throw new GraphValidationError(`Output channel '${String(chan)}' not in channels`);
        }
    }
    // validate interrupt before/after
    if (interruptAfterNodes && interruptAfterNodes !== "*") {
        for (const node of interruptAfterNodes){
            if (!(node in nodes)) {
                throw new GraphValidationError(`Node ${String(node)} not in nodes`);
            }
        }
    }
    if (interruptBeforeNodes && interruptBeforeNodes !== "*") {
        for (const node of interruptBeforeNodes){
            if (!(node in nodes)) {
                throw new GraphValidationError(`Node ${String(node)} not in nodes`);
            }
        }
    }
}
function validateKeys(keys, channels) {
    if (Array.isArray(keys)) {
        for (const key of keys){
            if (!(key in channels)) {
                throw new Error(`Key ${String(key)} not found in channels`);
            }
        }
    } else {
        if (!(keys in channels)) {
            throw new Error(`Key ${String(keys)} not found in channels`);
        }
    }
} //# sourceMappingURL=validate.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/topic.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Topic = void 0;
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
/**
 * @internal
 */ class Topic extends base_js_1.BaseChannel {
    constructor(fields){
        super();
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "Topic"
        });
        Object.defineProperty(this, "unique", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        Object.defineProperty(this, "accumulate", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        Object.defineProperty(this, "seen", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "values", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.unique = fields?.unique ?? this.unique;
        this.accumulate = fields?.accumulate ?? this.accumulate;
        // State
        this.seen = new Set();
        this.values = [];
    }
    fromCheckpoint(checkpoint) {
        const empty = new Topic({
            unique: this.unique,
            accumulate: this.accumulate
        });
        if (typeof checkpoint !== "undefined") {
            empty.seen = new Set(checkpoint[0]);
            // eslint-disable-next-line prefer-destructuring
            empty.values = checkpoint[1];
        }
        return empty;
    }
    update(values) {
        let updated = false;
        if (!this.accumulate) {
            updated = this.values.length > 0;
            this.values = [];
        }
        const flatValues = values.flat();
        if (flatValues.length > 0) {
            if (this.unique) {
                for (const value of flatValues){
                    if (!this.seen.has(value)) {
                        updated = true;
                        this.seen.add(value);
                        this.values.push(value);
                    }
                }
            } else {
                updated = true;
                this.values.push(...flatValues);
            }
        }
        return updated;
    }
    get() {
        if (this.values.length === 0) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.values;
    }
    checkpoint() {
        return [
            [
                ...this.seen
            ],
            this.values
        ];
    }
    isAvailable() {
        return this.values.length !== 0;
    }
}
exports.Topic = Topic; //# sourceMappingURL=topic.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/pregel/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.Pregel = exports.Channel = void 0;
/* eslint-disable no-param-reassign */ const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const langgraph_checkpoint_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph-checkpoint/index.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const algo_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/algo.cjs [app-route] (ecmascript)");
const debug_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/debug.cjs [app-route] (ecmascript)");
const io_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/io.cjs [app-route] (ecmascript)");
const loop_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/loop.cjs [app-route] (ecmascript)");
const messages_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/messages.cjs [app-route] (ecmascript)");
const read_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/read.cjs [app-route] (ecmascript)");
const runner_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/runner.cjs [app-route] (ecmascript)");
const stream_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/stream.cjs [app-route] (ecmascript)");
const config_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/config.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/index.cjs [app-route] (ecmascript)");
const subgraph_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.cjs [app-route] (ecmascript)");
const validate_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/validate.cjs [app-route] (ecmascript)");
const write_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)");
const topic_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/topic.cjs [app-route] (ecmascript)");
/**
 * Utility class for working with channels in the Pregel system.
 * Provides static methods for subscribing to channels and writing to them.
 *
 * Channels are the communication pathways between nodes in a Pregel graph.
 * They enable message passing and state updates between different parts of the graph.
 */ class Channel {
    static subscribeTo(channels, options) {
        const { key, tags } = {
            key: undefined,
            tags: undefined,
            ...options ?? {}
        };
        if (Array.isArray(channels) && key !== undefined) {
            throw new Error("Can't specify a key when subscribing to multiple channels");
        }
        let channelMappingOrArray;
        if (typeof channels === "string") {
            if (key) {
                channelMappingOrArray = {
                    [key]: channels
                };
            } else {
                channelMappingOrArray = [
                    channels
                ];
            }
        } else {
            channelMappingOrArray = Object.fromEntries(channels.map((chan)=>[
                    chan,
                    chan
                ]));
        }
        const triggers = Array.isArray(channels) ? channels : [
            channels
        ];
        return new read_js_1.PregelNode({
            channels: channelMappingOrArray,
            triggers,
            tags
        });
    }
    /**
     * Creates a ChannelWrite that specifies how to write values to channels.
     * This is used to define how nodes send output to channels.
     *
     * @example
     * ```typescript
     * // Write to multiple channels
     * const write = Channel.writeTo(["output", "state"]);
     *
     * // Write with specific values
     * const write = Channel.writeTo(["output"], {
     *   state: "completed",
     *   result: calculateResult()
     * });
     *
     * // Write with a transformation function
     * const write = Channel.writeTo(["output"], {
     *   result: (x) => processResult(x)
     * });
     * ```
     *
     * @param channels - Array of channel names to write to
     * @param writes - Optional map of channel names to values or transformations
     * @returns A ChannelWrite object that can be used to write to the specified channels
     */ static writeTo(channels, writes) {
        const channelWriteEntries = [];
        for (const channel of channels){
            channelWriteEntries.push({
                channel,
                value: write_js_1.PASSTHROUGH,
                skipNone: false
            });
        }
        for (const [key, value] of Object.entries(writes ?? {})){
            if (runnables_1.Runnable.isRunnable(value) || typeof value === "function") {
                channelWriteEntries.push({
                    channel: key,
                    value: write_js_1.PASSTHROUGH,
                    skipNone: true,
                    mapper: (0, runnables_1._coerceToRunnable)(value)
                });
            } else {
                channelWriteEntries.push({
                    channel: key,
                    value,
                    skipNone: false
                });
            }
        }
        return new write_js_1.ChannelWrite(channelWriteEntries);
    }
}
exports.Channel = Channel;
// This is a workaround to allow Pregel to override `invoke` / `stream` and `withConfig`
// without having to adhere to the types in the `Runnable` class (thanks to `any`).
// Alternatively we could mark those methods with @ts-ignore / @ts-expect-error,
// but these do not get carried over when building via `tsc`.
class PartialRunnable extends runnables_1.Runnable {
    constructor(){
        super(...arguments);
        Object.defineProperty(this, "lc_namespace", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: [
                "langgraph",
                "pregel"
            ]
        });
    }
    invoke(_input, _options) {
        throw new Error("Not implemented");
    }
    // Overriden by `Pregel`
    withConfig(_config) {
        return super.withConfig(_config);
    }
    // Overriden by `Pregel`
    stream(input, options) {
        return super.stream(input, options);
    }
}
/**
 * The Pregel class is the core runtime engine of LangGraph, implementing a message-passing graph computation model
 * inspired by [Google's Pregel system](https://research.google/pubs/pregel-a-system-for-large-scale-graph-processing/).
 * It provides the foundation for building reliable, controllable agent workflows that can evolve state over time.
 *
 * Key features:
 * - Message passing between nodes in discrete "supersteps"
 * - Built-in persistence layer through checkpointers
 * - First-class streaming support for values, updates, and events
 * - Human-in-the-loop capabilities via interrupts
 * - Support for parallel node execution within supersteps
 *
 * The Pregel class is not intended to be instantiated directly by consumers. Instead, use the following higher-level APIs:
 * - {@link StateGraph}: The main graph class for building agent workflows
 *   - Compiling a {@link StateGraph} will return a {@link CompiledGraph} instance, which extends `Pregel`
 * - Functional API: A declarative approach using tasks and entrypoints
 *   - A `Pregel` instance is returned by the {@link entrypoint} function
 *
 * @example
 * ```typescript
 * // Using StateGraph API
 * const graph = new StateGraph(annotation)
 *   .addNode("nodeA", myNodeFunction)
 *   .addEdge("nodeA", "nodeB")
 *   .compile();
 *
 * // The compiled graph is a Pregel instance
 * const result = await graph.invoke(input);
 * ```
 *
 * @example
 * ```typescript
 * // Using Functional API
 * import { task, entrypoint } from "@langchain/langgraph";
 * import { MemorySaver } from "@langchain/langgraph-checkpoint";
 *
 * // Define tasks that can be composed
 * const addOne = task("add", async (x: number) => x + 1);
 *
 * // Create a workflow using the entrypoint function
 * const workflow = entrypoint({
 *   name: "workflow",
 *   checkpointer: new MemorySaver()
 * }, async (numbers: number[]) => {
 *   // Tasks can be run in parallel
 *   const results = await Promise.all(numbers.map(n => addOne(n)));
 *   return results;
 * });
 *
 * // The workflow is a Pregel instance
 * const result = await workflow.invoke([1, 2, 3]); // Returns [2, 3, 4]
 * ```
 *
 * @typeParam Nodes - Mapping of node names to their {@link PregelNode} implementations
 * @typeParam Channels - Mapping of channel names to their {@link BaseChannel} or {@link ManagedValueSpec} implementations
 * @typeParam ContextType - Type of context that can be passed to the graph
 * @typeParam InputType - Type of input values accepted by the graph
 * @typeParam OutputType - Type of output values produced by the graph
 */ class Pregel extends PartialRunnable {
    /**
     * Name of the class when serialized
     * @internal
     */ static lc_name() {
        return "LangGraph";
    }
    /**
     * Constructor for Pregel - meant for internal use only.
     *
     * @internal
     */ constructor(fields){
        super(fields);
        /** @internal LangChain namespace for serialization necessary because Pregel extends Runnable */ Object.defineProperty(this, "lc_namespace", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: [
                "langgraph",
                "pregel"
            ]
        });
        /** @internal Flag indicating this is a Pregel instance - necessary for serialization */ Object.defineProperty(this, "lg_is_pregel", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        /** The nodes in the graph, mapping node names to their PregelNode instances */ Object.defineProperty(this, "nodes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** The channels in the graph, mapping channel names to their BaseChannel or ManagedValueSpec instances */ Object.defineProperty(this, "channels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * The input channels for the graph. These channels receive the initial input when the graph is invoked.
         * Can be a single channel key or an array of channel keys.
         */ Object.defineProperty(this, "inputChannels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * The output channels for the graph. These channels contain the final output when the graph completes.
         * Can be a single channel key or an array of channel keys.
         */ Object.defineProperty(this, "outputChannels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** Whether to automatically validate the graph structure when it is compiled. Defaults to true. */ Object.defineProperty(this, "autoValidate", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        /**
         * The streaming modes enabled for this graph. Defaults to ["values"].
         * Supported modes:
         * - "values": Streams the full state after each step
         * - "updates": Streams state updates after each step
         * - "messages": Streams messages from within nodes
         * - "custom": Streams custom events from within nodes
         * - "debug": Streams events related to the execution of the graph - useful for tracing & debugging graph execution
         */ Object.defineProperty(this, "streamMode", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: [
                "values"
            ]
        });
        /**
         * Optional channels to stream. If not specified, all channels will be streamed.
         * Can be a single channel key or an array of channel keys.
         */ Object.defineProperty(this, "streamChannels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Optional array of node names or "all" to interrupt after executing these nodes.
         * Used for implementing human-in-the-loop workflows.
         */ Object.defineProperty(this, "interruptAfter", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Optional array of node names or "all" to interrupt before executing these nodes.
         * Used for implementing human-in-the-loop workflows.
         */ Object.defineProperty(this, "interruptBefore", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** Optional timeout in milliseconds for the execution of each superstep */ Object.defineProperty(this, "stepTimeout", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** Whether to enable debug logging. Defaults to false. */ Object.defineProperty(this, "debug", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        /**
         * Optional checkpointer for persisting graph state.
         * When provided, saves a checkpoint of the graph state at every superstep.
         * When false or undefined, checkpointing is disabled, and the graph will not be able to save or restore state.
         */ Object.defineProperty(this, "checkpointer", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** Optional retry policy for handling failures in node execution */ Object.defineProperty(this, "retryPolicy", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** The default configuration for graph execution, can be overridden on a per-invocation basis */ Object.defineProperty(this, "config", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Optional long-term memory store for the graph, allows for persistence & retrieval of data across threads
         */ Object.defineProperty(this, "store", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "triggerToNodes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        /**
         * Optional cache for the graph, useful for caching tasks.
         */ Object.defineProperty(this, "cache", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        let { streamMode } = fields;
        if (streamMode != null && !Array.isArray(streamMode)) {
            streamMode = [
                streamMode
            ];
        }
        this.nodes = fields.nodes;
        this.channels = fields.channels;
        if (constants_js_1.TASKS in this.channels && "lc_graph_name" in this.channels[constants_js_1.TASKS] && this.channels[constants_js_1.TASKS].lc_graph_name !== "Topic") {
            throw new Error(`Channel '${constants_js_1.TASKS}' is reserved and cannot be used in the graph.`);
        } else {
            this.channels[constants_js_1.TASKS] = new topic_js_1.Topic({
                accumulate: false
            });
        }
        this.autoValidate = fields.autoValidate ?? this.autoValidate;
        this.streamMode = streamMode ?? this.streamMode;
        this.inputChannels = fields.inputChannels;
        this.outputChannels = fields.outputChannels;
        this.streamChannels = fields.streamChannels ?? this.streamChannels;
        this.interruptAfter = fields.interruptAfter;
        this.interruptBefore = fields.interruptBefore;
        this.stepTimeout = fields.stepTimeout ?? this.stepTimeout;
        this.debug = fields.debug ?? this.debug;
        this.checkpointer = fields.checkpointer;
        this.retryPolicy = fields.retryPolicy;
        this.config = fields.config;
        this.store = fields.store;
        this.cache = fields.cache;
        this.name = fields.name;
        if (this.autoValidate) {
            this.validate();
        }
    }
    /**
     * Creates a new instance of the Pregel graph with updated configuration.
     * This method follows the immutable pattern - instead of modifying the current instance,
     * it returns a new instance with the merged configuration.
     *
     * @example
     * ```typescript
     * // Create a new instance with debug enabled
     * const debugGraph = graph.withConfig({ debug: true });
     *
     * // Create a new instance with a specific thread ID
     * const threadGraph = graph.withConfig({
     *   configurable: { thread_id: "123" }
     * });
     * ```
     *
     * @param config - The configuration to merge with the current configuration
     * @returns A new Pregel instance with the merged configuration
     */ withConfig(config) {
        const mergedConfig = (0, runnables_1.mergeConfigs)(this.config, config);
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        return new this.constructor({
            ...this,
            config: mergedConfig
        });
    }
    /**
     * Validates the graph structure to ensure it is well-formed.
     * Checks for:
     * - No orphaned nodes
     * - Valid input/output channel configurations
     * - Valid interrupt configurations
     *
     * @returns this - The Pregel instance for method chaining
     * @throws {GraphValidationError} If the graph structure is invalid
     */ validate() {
        (0, validate_js_1.validateGraph)({
            nodes: this.nodes,
            channels: this.channels,
            outputChannels: this.outputChannels,
            inputChannels: this.inputChannels,
            streamChannels: this.streamChannels,
            interruptAfterNodes: this.interruptAfter,
            interruptBeforeNodes: this.interruptBefore
        });
        for (const [name, node] of Object.entries(this.nodes)){
            for (const trigger of node.triggers){
                this.triggerToNodes[trigger] ??= [];
                this.triggerToNodes[trigger].push(name);
            }
        }
        return this;
    }
    /**
     * Gets a list of all channels that should be streamed.
     * If streamChannels is specified, returns those channels.
     * Otherwise, returns all channels in the graph.
     *
     * @returns Array of channel keys to stream
     */ get streamChannelsList() {
        if (Array.isArray(this.streamChannels)) {
            return this.streamChannels;
        } else if (this.streamChannels) {
            return [
                this.streamChannels
            ];
        } else {
            return Object.keys(this.channels);
        }
    }
    /**
     * Gets the channels to stream in their original format.
     * If streamChannels is specified, returns it as-is (either single key or array).
     * Otherwise, returns all channels in the graph as an array.
     *
     * @returns Channel keys to stream, either as a single key or array
     */ get streamChannelsAsIs() {
        if (this.streamChannels) {
            return this.streamChannels;
        } else {
            return Object.keys(this.channels);
        }
    }
    /**
     * Gets a drawable representation of the graph structure.
     * This is an async version of getGraph() and is the preferred method to use.
     *
     * @param config - Configuration for generating the graph visualization
     * @returns A representation of the graph that can be visualized
     */ async getGraphAsync(config) {
        return this.getGraph(config);
    }
    /**
     * Gets all subgraphs within this graph.
     * A subgraph is a Pregel instance that is nested within a node of this graph.
     *
     * @deprecated Use getSubgraphsAsync instead. The async method will become the default in the next minor release.
     * @param namespace - Optional namespace to filter subgraphs
     * @param recurse - Whether to recursively get subgraphs of subgraphs
     * @returns Generator yielding tuples of [name, subgraph]
     */ *getSubgraphs(namespace, recurse) {
        for (const [name, node] of Object.entries(this.nodes)){
            // filter by prefix
            if (namespace !== undefined) {
                if (!namespace.startsWith(name)) {
                    continue;
                }
            }
            const candidates = node.subgraphs?.length ? node.subgraphs : [
                node.bound
            ];
            for (const candidate of candidates){
                const graph = (0, subgraph_js_1.findSubgraphPregel)(candidate);
                if (graph !== undefined) {
                    if (name === namespace) {
                        yield [
                            name,
                            graph
                        ];
                        return;
                    }
                    if (namespace === undefined) {
                        yield [
                            name,
                            graph
                        ];
                    }
                    if (recurse) {
                        let newNamespace = namespace;
                        if (namespace !== undefined) {
                            newNamespace = namespace.slice(name.length + 1);
                        }
                        for (const [subgraphName, subgraph] of graph.getSubgraphs(newNamespace, recurse)){
                            yield [
                                `${name}${constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR}${subgraphName}`,
                                subgraph
                            ];
                        }
                    }
                }
            }
        }
    }
    /**
     * Gets all subgraphs within this graph asynchronously.
     * A subgraph is a Pregel instance that is nested within a node of this graph.
     *
     * @param namespace - Optional namespace to filter subgraphs
     * @param recurse - Whether to recursively get subgraphs of subgraphs
     * @returns AsyncGenerator yielding tuples of [name, subgraph]
     */ async *getSubgraphsAsync(namespace, recurse) {
        yield* this.getSubgraphs(namespace, recurse);
    }
    /**
     * Prepares a state snapshot from saved checkpoint data.
     * This is an internal method used by getState and getStateHistory.
     *
     * @param config - Configuration for preparing the snapshot
     * @param saved - Optional saved checkpoint data
     * @param subgraphCheckpointer - Optional checkpointer for subgraphs
     * @param applyPendingWrites - Whether to apply pending writes to tasks and then to channels
     * @returns A snapshot of the graph state
     * @internal
     */ async _prepareStateSnapshot({ config, saved, subgraphCheckpointer, applyPendingWrites = false }) {
        if (saved === undefined) {
            return {
                values: {},
                next: [],
                config,
                tasks: []
            };
        }
        // Create all channels
        const channels = (0, base_js_1.emptyChannels)(this.channels, saved.checkpoint);
        // Apply null writes first (from NULL_TASK_ID)
        if (saved.pendingWrites?.length) {
            const nullWrites = saved.pendingWrites.filter(([taskId, _])=>taskId === constants_js_1.NULL_TASK_ID).map(([_, channel, value])=>[
                    String(channel),
                    value
                ]);
            if (nullWrites.length > 0) {
                (0, algo_js_1._applyWrites)(saved.checkpoint, channels, [
                    {
                        name: constants_js_1.INPUT,
                        writes: nullWrites,
                        triggers: []
                    }
                ], undefined, this.triggerToNodes);
            }
        }
        // Prepare next tasks
        const nextTasks = Object.values((0, algo_js_1._prepareNextTasks)(saved.checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {
            step: (saved.metadata?.step ?? -1) + 1,
            store: this.store
        }));
        // Find subgraphs
        const subgraphs = await (0, utils_js_1.gatherIterator)(this.getSubgraphsAsync());
        const parentNamespace = saved.config.configurable?.checkpoint_ns ?? "";
        const taskStates = {};
        // Prepare task states for subgraphs
        for (const task of nextTasks){
            const matchingSubgraph = subgraphs.find(([name])=>name === task.name);
            if (!matchingSubgraph) {
                continue;
            }
            // assemble checkpoint_ns for this task
            let taskNs = `${String(task.name)}${constants_js_1.CHECKPOINT_NAMESPACE_END}${task.id}`;
            if (parentNamespace) {
                taskNs = `${parentNamespace}${constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR}${taskNs}`;
            }
            if (subgraphCheckpointer === undefined) {
                // set config as signal that subgraph checkpoints exist
                const config = {
                    configurable: {
                        thread_id: saved.config.configurable?.thread_id,
                        checkpoint_ns: taskNs
                    }
                };
                taskStates[task.id] = config;
            } else {
                // get the state of the subgraph
                const subgraphConfig = {
                    configurable: {
                        [constants_js_1.CONFIG_KEY_CHECKPOINTER]: subgraphCheckpointer,
                        thread_id: saved.config.configurable?.thread_id,
                        checkpoint_ns: taskNs
                    }
                };
                const pregel = matchingSubgraph[1];
                taskStates[task.id] = await pregel.getState(subgraphConfig, {
                    subgraphs: true
                });
            }
        }
        // Apply pending writes to tasks and then to channels if applyPendingWrites is true
        if (applyPendingWrites && saved.pendingWrites?.length) {
            // Map task IDs to task objects for easy lookup
            const nextTaskById = Object.fromEntries(nextTasks.map((task)=>[
                    task.id,
                    task
                ]));
            // Apply pending writes to the appropriate tasks
            for (const [taskId, channel, value] of saved.pendingWrites){
                // Skip special channels and tasks not in nextTasks
                if ([
                    constants_js_1.ERROR,
                    constants_js_1.INTERRUPT,
                    langgraph_checkpoint_1.SCHEDULED
                ].includes(channel)) {
                    continue;
                }
                if (!(taskId in nextTaskById)) {
                    continue;
                }
                // Add the write to the task
                nextTaskById[taskId].writes.push([
                    String(channel),
                    value
                ]);
            }
            // Apply writes from tasks that have writes
            const tasksWithWrites = nextTasks.filter((task)=>task.writes.length > 0);
            if (tasksWithWrites.length > 0) {
                (0, algo_js_1._applyWrites)(saved.checkpoint, channels, tasksWithWrites, undefined, this.triggerToNodes);
            }
        }
        // Preserve thread_id from the config in metadata
        let metadata = saved?.metadata;
        if (metadata && saved?.config?.configurable?.thread_id) {
            metadata = {
                ...metadata,
                thread_id: saved.config.configurable.thread_id
            };
        }
        // Filter next tasks - only include tasks without writes
        const nextList = nextTasks.filter((task)=>task.writes.length === 0).map((task)=>task.name);
        // assemble the state snapshot
        return {
            values: (0, io_js_1.readChannels)(channels, this.streamChannelsAsIs),
            next: nextList,
            tasks: (0, debug_js_1.tasksWithWrites)(nextTasks, saved?.pendingWrites ?? [], taskStates, this.streamChannelsAsIs),
            metadata,
            config: (0, index_js_1.patchCheckpointMap)(saved.config, saved.metadata),
            createdAt: saved.checkpoint.ts,
            parentConfig: saved.parentConfig
        };
    }
    /**
     * Gets the current state of the graph.
     * Requires a checkpointer to be configured.
     *
     * @param config - Configuration for retrieving the state
     * @param options - Additional options
     * @returns A snapshot of the current graph state
     * @throws {GraphValueError} If no checkpointer is configured
     */ async getState(config, options) {
        const checkpointer = config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
        if (!checkpointer) {
            throw new errors_js_1.GraphValueError("No checkpointer set");
        }
        const checkpointNamespace = config.configurable?.checkpoint_ns ?? "";
        if (checkpointNamespace !== "" && config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] === undefined) {
            // remove task_ids from checkpoint_ns
            const recastNamespace = (0, config_js_1.recastCheckpointNamespace)(checkpointNamespace);
            for await (const [name, subgraph] of this.getSubgraphsAsync(recastNamespace, true)){
                if (name === recastNamespace) {
                    return await subgraph.getState((0, utils_js_1.patchConfigurable)(config, {
                        [constants_js_1.CONFIG_KEY_CHECKPOINTER]: checkpointer
                    }), {
                        subgraphs: options?.subgraphs
                    });
                }
            }
            throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
        }
        const mergedConfig = (0, runnables_1.mergeConfigs)(this.config, config);
        const saved = await checkpointer.getTuple(config);
        const snapshot = await this._prepareStateSnapshot({
            config: mergedConfig,
            saved,
            subgraphCheckpointer: options?.subgraphs ? checkpointer : undefined,
            applyPendingWrites: !config.configurable?.checkpoint_id
        });
        return snapshot;
    }
    /**
     * Gets the history of graph states.
     * Requires a checkpointer to be configured.
     * Useful for:
     * - Debugging execution history
     * - Implementing time travel
     * - Analyzing graph behavior
     *
     * @param config - Configuration for retrieving the history
     * @param options - Options for filtering the history
     * @returns An async iterator of state snapshots
     * @throws {Error} If no checkpointer is configured
     */ async *getStateHistory(config, options) {
        const checkpointer = config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
        if (!checkpointer) {
            throw new errors_js_1.GraphValueError("No checkpointer set");
        }
        const checkpointNamespace = config.configurable?.checkpoint_ns ?? "";
        if (checkpointNamespace !== "" && config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] === undefined) {
            const recastNamespace = (0, config_js_1.recastCheckpointNamespace)(checkpointNamespace);
            // find the subgraph with the matching name
            for await (const [name, pregel] of this.getSubgraphsAsync(recastNamespace, true)){
                if (name === recastNamespace) {
                    yield* pregel.getStateHistory((0, utils_js_1.patchConfigurable)(config, {
                        [constants_js_1.CONFIG_KEY_CHECKPOINTER]: checkpointer
                    }), options);
                    return;
                }
            }
            throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
        }
        const mergedConfig = (0, runnables_1.mergeConfigs)(this.config, config, {
            configurable: {
                checkpoint_ns: checkpointNamespace
            }
        });
        for await (const checkpointTuple of checkpointer.list(mergedConfig, options)){
            yield this._prepareStateSnapshot({
                config: checkpointTuple.config,
                saved: checkpointTuple
            });
        }
    }
    /**
     * Apply updates to the graph state in bulk.
     * Requires a checkpointer to be configured.
     *
     * This method is useful for recreating a thread
     * from a list of updates, especially if a checkpoint
     * is created as a result of multiple tasks.
     *
     * @internal The API might change in the future.
     *
     * @param startConfig - Configuration for the update
     * @param updates - The list of updates to apply to graph state
     * @returns Updated configuration
     * @throws {GraphValueError} If no checkpointer is configured
     * @throws {InvalidUpdateError} If the update cannot be attributed to a node or an update can be only applied in sequence.
     */ async bulkUpdateState(startConfig, supersteps) {
        const checkpointer = startConfig.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
        if (!checkpointer) {
            throw new errors_js_1.GraphValueError("No checkpointer set");
        }
        if (supersteps.length === 0) {
            throw new Error("No supersteps provided");
        }
        if (supersteps.some((s)=>s.updates.length === 0)) {
            throw new Error("No updates provided");
        }
        // delegate to subgraph
        const checkpointNamespace = startConfig.configurable?.checkpoint_ns ?? "";
        if (checkpointNamespace !== "" && startConfig.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] === undefined) {
            // remove task_ids from checkpoint_ns
            const recastNamespace = (0, config_js_1.recastCheckpointNamespace)(checkpointNamespace);
            // find the subgraph with the matching name
            // eslint-disable-next-line no-unreachable-loop
            for await (const [, pregel] of this.getSubgraphsAsync(recastNamespace, true)){
                return await pregel.bulkUpdateState((0, utils_js_1.patchConfigurable)(startConfig, {
                    [constants_js_1.CONFIG_KEY_CHECKPOINTER]: checkpointer
                }), supersteps);
            }
            throw new Error(`Subgraph "${recastNamespace}" not found`);
        }
        const updateSuperStep = async (inputConfig, updates)=>{
            // get last checkpoint
            const config = this.config ? (0, runnables_1.mergeConfigs)(this.config, inputConfig) : inputConfig;
            const saved = await checkpointer.getTuple(config);
            const checkpoint = saved !== undefined ? (0, langgraph_checkpoint_1.copyCheckpoint)(saved.checkpoint) : (0, langgraph_checkpoint_1.emptyCheckpoint)();
            const checkpointPreviousVersions = {
                ...saved?.checkpoint.channel_versions
            };
            const step = saved?.metadata?.step ?? -1;
            // merge configurable fields with previous checkpoint config
            let checkpointConfig = (0, utils_js_1.patchConfigurable)(config, {
                checkpoint_ns: config.configurable?.checkpoint_ns ?? ""
            });
            let checkpointMetadata = config.metadata ?? {};
            if (saved?.config.configurable) {
                checkpointConfig = (0, utils_js_1.patchConfigurable)(config, saved.config.configurable);
                checkpointMetadata = {
                    ...saved.metadata,
                    ...checkpointMetadata
                };
            }
            // Find last node that updated the state, if not provided
            const { values, asNode } = updates[0];
            if (values == null && asNode === undefined) {
                if (updates.length > 1) {
                    throw new errors_js_1.InvalidUpdateError(`Cannot create empty checkpoint with multiple updates`);
                }
                const nextConfig = await checkpointer.put(checkpointConfig, (0, base_js_1.createCheckpoint)(checkpoint, undefined, step), {
                    source: "update",
                    step: step + 1,
                    parents: saved?.metadata?.parents ?? {}
                }, {});
                return (0, index_js_1.patchCheckpointMap)(nextConfig, saved ? saved.metadata : undefined);
            }
            // update channels
            const channels = (0, base_js_1.emptyChannels)(this.channels, checkpoint);
            if (values === null && asNode === constants_js_1.END) {
                if (updates.length > 1) {
                    throw new errors_js_1.InvalidUpdateError(`Cannot apply multiple updates when clearing state`);
                }
                if (saved) {
                    // tasks for this checkpoint
                    const nextTasks = (0, algo_js_1._prepareNextTasks)(checkpoint, saved.pendingWrites || [], this.nodes, channels, saved.config, true, {
                        step: (saved.metadata?.step ?? -1) + 1,
                        checkpointer,
                        store: this.store
                    });
                    // apply null writes
                    const nullWrites = (saved.pendingWrites || []).filter((w)=>w[0] === constants_js_1.NULL_TASK_ID).map((w)=>w.slice(1));
                    if (nullWrites.length > 0) {
                        (0, algo_js_1._applyWrites)(checkpoint, channels, [
                            {
                                name: constants_js_1.INPUT,
                                writes: nullWrites,
                                triggers: []
                            }
                        ], checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);
                    }
                    // apply writes from tasks that already ran
                    for (const [taskId, k, v] of saved.pendingWrites || []){
                        if ([
                            constants_js_1.ERROR,
                            constants_js_1.INTERRUPT,
                            langgraph_checkpoint_1.SCHEDULED
                        ].includes(k)) {
                            continue;
                        }
                        if (!(taskId in nextTasks)) {
                            continue;
                        }
                        nextTasks[taskId].writes.push([
                            k,
                            v
                        ]);
                    }
                    // clear all current tasks
                    (0, algo_js_1._applyWrites)(checkpoint, channels, Object.values(nextTasks), checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);
                }
                // save checkpoint
                const nextConfig = await checkpointer.put(checkpointConfig, (0, base_js_1.createCheckpoint)(checkpoint, channels, step), {
                    ...checkpointMetadata,
                    source: "update",
                    step: step + 1,
                    parents: saved?.metadata?.parents ?? {}
                }, (0, index_js_1.getNewChannelVersions)(checkpointPreviousVersions, checkpoint.channel_versions));
                return (0, index_js_1.patchCheckpointMap)(nextConfig, saved ? saved.metadata : undefined);
            }
            if (asNode === constants_js_1.COPY) {
                if (updates.length > 1) {
                    throw new errors_js_1.InvalidUpdateError(`Cannot copy checkpoint with multiple updates`);
                }
                if (saved == null) {
                    throw new errors_js_1.InvalidUpdateError(`Cannot copy a non-existent checkpoint`);
                }
                const isCopyWithUpdates = (values)=>{
                    if (!Array.isArray(values)) return false;
                    if (values.length === 0) return false;
                    return values.every((v)=>Array.isArray(v) && v.length === 2);
                };
                const nextCheckpoint = (0, base_js_1.createCheckpoint)(checkpoint, undefined, step);
                const nextConfig = await checkpointer.put(saved.parentConfig ?? (0, utils_js_1.patchConfigurable)(saved.config, {
                    checkpoint_id: undefined
                }), nextCheckpoint, {
                    source: "fork",
                    step: step + 1,
                    parents: saved.metadata?.parents ?? {}
                }, {});
                // We want to both clone a checkpoint and update state in one go.
                // Reuse the same task ID if possible.
                if (isCopyWithUpdates(values)) {
                    // figure out the task IDs for the next update checkpoint
                    const nextTasks = (0, algo_js_1._prepareNextTasks)(nextCheckpoint, saved.pendingWrites, this.nodes, channels, nextConfig, false, {
                        step: step + 2
                    });
                    const tasksGroupBy = Object.values(nextTasks).reduce((acc, { name, id })=>{
                        acc[name] ??= [];
                        acc[name].push({
                            id
                        });
                        return acc;
                    }, {});
                    const userGroupBy = values.reduce((acc, item)=>{
                        const [values, asNode] = item;
                        acc[asNode] ??= [];
                        const targetIdx = acc[asNode].length;
                        const taskId = tasksGroupBy[asNode]?.[targetIdx]?.id;
                        acc[asNode].push({
                            values,
                            asNode,
                            taskId
                        });
                        return acc;
                    }, {});
                    return updateSuperStep((0, index_js_1.patchCheckpointMap)(nextConfig, saved.metadata), Object.values(userGroupBy).flat());
                }
                return (0, index_js_1.patchCheckpointMap)(nextConfig, saved.metadata);
            }
            if (asNode === constants_js_1.INPUT) {
                if (updates.length > 1) {
                    throw new errors_js_1.InvalidUpdateError(`Cannot apply multiple updates when updating as input`);
                }
                const inputWrites = await (0, utils_js_1.gatherIterator)((0, io_js_1.mapInput)(this.inputChannels, values));
                if (inputWrites.length === 0) {
                    throw new errors_js_1.InvalidUpdateError(`Received no input writes for ${JSON.stringify(this.inputChannels, null, 2)}`);
                }
                // apply to checkpoint
                (0, algo_js_1._applyWrites)(checkpoint, channels, [
                    {
                        name: constants_js_1.INPUT,
                        writes: inputWrites,
                        triggers: []
                    }
                ], checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
                // apply input write to channels
                const nextStep = saved?.metadata?.step != null ? saved.metadata.step + 1 : -1;
                const nextConfig = await checkpointer.put(checkpointConfig, (0, base_js_1.createCheckpoint)(checkpoint, channels, nextStep), {
                    source: "input",
                    step: nextStep,
                    parents: saved?.metadata?.parents ?? {}
                }, (0, index_js_1.getNewChannelVersions)(checkpointPreviousVersions, checkpoint.channel_versions));
                // Store the writes
                await checkpointer.putWrites(nextConfig, inputWrites, (0, langgraph_checkpoint_1.uuid5)(constants_js_1.INPUT, checkpoint.id));
                return (0, index_js_1.patchCheckpointMap)(nextConfig, saved ? saved.metadata : undefined);
            }
            // apply pending writes, if not on specific checkpoint
            if (config.configurable?.checkpoint_id === undefined && saved?.pendingWrites !== undefined && saved.pendingWrites.length > 0) {
                // tasks for this checkpoint
                const nextTasks = (0, algo_js_1._prepareNextTasks)(checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {
                    store: this.store,
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    checkpointer: this.checkpointer,
                    step: (saved.metadata?.step ?? -1) + 1
                });
                // apply null writes
                const nullWrites = (saved.pendingWrites ?? []).filter((w)=>w[0] === constants_js_1.NULL_TASK_ID).map((w)=>w.slice(1));
                if (nullWrites.length > 0) {
                    (0, algo_js_1._applyWrites)(saved.checkpoint, channels, [
                        {
                            name: constants_js_1.INPUT,
                            writes: nullWrites,
                            triggers: []
                        }
                    ], undefined, this.triggerToNodes);
                }
                // apply writes
                for (const [tid, k, v] of saved.pendingWrites){
                    if ([
                        constants_js_1.ERROR,
                        constants_js_1.INTERRUPT,
                        langgraph_checkpoint_1.SCHEDULED
                    ].includes(k) || nextTasks[tid] === undefined) {
                        continue;
                    }
                    nextTasks[tid].writes.push([
                        k,
                        v
                    ]);
                }
                const tasks = Object.values(nextTasks).filter((task)=>{
                    return task.writes.length > 0;
                });
                if (tasks.length > 0) {
                    (0, algo_js_1._applyWrites)(checkpoint, channels, tasks, undefined, this.triggerToNodes);
                }
            }
            const nonNullVersion = Object.values(checkpoint.versions_seen).map((seenVersions)=>{
                return Object.values(seenVersions);
            }).flat().find((v)=>!!v);
            const validUpdates = [];
            if (updates.length === 1) {
                // eslint-disable-next-line prefer-const
                let { values, asNode, taskId } = updates[0];
                if (asNode === undefined && Object.keys(this.nodes).length === 1) {
                    // if only one node, use it
                    [asNode] = Object.keys(this.nodes);
                } else if (asNode === undefined && nonNullVersion === undefined) {
                    if (typeof this.inputChannels === "string" && this.nodes[this.inputChannels] !== undefined) {
                        asNode = this.inputChannels;
                    }
                } else if (asNode === undefined) {
                    const lastSeenByNode = Object.entries(checkpoint.versions_seen).map(([n, seen])=>{
                        return Object.values(seen).map((v)=>{
                            return [
                                v,
                                n
                            ];
                        });
                    }).flat().filter(([_, v])=>v !== constants_js_1.INTERRUPT).sort(([aNumber], [bNumber])=>(0, langgraph_checkpoint_1.compareChannelVersions)(aNumber, bNumber));
                    // if two nodes updated the state at the same time, it's ambiguous
                    if (lastSeenByNode) {
                        if (lastSeenByNode.length === 1) {
                            // eslint-disable-next-line prefer-destructuring
                            asNode = lastSeenByNode[0][1];
                        } else if (lastSeenByNode[lastSeenByNode.length - 1][0] !== lastSeenByNode[lastSeenByNode.length - 2][0]) {
                            // eslint-disable-next-line prefer-destructuring
                            asNode = lastSeenByNode[lastSeenByNode.length - 1][1];
                        }
                    }
                }
                if (asNode === undefined) {
                    throw new errors_js_1.InvalidUpdateError(`Ambiguous update, specify "asNode"`);
                }
                validUpdates.push({
                    values,
                    asNode,
                    taskId
                });
            } else {
                for (const { asNode, values, taskId } of updates){
                    if (asNode == null) {
                        throw new errors_js_1.InvalidUpdateError(`"asNode" is required when applying multiple updates`);
                    }
                    validUpdates.push({
                        values,
                        asNode,
                        taskId
                    });
                }
            }
            const tasks = [];
            for (const { asNode, values, taskId } of validUpdates){
                if (this.nodes[asNode] === undefined) {
                    throw new errors_js_1.InvalidUpdateError(`Node "${asNode.toString()}" does not exist`);
                }
                // run all writers of the chosen node
                const writers = this.nodes[asNode].getWriters();
                if (!writers.length) {
                    throw new errors_js_1.InvalidUpdateError(`No writers found for node "${asNode.toString()}"`);
                }
                tasks.push({
                    name: asNode,
                    input: values,
                    proc: writers.length > 1 ? runnables_1.RunnableSequence.from(writers, {
                        omitSequenceTags: true
                    }) : writers[0],
                    writes: [],
                    triggers: [
                        constants_js_1.INTERRUPT
                    ],
                    id: taskId ?? (0, langgraph_checkpoint_1.uuid5)(constants_js_1.INTERRUPT, checkpoint.id),
                    writers: []
                });
            }
            for (const task of tasks){
                // execute task
                await task.proc.invoke(task.input, (0, runnables_1.patchConfig)({
                    ...config,
                    store: config?.store ?? this.store
                }, {
                    runName: config.runName ?? `${this.getName()}UpdateState`,
                    configurable: {
                        [constants_js_1.CONFIG_KEY_SEND]: (items)=>task.writes.push(...items),
                        [constants_js_1.CONFIG_KEY_READ]: (select_, fresh_ = false)=>(0, algo_js_1._localRead)(checkpoint, channels, // TODO: Why does keyof StrRecord allow number and symbol?
                            task, select_, fresh_)
                    }
                }));
            }
            for (const task of tasks){
                // channel writes are saved to current checkpoint
                const channelWrites = task.writes.filter((w)=>w[0] !== constants_js_1.PUSH);
                // save task writes
                if (saved !== undefined && channelWrites.length > 0) {
                    await checkpointer.putWrites(checkpointConfig, channelWrites, task.id);
                }
            }
            // apply to checkpoint
            // TODO: Why does keyof StrRecord allow number and symbol?
            (0, algo_js_1._applyWrites)(checkpoint, channels, tasks, checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
            const newVersions = (0, index_js_1.getNewChannelVersions)(checkpointPreviousVersions, checkpoint.channel_versions);
            const nextConfig = await checkpointer.put(checkpointConfig, (0, base_js_1.createCheckpoint)(checkpoint, channels, step + 1), {
                source: "update",
                step: step + 1,
                parents: saved?.metadata?.parents ?? {}
            }, newVersions);
            for (const task of tasks){
                // push writes are saved to next checkpoint
                const pushWrites = task.writes.filter((w)=>w[0] === constants_js_1.PUSH);
                if (pushWrites.length > 0) {
                    await checkpointer.putWrites(nextConfig, pushWrites, task.id);
                }
            }
            return (0, index_js_1.patchCheckpointMap)(nextConfig, saved ? saved.metadata : undefined);
        };
        let currentConfig = startConfig;
        for (const { updates } of supersteps){
            currentConfig = await updateSuperStep(currentConfig, updates);
        }
        return currentConfig;
    }
    /**
     * Updates the state of the graph with new values.
     * Requires a checkpointer to be configured.
     *
     * This method can be used for:
     * - Implementing human-in-the-loop workflows
     * - Modifying graph state during breakpoints
     * - Integrating external inputs into the graph
     *
     * @param inputConfig - Configuration for the update
     * @param values - The values to update the state with
     * @param asNode - Optional node name to attribute the update to
     * @returns Updated configuration
     * @throws {GraphValueError} If no checkpointer is configured
     * @throws {InvalidUpdateError} If the update cannot be attributed to a node
     */ async updateState(inputConfig, values, asNode) {
        return this.bulkUpdateState(inputConfig, [
            {
                updates: [
                    {
                        values,
                        asNode
                    }
                ]
            }
        ]);
    }
    /**
     * Gets the default values for various graph configuration options.
     * This is an internal method used to process and normalize configuration options.
     *
     * @param config - The input configuration options
     * @returns A tuple containing normalized values for:
     * - debug mode
     * - stream modes
     * - input keys
     * - output keys
     * - remaining config
     * - interrupt before nodes
     * - interrupt after nodes
     * - checkpointer
     * - store
     * - whether stream mode is single
     * - node cache
     * - whether checkpoint during is enabled
     * @internal
     */ _defaults(config) {
        const { debug, streamMode, inputKeys, outputKeys, interruptAfter, interruptBefore, ...rest } = config;
        let streamModeSingle = true;
        const defaultDebug = debug !== undefined ? debug : this.debug;
        let defaultOutputKeys = outputKeys;
        if (defaultOutputKeys === undefined) {
            defaultOutputKeys = this.streamChannelsAsIs;
        } else {
            (0, validate_js_1.validateKeys)(defaultOutputKeys, this.channels);
        }
        let defaultInputKeys = inputKeys;
        if (defaultInputKeys === undefined) {
            defaultInputKeys = this.inputChannels;
        } else {
            (0, validate_js_1.validateKeys)(defaultInputKeys, this.channels);
        }
        const defaultInterruptBefore = interruptBefore ?? this.interruptBefore ?? [];
        const defaultInterruptAfter = interruptAfter ?? this.interruptAfter ?? [];
        let defaultStreamMode;
        if (streamMode !== undefined) {
            defaultStreamMode = Array.isArray(streamMode) ? streamMode : [
                streamMode
            ];
            streamModeSingle = typeof streamMode === "string";
        } else {
            // if being called as a node in another graph, default to values mode
            // but don't overwrite `streamMode`if provided
            if (config.configurable?.[constants_js_1.CONFIG_KEY_TASK_ID] !== undefined) {
                defaultStreamMode = [
                    "values"
                ];
            } else {
                defaultStreamMode = this.streamMode;
            }
            streamModeSingle = true;
        }
        let defaultCheckpointer;
        if (this.checkpointer === false) {
            defaultCheckpointer = undefined;
        } else if (config !== undefined && config.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINTER] !== undefined) {
            defaultCheckpointer = config.configurable[constants_js_1.CONFIG_KEY_CHECKPOINTER];
        } else if (this.checkpointer === true) {
            throw new Error("checkpointer: true cannot be used for root graphs.");
        } else {
            defaultCheckpointer = this.checkpointer;
        }
        const defaultStore = config.store ?? this.store;
        const defaultCache = config.cache ?? this.cache;
        if (config.durability != null && config.checkpointDuring != null) {
            throw new Error("Cannot use both `durability` and `checkpointDuring` at the same time.");
        }
        const checkpointDuringDurability = (()=>{
            if (config.checkpointDuring == null) return undefined;
            if (config.checkpointDuring === false) return "exit";
            return "async";
        })();
        const defaultDurability = config.durability ?? checkpointDuringDurability ?? config?.configurable?.[constants_js_1.CONFIG_KEY_DURABILITY] ?? "async";
        return [
            defaultDebug,
            defaultStreamMode,
            defaultInputKeys,
            defaultOutputKeys,
            rest,
            defaultInterruptBefore,
            defaultInterruptAfter,
            defaultCheckpointer,
            defaultStore,
            streamModeSingle,
            defaultCache,
            defaultDurability
        ];
    }
    /**
     * Streams the execution of the graph, emitting state updates as they occur.
     * This is the primary method for observing graph execution in real-time.
     *
     * Stream modes:
     * - "values": Emits complete state after each step
     * - "updates": Emits only state changes after each step
     * - "debug": Emits detailed debug information
     * - "messages": Emits messages from within nodes
     *
     * For more details, see the [Streaming how-to guides](../../how-tos/#streaming_1).
     *
     * @param input - The input to start graph execution with
     * @param options - Configuration options for streaming
     * @returns An async iterable stream of graph state updates
     */ async stream(input, options) {
        // The ensureConfig method called internally defaults recursionLimit to 25 if not
        // passed directly in `options`.
        // There is currently no way in _streamIterator to determine whether this was
        // set by by ensureConfig or manually by the user, so we specify the bound value here
        // and override if it is passed as an explicit param in `options`.
        const abortController = new AbortController();
        const config = {
            recursionLimit: this.config?.recursionLimit,
            ...options,
            signal: (0, index_js_1.combineAbortSignals)(options?.signal, abortController.signal).signal
        };
        return new stream_js_1.IterableReadableStreamWithAbortSignal(await super.stream(input, config), abortController);
    }
    streamEvents(input, options, streamOptions) {
        const abortController = new AbortController();
        const config = {
            recursionLimit: this.config?.recursionLimit,
            ...options,
            // Similar to `stream`, we need to pass the `config.callbacks` here,
            // otherwise the user-provided callback will get lost in `ensureLangGraphConfig`.
            // extend the callbacks with the ones from the config
            callbacks: (0, index_js_1.combineCallbacks)(this.config?.callbacks, options?.callbacks),
            signal: (0, index_js_1.combineAbortSignals)(options?.signal, abortController.signal).signal
        };
        return new stream_js_1.IterableReadableStreamWithAbortSignal(super.streamEvents(input, config, streamOptions), abortController);
    }
    /**
     * Validates the input for the graph.
     * @param input - The input to validate
     * @returns The validated input
     * @internal
     */ async _validateInput(input) {
        return input;
    }
    /**
     * Validates the context options for the graph.
     * @param context - The context options to validate
     * @returns The validated context options
     * @internal
     */ async _validateContext(context) {
        return context;
    }
    /**
     * Internal iterator used by stream() to generate state updates.
     * This method handles the core logic of graph execution and streaming.
     *
     * @param input - The input to start graph execution with
     * @param options - Configuration options for streaming
     * @returns AsyncGenerator yielding state updates
     * @internal
     */ async *_streamIterator(input, options) {
        const streamSubgraphs = options?.subgraphs;
        const inputConfig = (0, config_js_1.ensureLangGraphConfig)(this.config, options);
        if (inputConfig.recursionLimit === undefined || inputConfig.recursionLimit < 1) {
            throw new Error(`Passed "recursionLimit" must be at least 1.`);
        }
        if (this.checkpointer !== undefined && this.checkpointer !== false && inputConfig.configurable === undefined) {
            throw new Error(`Checkpointer requires one or more of the following "configurable" keys: "thread_id", "checkpoint_ns", "checkpoint_id"`);
        }
        const validInput = await this._validateInput(input);
        const { runId, ...restConfig } = inputConfig;
        // assign defaults
        const [debug, streamMode, , outputKeys, config, interruptBefore, interruptAfter, checkpointer, store, streamModeSingle, cache, durability] = this._defaults(restConfig);
        // At entrypoint, `configurable` is an alias for `context`.
        if (typeof config.context !== "undefined") {
            config.context = await this._validateContext(config.context);
        } else {
            config.configurable = await this._validateContext(config.configurable);
        }
        const stream = new stream_js_1.IterableReadableWritableStream({
            modes: new Set(streamMode)
        });
        // set up subgraph checkpointing
        if (this.checkpointer === true) {
            config.configurable ??= {};
            const ns = config.configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_NS] ?? "";
            config.configurable[constants_js_1.CONFIG_KEY_CHECKPOINT_NS] = ns.split(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR).map((part)=>part.split(constants_js_1.CHECKPOINT_NAMESPACE_END)[0]).join(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR);
        }
        // set up messages stream mode
        if (streamMode.includes("messages")) {
            const messageStreamer = new messages_js_1.StreamMessagesHandler((chunk)=>stream.push(chunk));
            const { callbacks } = config;
            if (callbacks === undefined) {
                config.callbacks = [
                    messageStreamer
                ];
            } else if (Array.isArray(callbacks)) {
                config.callbacks = callbacks.concat(messageStreamer);
            } else {
                const copiedCallbacks = callbacks.copy();
                copiedCallbacks.addHandler(messageStreamer, true);
                config.callbacks = copiedCallbacks;
            }
        }
        // setup custom stream mode
        if (streamMode.includes("custom")) {
            config.writer = (chunk)=>{
                const ns = (0, config_js_1.getConfig)()?.configurable?.[constants_js_1.CONFIG_KEY_CHECKPOINT_NS]?.split(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR).slice(0, -1);
                stream.push([
                    ns ?? [],
                    "custom",
                    chunk
                ]);
            };
        }
        const callbackManager = await (0, runnables_1.getCallbackManagerForConfig)(config);
        const runManager = await callbackManager?.handleChainStart(this.toJSON(), (0, index_js_1._coerceToDict)(input, "input"), runId, undefined, undefined, undefined, config?.runName ?? this.getName() // run_name
        );
        const channelSpecs = (0, base_js_1.getOnlyChannels)(this.channels);
        let loop;
        let loopError;
        /**
         * The PregelLoop will yield events from concurrent tasks as soon as they are
         * generated. Each task can push multiple events onto the stream in any order.
         *
         * We use a separate background method and stream here in order to yield events
         * from the loop to the main stream and therefore back to the user as soon as
         * they are available.
         */ const createAndRunLoop = async ()=>{
            try {
                loop = await loop_js_1.PregelLoop.initialize({
                    input: validInput,
                    config,
                    checkpointer,
                    nodes: this.nodes,
                    channelSpecs,
                    outputKeys,
                    streamKeys: this.streamChannelsAsIs,
                    store,
                    cache: cache,
                    stream,
                    interruptAfter,
                    interruptBefore,
                    manager: runManager,
                    debug: this.debug,
                    triggerToNodes: this.triggerToNodes,
                    durability
                });
                const runner = new runner_js_1.PregelRunner({
                    loop,
                    nodeFinished: config.configurable?.[constants_js_1.CONFIG_KEY_NODE_FINISHED]
                });
                if (options?.subgraphs) {
                    loop.config.configurable = {
                        ...loop.config.configurable,
                        [constants_js_1.CONFIG_KEY_STREAM]: loop.stream
                    };
                }
                await this._runLoop({
                    loop,
                    runner,
                    debug,
                    config
                });
                // wait for checkpoints to be persisted
                if (durability === "sync") {
                    await Promise.all(loop?.checkpointerPromises ?? []);
                }
            } catch (e) {
                loopError = e;
            } finally{
                try {
                    // Call `.stop()` again incase it was not called in the loop, e.g due to an error.
                    if (loop) {
                        await loop.store?.stop();
                        await loop.cache?.stop();
                    }
                    await Promise.all(loop?.checkpointerPromises ?? []);
                } catch (e) {
                    loopError = loopError ?? e;
                }
                if (loopError) {
                    // "Causes any future interactions with the associated stream to error".
                    // Wraps ReadableStreamDefaultController#error:
                    // https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamDefaultController/error
                    stream.error(loopError);
                } else {
                    // Will end the iterator outside of this method,
                    // keeping previously enqueued chunks.
                    // Wraps ReadableStreamDefaultController#close:
                    // https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamDefaultController/close
                    stream.close();
                }
            }
        };
        const runLoopPromise = createAndRunLoop();
        try {
            for await (const chunk of stream){
                if (chunk === undefined) {
                    throw new Error("Data structure error.");
                }
                const [namespace, mode, payload] = chunk;
                if (streamMode.includes(mode)) {
                    if (streamSubgraphs && !streamModeSingle) {
                        yield [
                            namespace,
                            mode,
                            payload
                        ];
                    } else if (!streamModeSingle) {
                        yield [
                            mode,
                            payload
                        ];
                    } else if (streamSubgraphs) {
                        yield [
                            namespace,
                            payload
                        ];
                    } else {
                        yield payload;
                    }
                }
            }
        } catch (e) {
            await runManager?.handleChainError(loopError);
            throw e;
        } finally{
            await runLoopPromise;
        }
        await runManager?.handleChainEnd(loop?.output ?? {}, runId, undefined, undefined, undefined // metadata
        );
    }
    /**
     * Run the graph with a single input and config.
     * @param input The input to the graph.
     * @param options The configuration to use for the run.
     */ async invoke(input, options) {
        const streamMode = options?.streamMode ?? "values";
        const config = {
            ...options,
            outputKeys: options?.outputKeys ?? this.outputChannels,
            streamMode
        };
        const chunks = [];
        const stream = await this.stream(input, config);
        const interruptChunks = [];
        let latest;
        for await (const chunk of stream){
            if (streamMode === "values") {
                if ((0, constants_js_1.isInterrupted)(chunk)) {
                    interruptChunks.push(chunk[constants_js_1.INTERRUPT]);
                } else {
                    latest = chunk;
                }
            } else {
                chunks.push(chunk);
            }
        }
        if (streamMode === "values") {
            if (interruptChunks.length > 0) {
                const interrupts = interruptChunks.flat(1);
                if (latest == null) return {
                    [constants_js_1.INTERRUPT]: interrupts
                };
                if (typeof latest === "object") {
                    return {
                        ...latest,
                        [constants_js_1.INTERRUPT]: interrupts
                    };
                }
            }
            return latest;
        }
        return chunks;
    }
    async _runLoop(params) {
        const { loop, runner, debug, config } = params;
        let tickError;
        try {
            while(await loop.tick({
                inputKeys: this.inputChannels
            })){
                for (const { task } of (await loop._matchCachedWrites())){
                    loop._outputWrites(task.id, task.writes, true);
                }
                if (debug) {
                    (0, debug_js_1.printStepCheckpoint)(loop.checkpointMetadata.step, loop.channels, this.streamChannelsList);
                }
                if (debug) {
                    (0, debug_js_1.printStepTasks)(loop.step, Object.values(loop.tasks));
                }
                await runner.tick({
                    timeout: this.stepTimeout,
                    retryPolicy: this.retryPolicy,
                    onStepWrite: (step, writes)=>{
                        if (debug) {
                            (0, debug_js_1.printStepWrites)(step, writes, this.streamChannelsList);
                        }
                    },
                    maxConcurrency: config.maxConcurrency,
                    signal: config.signal
                });
            }
            if (loop.status === "out_of_steps") {
                throw new errors_js_1.GraphRecursionError([
                    `Recursion limit of ${config.recursionLimit} reached`,
                    "without hitting a stop condition. You can increase the",
                    `limit by setting the "recursionLimit" config key.`
                ].join(" "), {
                    lc_error_code: "GRAPH_RECURSION_LIMIT"
                });
            }
        } catch (e) {
            tickError = e;
            const suppress = await loop.finishAndHandleError(tickError);
            if (!suppress) {
                throw e;
            }
        } finally{
            if (tickError === undefined) {
                await loop.finishAndHandleError();
            }
        }
    }
    async clearCache() {
        await this.cache?.clear([]);
    }
}
exports.Pregel = Pregel; //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.BinaryOperatorAggregate = exports.empty = exports.createCheckpoint = exports.BaseChannel = void 0;
var base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "BaseChannel", {
    enumerable: true,
    get: function() {
        return base_js_1.BaseChannel;
    }
});
Object.defineProperty(exports, "createCheckpoint", {
    enumerable: true,
    get: function() {
        return base_js_1.createCheckpoint;
    }
});
Object.defineProperty(exports, "empty", {
    enumerable: true,
    get: function() {
        return base_js_1.emptyChannels;
    }
});
var binop_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/binop.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "BinaryOperatorAggregate", {
    enumerable: true,
    get: function() {
        return binop_js_1.BinaryOperatorAggregate;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/ephemeral_value.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.EphemeralValue = void 0;
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/index.cjs [app-route] (ecmascript)");
/**
 * Stores the value received in the step immediately preceding, clears after.
 * @internal
 */ class EphemeralValue extends index_js_1.BaseChannel {
    constructor(guard = true){
        super();
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "EphemeralValue"
        });
        Object.defineProperty(this, "guard", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // value is an array so we don't misinterpret an update to undefined as no write
        Object.defineProperty(this, "value", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: []
        });
        this.guard = guard;
    }
    fromCheckpoint(checkpoint) {
        const empty = new EphemeralValue(this.guard);
        if (typeof checkpoint !== "undefined") {
            empty.value = [
                checkpoint
            ];
        }
        return empty;
    }
    update(values) {
        if (values.length === 0) {
            const updated = this.value.length > 0;
            // If there are no updates for this specific channel at the end of the step, wipe it.
            this.value = [];
            return updated;
        }
        if (values.length !== 1 && this.guard) {
            throw new errors_js_1.InvalidUpdateError("EphemeralValue can only receive one value per step.");
        }
        // eslint-disable-next-line prefer-destructuring
        this.value = [
            values[values.length - 1]
        ];
        return true;
    }
    get() {
        if (this.value.length === 0) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value[0];
    }
    checkpoint() {
        if (this.value.length === 0) {
            throw new errors_js_1.EmptyChannelError();
        }
        return this.value[0];
    }
    isAvailable() {
        return this.value.length !== 0;
    }
}
exports.EphemeralValue = EphemeralValue; //# sourceMappingURL=ephemeral_value.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/graph.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.CompiledGraph = exports.Graph = exports.Branch = void 0;
/* eslint-disable @typescript-eslint/no-use-before-define */ const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const graph_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables/graph.cjs [app-route] (ecmascript)");
const zod_1 = __turbopack_context__.r("[project]/node_modules/zod/index.cjs [app-route] (ecmascript)");
const uuid_1 = __turbopack_context__.r("[project]/node_modules/uuid/dist/esm-node/index.js [app-route] (ecmascript)");
const read_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/read.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/index.cjs [app-route] (ecmascript)");
const ephemeral_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/ephemeral_value.cjs [app-route] (ecmascript)");
const write_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const subgraph_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.cjs [app-route] (ecmascript)");
class Branch {
    constructor(options){
        Object.defineProperty(this, "path", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "ends", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        if (runnables_1.Runnable.isRunnable(options.path)) {
            this.path = options.path;
        } else {
            this.path = (0, runnables_1._coerceToRunnable)(options.path).withConfig({
                runName: `Branch`
            });
        }
        this.ends = Array.isArray(options.pathMap) ? options.pathMap.reduce((acc, n)=>{
            acc[n] = n;
            return acc;
        }, {}) : options.pathMap;
    }
    run(writer, reader) {
        return write_js_1.ChannelWrite.registerWriter(new utils_js_1.RunnableCallable({
            name: "<branch_run>",
            trace: false,
            func: async (input, config)=>{
                try {
                    return await this._route(input, config, writer, reader);
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                } catch (e) {
                    // Detect & warn if NodeInterrupt is thrown in a conditional edge
                    if (e.name === errors_js_1.NodeInterrupt.unminifiable_name) {
                        console.warn("[WARN]: 'NodeInterrupt' thrown in conditional edge. This is likely a bug in your graph implementation.\n" + "NodeInterrupt should only be thrown inside a node, not in edge conditions.");
                    }
                    throw e;
                }
            }
        }));
    }
    async _route(input, config, writer, reader) {
        let result = await this.path.invoke(reader ? reader(config) : input, config);
        if (!Array.isArray(result)) {
            result = [
                result
            ];
        }
        let destinations;
        if (this.ends) {
            destinations = result.map((r)=>(0, constants_js_1._isSend)(r) ? r : this.ends[r]);
        } else {
            destinations = result;
        }
        if (destinations.some((dest)=>!dest)) {
            throw new Error("Branch condition returned unknown or null destination");
        }
        if (destinations.filter(constants_js_1._isSend).some((packet)=>packet.node === constants_js_1.END)) {
            throw new errors_js_1.InvalidUpdateError("Cannot send a packet to the END node");
        }
        const writeResult = await writer(destinations, config);
        return writeResult ?? input;
    }
}
exports.Branch = Branch;
class Graph {
    constructor(){
        Object.defineProperty(this, "nodes", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "edges", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        Object.defineProperty(this, "branches", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "entryPoint", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "compiled", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        this.nodes = {};
        this.edges = new Set();
        this.branches = {};
    }
    warnIfCompiled(message) {
        if (this.compiled) {
            console.warn(message);
        }
    }
    get allEdges() {
        return this.edges;
    }
    addNode(...args) {
        function isMutlipleNodes(args) {
            return args.length >= 1 && typeof args[0] !== "string";
        }
        const nodes = isMutlipleNodes(args) // eslint-disable-line no-nested-ternary
         ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]) : [
            [
                args[0],
                args[1],
                args[2]
            ]
        ];
        if (nodes.length === 0) {
            throw new Error("No nodes provided in `addNode`");
        }
        for (const [key, action, options] of nodes){
            for (const reservedChar of [
                constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR,
                constants_js_1.CHECKPOINT_NAMESPACE_END
            ]){
                if (key.includes(reservedChar)) {
                    throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
                }
            }
            this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
            if (key in this.nodes) {
                throw new Error(`Node \`${key}\` already present.`);
            }
            if (key === constants_js_1.END) {
                throw new Error(`Node \`${key}\` is reserved.`);
            }
            const runnable = (0, runnables_1._coerceToRunnable)(// Account for arbitrary state due to Send API
            action);
            this.nodes[key] = {
                runnable,
                metadata: options?.metadata,
                subgraphs: (0, subgraph_js_1.isPregelLike)(runnable) ? [
                    runnable
                ] : options?.subgraphs,
                ends: options?.ends
            };
        }
        return this;
    }
    addEdge(startKey, endKey) {
        this.warnIfCompiled(`Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
        if (startKey === constants_js_1.END) {
            throw new Error("END cannot be a start node");
        }
        if (endKey === constants_js_1.START) {
            throw new Error("START cannot be an end node");
        }
        if (Array.from(this.edges).some(([start])=>start === startKey) && !("channels" in this)) {
            throw new Error(`Already found path for ${startKey}. For multiple edges, use StateGraph.`);
        }
        this.edges.add([
            startKey,
            endKey
        ]);
        return this;
    }
    addConditionalEdges(source, path, pathMap) {
        const options = typeof source === "object" ? source : {
            source,
            path: path,
            pathMap
        };
        this.warnIfCompiled("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
        if (!runnables_1.Runnable.isRunnable(options.path)) {
            const pathDisplayValues = Array.isArray(options.pathMap) ? options.pathMap.join(",") : Object.keys(options.pathMap ?? {}).join(",");
            options.path = (0, runnables_1._coerceToRunnable)(options.path).withConfig({
                runName: `Branch<${options.source}${pathDisplayValues !== "" ? `,${pathDisplayValues}` : ""}>`.slice(0, 63)
            });
        }
        // find a name for condition
        const name = options.path.getName() === "RunnableLambda" ? "condition" : options.path.getName();
        // validate condition
        if (this.branches[options.source] && this.branches[options.source][name]) {
            throw new Error(`Condition \`${name}\` already present for node \`${source}\``);
        }
        // save it
        this.branches[options.source] ??= {};
        this.branches[options.source][name] = new Branch(options);
        return this;
    }
    /**
     * @deprecated use `addEdge(START, key)` instead
     */ setEntryPoint(key) {
        this.warnIfCompiled("Setting the entry point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
        return this.addEdge(constants_js_1.START, key);
    }
    /**
     * @deprecated use `addEdge(key, END)` instead
     */ setFinishPoint(key) {
        this.warnIfCompiled("Setting a finish point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
        return this.addEdge(key, constants_js_1.END);
    }
    compile({ checkpointer, interruptBefore, interruptAfter, name } = {}) {
        // validate the graph
        this.validate([
            ...Array.isArray(interruptBefore) ? interruptBefore : [],
            ...Array.isArray(interruptAfter) ? interruptAfter : []
        ]);
        // create empty compiled graph
        const compiled = new CompiledGraph({
            builder: this,
            checkpointer,
            interruptAfter,
            interruptBefore,
            autoValidate: false,
            nodes: {},
            channels: {
                [constants_js_1.START]: new ephemeral_value_js_1.EphemeralValue(),
                [constants_js_1.END]: new ephemeral_value_js_1.EphemeralValue()
            },
            inputChannels: constants_js_1.START,
            outputChannels: constants_js_1.END,
            streamChannels: [],
            streamMode: "values",
            name
        });
        // attach nodes, edges and branches
        for (const [key, node] of Object.entries(this.nodes)){
            compiled.attachNode(key, node);
        }
        for (const [start, end] of this.edges){
            compiled.attachEdge(start, end);
        }
        for (const [start, branches] of Object.entries(this.branches)){
            for (const [name, branch] of Object.entries(branches)){
                compiled.attachBranch(start, name, branch);
            }
        }
        return compiled.validate();
    }
    validate(interrupt) {
        // assemble sources
        const allSources = new Set([
            ...this.allEdges
        ].map(([src, _])=>src));
        for (const [start] of Object.entries(this.branches)){
            allSources.add(start);
        }
        // validate sources
        for (const source of allSources){
            if (source !== constants_js_1.START && !(source in this.nodes)) {
                throw new Error(`Found edge starting at unknown node \`${source}\``);
            }
        }
        // assemble targets
        const allTargets = new Set([
            ...this.allEdges
        ].map(([_, target])=>target));
        for (const [start, branches] of Object.entries(this.branches)){
            for (const branch of Object.values(branches)){
                if (branch.ends != null) {
                    for (const end of Object.values(branch.ends)){
                        allTargets.add(end);
                    }
                } else {
                    allTargets.add(constants_js_1.END);
                    for (const node of Object.keys(this.nodes)){
                        if (node !== start) {
                            allTargets.add(node);
                        }
                    }
                }
            }
        }
        for (const node of Object.values(this.nodes)){
            for (const target of node.ends ?? []){
                allTargets.add(target);
            }
        }
        // validate targets
        for (const node of Object.keys(this.nodes)){
            if (!allTargets.has(node)) {
                throw new errors_js_1.UnreachableNodeError([
                    `Node \`${node}\` is not reachable.`,
                    "",
                    "If you are returning Command objects from your node,",
                    'make sure you are passing names of potential destination nodes as an "ends" array',
                    'into ".addNode(..., { ends: ["node1", "node2"] })".'
                ].join("\n"), {
                    lc_error_code: "UNREACHABLE_NODE"
                });
            }
        }
        for (const target of allTargets){
            if (target !== constants_js_1.END && !(target in this.nodes)) {
                throw new Error(`Found edge ending at unknown node \`${target}\``);
            }
        }
        // validate interrupts
        if (interrupt) {
            for (const node of interrupt){
                if (!(node in this.nodes)) {
                    throw new Error(`Interrupt node \`${node}\` is not present`);
                }
            }
        }
        this.compiled = true;
    }
}
exports.Graph = Graph;
class CompiledGraph extends index_js_1.Pregel {
    constructor({ builder, ...rest }){
        super(rest);
        Object.defineProperty(this, "builder", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.builder = builder;
    }
    attachNode(key, node) {
        this.channels[key] = new ephemeral_value_js_1.EphemeralValue();
        this.nodes[key] = new read_js_1.PregelNode({
            channels: [],
            triggers: [],
            metadata: node.metadata,
            subgraphs: node.subgraphs,
            ends: node.ends
        }).pipe(node.runnable).pipe(new write_js_1.ChannelWrite([
            {
                channel: key,
                value: write_js_1.PASSTHROUGH
            }
        ], [
            constants_js_1.TAG_HIDDEN
        ]));
        this.streamChannels.push(key);
    }
    attachEdge(start, end) {
        if (end === constants_js_1.END) {
            if (start === constants_js_1.START) {
                throw new Error("Cannot have an edge from START to END");
            }
            this.nodes[start].writers.push(new write_js_1.ChannelWrite([
                {
                    channel: constants_js_1.END,
                    value: write_js_1.PASSTHROUGH
                }
            ], [
                constants_js_1.TAG_HIDDEN
            ]));
        } else {
            this.nodes[end].triggers.push(start);
            this.nodes[end].channels.push(start);
        }
    }
    attachBranch(start, name, branch) {
        // add hidden start node
        if (start === constants_js_1.START && !this.nodes[constants_js_1.START]) {
            this.nodes[constants_js_1.START] = index_js_1.Channel.subscribeTo(constants_js_1.START, {
                tags: [
                    constants_js_1.TAG_HIDDEN
                ]
            });
        }
        // attach branch writer
        this.nodes[start].pipe(branch.run((dests)=>{
            const writes = dests.map((dest)=>{
                if ((0, constants_js_1._isSend)(dest)) {
                    return dest;
                }
                return {
                    channel: dest === constants_js_1.END ? constants_js_1.END : `branch:${start}:${name}:${dest}`,
                    value: write_js_1.PASSTHROUGH
                };
            });
            return new write_js_1.ChannelWrite(writes, [
                constants_js_1.TAG_HIDDEN
            ]);
        }));
        // attach branch readers
        const ends = branch.ends ? Object.values(branch.ends) : Object.keys(this.nodes);
        for (const end of ends){
            if (end !== constants_js_1.END) {
                const channelName = `branch:${start}:${name}:${end}`;
                this.channels[channelName] = new ephemeral_value_js_1.EphemeralValue();
                this.nodes[end].triggers.push(channelName);
                this.nodes[end].channels.push(channelName);
            }
        }
    }
    /**
     * Returns a drawable representation of the computation graph.
     */ async getGraphAsync(config) {
        const xray = config?.xray;
        const graph = new graph_1.Graph();
        const startNodes = {
            [constants_js_1.START]: graph.addNode({
                schema: zod_1.z.any()
            }, constants_js_1.START)
        };
        const endNodes = {};
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        let subgraphs = {};
        if (xray) {
            subgraphs = Object.fromEntries((await (0, utils_js_1.gatherIterator)(this.getSubgraphsAsync())).filter(// eslint-disable-next-line @typescript-eslint/no-explicit-any
            (x)=>isCompiledGraph(x[1])));
        }
        function addEdge(start, end, label, conditional = false) {
            if (end === constants_js_1.END && endNodes[constants_js_1.END] === undefined) {
                endNodes[constants_js_1.END] = graph.addNode({
                    schema: zod_1.z.any()
                }, constants_js_1.END);
            }
            if (startNodes[start] === undefined) {
                return;
            }
            if (endNodes[end] === undefined) {
                throw new Error(`End node ${end} not found!`);
            }
            return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : undefined, conditional);
        }
        for (const [key, nodeSpec] of Object.entries(this.builder.nodes)){
            const displayKey = _escapeMermaidKeywords(key);
            const node = nodeSpec.runnable;
            const metadata = nodeSpec.metadata ?? {};
            if (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) {
                metadata.__interrupt = "before,after";
            } else if (this.interruptBefore?.includes(key)) {
                metadata.__interrupt = "before";
            } else if (this.interruptAfter?.includes(key)) {
                metadata.__interrupt = "after";
            }
            if (xray) {
                const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
                const drawableSubgraph = subgraphs[key] !== undefined ? await subgraphs[key].getGraphAsync({
                    ...config,
                    xray: newXrayValue
                }) : node.getGraph(config);
                drawableSubgraph.trimFirstNode();
                drawableSubgraph.trimLastNode();
                if (Object.keys(drawableSubgraph.nodes).length > 1) {
                    const [e, s] = graph.extend(drawableSubgraph, displayKey);
                    if (e === undefined) {
                        throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
                    }
                    // TODO: Remove default name once we stop supporting core 0.2.0
                    // eslint-disable-next-line no-inner-declarations
                    function _isRunnableInterface(// eslint-disable-next-line @typescript-eslint/no-explicit-any
                    thing) {
                        return thing ? thing.lc_runnable : false;
                    }
                    // eslint-disable-next-line no-inner-declarations
                    function _nodeDataStr(id, data) {
                        if (id !== undefined && !(0, uuid_1.validate)(id)) {
                            return id;
                        } else if (_isRunnableInterface(data)) {
                            try {
                                let dataStr = data.getName();
                                dataStr = dataStr.startsWith("Runnable") ? dataStr.slice("Runnable".length) : dataStr;
                                return dataStr;
                            } catch (error) {
                                return data.getName();
                            }
                        } else {
                            return data.name ?? "UnknownSchema";
                        }
                    }
                    // TODO: Remove casts when we stop supporting core 0.2.0
                    if (s !== undefined) {
                        startNodes[displayKey] = {
                            name: _nodeDataStr(s.id, s.data),
                            ...s
                        };
                    }
                    endNodes[displayKey] = {
                        name: _nodeDataStr(e.id, e.data),
                        ...e
                    };
                } else {
                    // TODO: Remove when we stop supporting core 0.2.0
                    // eslint-disable-next-line @typescript-eslint/ban-ts-comment
                    // @ts-ignore
                    const newNode = graph.addNode(node, displayKey, metadata);
                    startNodes[displayKey] = newNode;
                    endNodes[displayKey] = newNode;
                }
            } else {
                // TODO: Remove when we stop supporting core 0.2.0
                // eslint-disable-next-line @typescript-eslint/ban-ts-comment
                // @ts-ignore
                const newNode = graph.addNode(node, displayKey, metadata);
                startNodes[displayKey] = newNode;
                endNodes[displayKey] = newNode;
            }
        }
        const sortedEdges = [
            ...this.builder.allEdges
        ].sort(([a], [b])=>{
            if (a < b) {
                return -1;
            } else if (b > a) {
                return 1;
            } else {
                return 0;
            }
        });
        for (const [start, end] of sortedEdges){
            addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
        }
        for (const [start, branches] of Object.entries(this.builder.branches)){
            const defaultEnds = {
                ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k)=>k !== start).map((k)=>[
                        _escapeMermaidKeywords(k),
                        _escapeMermaidKeywords(k)
                    ])),
                [constants_js_1.END]: constants_js_1.END
            };
            for (const branch of Object.values(branches)){
                let ends;
                if (branch.ends !== undefined) {
                    ends = branch.ends;
                } else {
                    ends = defaultEnds;
                }
                for (const [label, end] of Object.entries(ends)){
                    addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
                }
            }
        }
        for (const [key, node] of Object.entries(this.builder.nodes)){
            if (node.ends !== undefined) {
                for (const end of node.ends){
                    addEdge(_escapeMermaidKeywords(key), _escapeMermaidKeywords(end), undefined, true);
                }
            }
        }
        return graph;
    }
    /**
     * Returns a drawable representation of the computation graph.
     *
     * @deprecated Use getGraphAsync instead. The async method will be the default in the next minor core release.
     */ getGraph(config) {
        const xray = config?.xray;
        const graph = new graph_1.Graph();
        const startNodes = {
            [constants_js_1.START]: graph.addNode({
                schema: zod_1.z.any()
            }, constants_js_1.START)
        };
        const endNodes = {};
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        let subgraphs = {};
        if (xray) {
            subgraphs = Object.fromEntries((0, utils_js_1.gatherIteratorSync)(this.getSubgraphs()).filter(// eslint-disable-next-line @typescript-eslint/no-explicit-any
            (x)=>isCompiledGraph(x[1])));
        }
        function addEdge(start, end, label, conditional = false) {
            if (end === constants_js_1.END && endNodes[constants_js_1.END] === undefined) {
                endNodes[constants_js_1.END] = graph.addNode({
                    schema: zod_1.z.any()
                }, constants_js_1.END);
            }
            return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : undefined, conditional);
        }
        for (const [key, nodeSpec] of Object.entries(this.builder.nodes)){
            const displayKey = _escapeMermaidKeywords(key);
            const node = nodeSpec.runnable;
            const metadata = nodeSpec.metadata ?? {};
            if (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) {
                metadata.__interrupt = "before,after";
            } else if (this.interruptBefore?.includes(key)) {
                metadata.__interrupt = "before";
            } else if (this.interruptAfter?.includes(key)) {
                metadata.__interrupt = "after";
            }
            if (xray) {
                const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
                const drawableSubgraph = subgraphs[key] !== undefined ? subgraphs[key].getGraph({
                    ...config,
                    xray: newXrayValue
                }) : node.getGraph(config);
                drawableSubgraph.trimFirstNode();
                drawableSubgraph.trimLastNode();
                if (Object.keys(drawableSubgraph.nodes).length > 1) {
                    const [e, s] = graph.extend(drawableSubgraph, displayKey);
                    if (e === undefined) {
                        throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
                    }
                    // TODO: Remove default name once we stop supporting core 0.2.0
                    // eslint-disable-next-line no-inner-declarations
                    function _isRunnableInterface(// eslint-disable-next-line @typescript-eslint/no-explicit-any
                    thing) {
                        return thing ? thing.lc_runnable : false;
                    }
                    // eslint-disable-next-line no-inner-declarations
                    function _nodeDataStr(id, data) {
                        if (id !== undefined && !(0, uuid_1.validate)(id)) {
                            return id;
                        } else if (_isRunnableInterface(data)) {
                            try {
                                let dataStr = data.getName();
                                dataStr = dataStr.startsWith("Runnable") ? dataStr.slice("Runnable".length) : dataStr;
                                return dataStr;
                            } catch (error) {
                                return data.getName();
                            }
                        } else {
                            return data.name ?? "UnknownSchema";
                        }
                    }
                    // TODO: Remove casts when we stop supporting core 0.2.0
                    if (s !== undefined) {
                        startNodes[displayKey] = {
                            name: _nodeDataStr(s.id, s.data),
                            ...s
                        };
                    }
                    endNodes[displayKey] = {
                        name: _nodeDataStr(e.id, e.data),
                        ...e
                    };
                } else {
                    // TODO: Remove when we stop supporting core 0.2.0
                    // eslint-disable-next-line @typescript-eslint/ban-ts-comment
                    // @ts-ignore
                    const newNode = graph.addNode(node, displayKey, metadata);
                    startNodes[displayKey] = newNode;
                    endNodes[displayKey] = newNode;
                }
            } else {
                // TODO: Remove when we stop supporting core 0.2.0
                // eslint-disable-next-line @typescript-eslint/ban-ts-comment
                // @ts-ignore
                const newNode = graph.addNode(node, displayKey, metadata);
                startNodes[displayKey] = newNode;
                endNodes[displayKey] = newNode;
            }
        }
        const sortedEdges = [
            ...this.builder.allEdges
        ].sort(([a], [b])=>{
            if (a < b) {
                return -1;
            } else if (b > a) {
                return 1;
            } else {
                return 0;
            }
        });
        for (const [start, end] of sortedEdges){
            addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
        }
        for (const [start, branches] of Object.entries(this.builder.branches)){
            const defaultEnds = {
                ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k)=>k !== start).map((k)=>[
                        _escapeMermaidKeywords(k),
                        _escapeMermaidKeywords(k)
                    ])),
                [constants_js_1.END]: constants_js_1.END
            };
            for (const branch of Object.values(branches)){
                let ends;
                if (branch.ends !== undefined) {
                    ends = branch.ends;
                } else {
                    ends = defaultEnds;
                }
                for (const [label, end] of Object.entries(ends)){
                    addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
                }
            }
        }
        return graph;
    }
}
exports.CompiledGraph = CompiledGraph;
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function isCompiledGraph(x) {
    return(// eslint-disable-next-line @typescript-eslint/no-explicit-any
    typeof x.attachNode === "function" && // eslint-disable-next-line @typescript-eslint/no-explicit-any
    typeof x.attachEdge === "function");
}
function _escapeMermaidKeywords(key) {
    if (key === "subgraph") {
        return `"${key}"`;
    }
    return key;
} //# sourceMappingURL=graph.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/channels/named_barrier_value.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.NamedBarrierValueAfterFinish = exports.NamedBarrierValue = exports.areSetsEqual = void 0;
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
const areSetsEqual = (a, b)=>a.size === b.size && [
        ...a
    ].every((value)=>b.has(value));
exports.areSetsEqual = areSetsEqual;
/**
 * A channel that waits until all named values are received before making the value available.
 *
 * This ensures that if node N and node M both write to channel C, the value of C will not be updated
 * until N and M have completed updating.
 * @internal
 */ class NamedBarrierValue extends base_js_1.BaseChannel {
    constructor(names){
        super();
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "NamedBarrierValue"
        });
        Object.defineProperty(this, "names", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        }); // Names of nodes that we want to wait for.
        Object.defineProperty(this, "seen", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.names = names;
        this.seen = new Set();
    }
    fromCheckpoint(checkpoint) {
        const empty = new NamedBarrierValue(this.names);
        if (typeof checkpoint !== "undefined") {
            empty.seen = new Set(checkpoint);
        }
        return empty;
    }
    update(values) {
        let updated = false;
        for (const nodeName of values){
            if (this.names.has(nodeName)) {
                if (!this.seen.has(nodeName)) {
                    this.seen.add(nodeName);
                    updated = true;
                }
            } else {
                throw new errors_js_1.InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
            }
        }
        return updated;
    }
    // If we have not yet seen all the node names we want to wait for,
    // throw an error to prevent continuing.
    get() {
        if (!(0, exports.areSetsEqual)(this.names, this.seen)) {
            throw new errors_js_1.EmptyChannelError();
        }
        return undefined;
    }
    checkpoint() {
        return [
            ...this.seen
        ];
    }
    consume() {
        if (this.seen && this.names && (0, exports.areSetsEqual)(this.seen, this.names)) {
            this.seen = new Set();
            return true;
        }
        return false;
    }
    isAvailable() {
        return !!this.names && (0, exports.areSetsEqual)(this.names, this.seen);
    }
}
exports.NamedBarrierValue = NamedBarrierValue;
/**
 * A channel that waits until all named values are received before making the value ready to be made available.
 * It is only made available after finish() is called.
 * @internal
 */ class NamedBarrierValueAfterFinish extends base_js_1.BaseChannel {
    constructor(names){
        super();
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "NamedBarrierValueAfterFinish"
        });
        Object.defineProperty(this, "names", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        }); // Names of nodes that we want to wait for.
        Object.defineProperty(this, "seen", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "finished", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.names = names;
        this.seen = new Set();
        this.finished = false;
    }
    fromCheckpoint(checkpoint) {
        const empty = new NamedBarrierValueAfterFinish(this.names);
        if (typeof checkpoint !== "undefined") {
            const [seen, finished] = checkpoint;
            empty.seen = new Set(seen);
            empty.finished = finished;
        }
        return empty;
    }
    update(values) {
        let updated = false;
        for (const nodeName of values){
            if (this.names.has(nodeName) && !this.seen.has(nodeName)) {
                this.seen.add(nodeName);
                updated = true;
            } else if (!this.names.has(nodeName)) {
                throw new errors_js_1.InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
            }
        }
        return updated;
    }
    get() {
        if (!this.finished || !(0, exports.areSetsEqual)(this.names, this.seen)) {
            throw new errors_js_1.EmptyChannelError();
        }
        return undefined;
    }
    checkpoint() {
        return [
            [
                ...this.seen
            ],
            this.finished
        ];
    }
    consume() {
        if (this.finished && this.seen && this.names && (0, exports.areSetsEqual)(this.seen, this.names)) {
            this.seen = new Set();
            this.finished = false;
            return true;
        }
        return false;
    }
    finish() {
        if (!this.finished && !!this.names && (0, exports.areSetsEqual)(this.names, this.seen)) {
            this.finished = true;
            return true;
        }
        return false;
    }
    isAvailable() {
        return this.finished && !!this.names && (0, exports.areSetsEqual)(this.names, this.seen);
    }
}
exports.NamedBarrierValueAfterFinish = NamedBarrierValueAfterFinish; //# sourceMappingURL=named_barrier_value.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/zod/meta.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.schemaMetaRegistry = exports.SchemaMetaRegistry = exports.META_EXTRAS_DESCRIPTION_PREFIX = void 0;
exports.withLangGraph = withLangGraph;
const types_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/utils/types.cjs [app-route] (ecmascript)");
const binop_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/binop.cjs [app-route] (ecmascript)");
const last_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/last_value.cjs [app-route] (ecmascript)");
exports.META_EXTRAS_DESCRIPTION_PREFIX = "lg:";
/**
 * A registry for storing and managing metadata associated with schemas.
 * This class provides methods to get, extend, remove, and check metadata for a given schema.
 */ class SchemaMetaRegistry {
    constructor(){
        /**
         * Internal map storing schema metadata.
         * @internal
         */ Object.defineProperty(this, "_map", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: new WeakMap()
        });
        /**
         * Cache for extended schfemas.
         * @internal
         */ Object.defineProperty(this, "_extensionCache", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: new Map()
        });
    }
    /**
     * Retrieves the metadata associated with a given schema.
     * @template TValue The value type of the schema.
     * @template TUpdate The update type of the schema (defaults to TValue).
     * @param schema The schema to retrieve metadata for.
     * @returns The associated SchemaMeta, or undefined if not present.
     */ get(schema) {
        return this._map.get(schema);
    }
    /**
     * Extends or sets the metadata for a given schema.
     * @template TValue The value type of the schema.
     * @template TUpdate The update type of the schema (defaults to TValue).
     * @param schema The schema to extend metadata for.
     * @param predicate A function that receives the existing metadata (or undefined) and returns the new metadata.
     */ extend(schema, predicate) {
        const existingMeta = this.get(schema);
        this._map.set(schema, predicate(existingMeta));
    }
    /**
     * Removes the metadata associated with a given schema.
     * @param schema The schema to remove metadata for.
     * @returns The SchemaMetaRegistry instance (for chaining).
     */ remove(schema) {
        this._map.delete(schema);
        return this;
    }
    /**
     * Checks if metadata exists for a given schema.
     * @param schema The schema to check.
     * @returns True if metadata exists, false otherwise.
     */ has(schema) {
        return this._map.has(schema);
    }
    /**
     * Returns a mapping of channel instances for each property in the schema
     * using the associated metadata in the registry.
     *
     * This is used to create the `channels` object that's passed to the `Graph` constructor.
     *
     * @template T The shape of the schema.
     * @param schema The schema to extract channels from.
     * @returns A mapping from property names to channel instances.
     */ getChannelsForSchema(schema) {
        const channels = {};
        const shape = (0, types_1.getInteropZodObjectShape)(schema);
        for (const [key, channelSchema] of Object.entries(shape)){
            const meta = this.get(channelSchema);
            if (meta?.reducer) {
                channels[key] = new binop_js_1.BinaryOperatorAggregate(meta.reducer.fn, meta.default);
            } else {
                channels[key] = new last_value_js_1.LastValue();
            }
        }
        return channels;
    }
    /**
     * Returns a modified schema that introspectively looks at all keys of the provided
     * object schema, and applies the augmentations based on meta provided with those keys
     * in the registry and the selectors provided in the `effects` parameter.
     *
     * This assumes that the passed in schema is the "root" schema object for a graph where
     * the keys of the schema are the channels of the graph. Because we need to represent
     * the input of a graph in a couple of different ways, the `effects` parameter allows
     * us to apply those augmentations based on pre determined conditions.
     *
     * @param schema The root schema object to extend.
     * @param effects The effects that are being applied.
     * @returns The extended schema.
     */ getExtendedChannelSchemas(schema, effects) {
        // If no effects are being applied, return the schema unchanged
        if (Object.keys(effects).length === 0) {
            return schema;
        }
        // Cache key is determined by looking at the effects that are being applied
        const cacheKey = Object.entries(effects).filter(([, v])=>v === true).sort(([a], [b])=>a.localeCompare(b)).map(([k, v])=>`${k}:${v}`).join("|");
        const cache = this._extensionCache.get(cacheKey) ?? new WeakMap();
        if (cache.has(schema)) return cache.get(schema);
        let modifiedSchema = schema;
        if (effects.withReducerSchema || effects.withJsonSchemaExtrasAsDescription) {
            const newShapeEntries = Object.entries((0, types_1.getInteropZodObjectShape)(schema)).map(([key, schema])=>{
                const meta = this.get(schema);
                let outputSchema = effects.withReducerSchema ? meta?.reducer?.schema ?? schema : schema;
                if (effects.withJsonSchemaExtrasAsDescription && meta?.jsonSchemaExtra) {
                    const description = (0, types_1.getSchemaDescription)(outputSchema) ?? (0, types_1.getSchemaDescription)(schema);
                    const strExtras = JSON.stringify({
                        ...meta.jsonSchemaExtra,
                        description
                    });
                    outputSchema = outputSchema.describe(`${exports.META_EXTRAS_DESCRIPTION_PREFIX}${strExtras}`);
                }
                return [
                    key,
                    outputSchema
                ];
            });
            modifiedSchema = (0, types_1.extendInteropZodObject)(schema, Object.fromEntries(newShapeEntries));
            if ((0, types_1.isZodSchemaV3)(modifiedSchema)) {
                modifiedSchema._def.unknownKeys = "strip";
            }
        }
        if (effects.asPartial) {
            modifiedSchema = (0, types_1.interopZodObjectPartial)(modifiedSchema);
        }
        cache.set(schema, modifiedSchema);
        this._extensionCache.set(cacheKey, cache);
        return modifiedSchema;
    }
}
exports.SchemaMetaRegistry = SchemaMetaRegistry;
exports.schemaMetaRegistry = new SchemaMetaRegistry();
function withLangGraph(schema, meta) {
    if (meta.reducer && !meta.default) {
        const defaultValueGetter = (0, types_1.getInteropZodDefaultGetter)(schema);
        if (defaultValueGetter != null) {
            // eslint-disable-next-line no-param-reassign
            meta.default = defaultValueGetter;
        }
    }
    if (meta.reducer) {
        const schemaWithReducer = Object.assign(schema, {
            lg_reducer_schema: meta.reducer?.schema ?? schema
        });
        exports.schemaMetaRegistry.extend(schemaWithReducer, ()=>meta);
        return schemaWithReducer;
    } else {
        exports.schemaMetaRegistry.extend(schema, ()=>meta);
        return schema;
    }
} //# sourceMappingURL=meta.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/state.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.CompiledStateGraph = exports.StateGraph = void 0;
exports.typedNode = typedNode;
/* eslint-disable @typescript-eslint/no-use-before-define */ const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const types_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/utils/types.cjs [app-route] (ecmascript)");
const base_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/base.cjs [app-route] (ecmascript)");
const graph_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/graph.cjs [app-route] (ecmascript)");
const write_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)");
const read_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/read.cjs [app-route] (ecmascript)");
const named_barrier_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/named_barrier_value.cjs [app-route] (ecmascript)");
const ephemeral_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/ephemeral_value.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const annotation_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/annotation.cjs [app-route] (ecmascript)");
const subgraph_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.cjs [app-route] (ecmascript)");
const last_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/last_value.cjs [app-route] (ecmascript)");
const meta_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/zod/meta.cjs [app-route] (ecmascript)");
const ROOT = "__root__";
const PartialStateSchema = Symbol.for("langgraph.state.partial");
/**
 * A graph whose nodes communicate by reading and writing to a shared state.
 * Each node takes a defined `State` as input and returns a `Partial<State>`.
 *
 * Each state key can optionally be annotated with a reducer function that
 * will be used to aggregate the values of that key received from multiple nodes.
 * The signature of a reducer function is (left: Value, right: UpdateValue) => Value.
 *
 * See {@link Annotation} for more on defining state.
 *
 * After adding nodes and edges to your graph, you must call `.compile()` on it before
 * you can use it.
 *
 * @example
 * ```ts
 * import {
 *   type BaseMessage,
 *   AIMessage,
 *   HumanMessage,
 * } from "@langchain/core/messages";
 * import { StateGraph, Annotation } from "@langchain/langgraph";
 *
 * // Define a state with a single key named "messages" that will
 * // combine a returned BaseMessage or arrays of BaseMessages
 * const StateAnnotation = Annotation.Root({
 *   sentiment: Annotation<string>,
 *   messages: Annotation<BaseMessage[]>({
 *     reducer: (left: BaseMessage[], right: BaseMessage | BaseMessage[]) => {
 *       if (Array.isArray(right)) {
 *         return left.concat(right);
 *       }
 *       return left.concat([right]);
 *     },
 *     default: () => [],
 *   }),
 * });
 *
 * const graphBuilder = new StateGraph(StateAnnotation);
 *
 * // A node in the graph that returns an object with a "messages" key
 * // will update the state by combining the existing value with the returned one.
 * const myNode = (state: typeof StateAnnotation.State) => {
 *   return {
 *     messages: [new AIMessage("Some new response")],
 *     sentiment: "positive",
 *   };
 * };
 *
 * const graph = graphBuilder
 *   .addNode("myNode", myNode)
 *   .addEdge("__start__", "myNode")
 *   .addEdge("myNode", "__end__")
 *   .compile();
 *
 * await graph.invoke({ messages: [new HumanMessage("how are you?")] });
 *
 * // {
 * //   messages: [HumanMessage("how are you?"), AIMessage("Some new response")],
 * //   sentiment: "positive",
 * // }
 * ```
 */ class StateGraph extends graph_js_1.Graph {
    constructor(fields, contextSchema){
        super();
        Object.defineProperty(this, "channels", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: {}
        });
        // TODO: this doesn't dedupe edges as in py, so worth fixing at some point
        Object.defineProperty(this, "waitingEdges", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: new Set()
        });
        /** @internal */ Object.defineProperty(this, "_schemaDefinition", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_schemaRuntimeDefinition", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_inputDefinition", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_inputRuntimeDefinition", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_outputDefinition", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_outputRuntimeDefinition", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /**
         * Map schemas to managed values
         * @internal
         */ Object.defineProperty(this, "_schemaDefinitions", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: new Map()
        });
        /** @internal */ Object.defineProperty(this, "_metaRegistry", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: meta_js_1.schemaMetaRegistry
        });
        /** @internal Used only for typing. */ Object.defineProperty(this, "_configSchema", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_configRuntimeSchema", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        if (isZodStateGraphArgsWithStateSchema(fields)) {
            const stateDef = this._metaRegistry.getChannelsForSchema(fields.state);
            const inputDef = fields.input != null ? this._metaRegistry.getChannelsForSchema(fields.input) : stateDef;
            const outputDef = fields.output != null ? this._metaRegistry.getChannelsForSchema(fields.output) : stateDef;
            this._schemaDefinition = stateDef;
            this._schemaRuntimeDefinition = fields.state;
            this._inputDefinition = inputDef;
            this._inputRuntimeDefinition = fields.input ?? PartialStateSchema;
            this._outputDefinition = outputDef;
            this._outputRuntimeDefinition = fields.output ?? fields.state;
        } else if ((0, types_1.isInteropZodObject)(fields)) {
            const stateDef = this._metaRegistry.getChannelsForSchema(fields);
            this._schemaDefinition = stateDef;
            this._schemaRuntimeDefinition = fields;
            this._inputDefinition = stateDef;
            this._inputRuntimeDefinition = PartialStateSchema;
            this._outputDefinition = stateDef;
            this._outputRuntimeDefinition = fields;
        } else if (isStateGraphArgsWithInputOutputSchemas(fields)) {
            this._schemaDefinition = fields.input.spec;
            this._inputDefinition = fields.input.spec;
            this._outputDefinition = fields.output.spec;
        } else if (isStateGraphArgsWithStateSchema(fields)) {
            this._schemaDefinition = fields.stateSchema.spec;
            this._inputDefinition = fields.input?.spec ?? this._schemaDefinition;
            this._outputDefinition = fields.output?.spec ?? this._schemaDefinition;
        } else if (isStateDefinition(fields) || isAnnotationRoot(fields)) {
            const spec = isAnnotationRoot(fields) ? fields.spec : fields;
            this._schemaDefinition = spec;
        } else if (isStateGraphArgs(fields)) {
            const spec = _getChannels(fields.channels);
            this._schemaDefinition = spec;
        } else {
            throw new Error("Invalid StateGraph input. Make sure to pass a valid Annotation.Root or Zod schema.");
        }
        this._inputDefinition ??= this._schemaDefinition;
        this._outputDefinition ??= this._schemaDefinition;
        this._addSchema(this._schemaDefinition);
        this._addSchema(this._inputDefinition);
        this._addSchema(this._outputDefinition);
        if ((0, types_1.isInteropZodObject)(contextSchema)) {
            this._configRuntimeSchema = contextSchema;
        }
    }
    get allEdges() {
        return new Set([
            ...this.edges,
            ...Array.from(this.waitingEdges).flatMap(([starts, end])=>starts.map((start)=>[
                        start,
                        end
                    ]))
        ]);
    }
    _addSchema(stateDefinition) {
        if (this._schemaDefinitions.has(stateDefinition)) {
            return;
        }
        // TODO: Support managed values
        this._schemaDefinitions.set(stateDefinition, stateDefinition);
        for (const [key, val] of Object.entries(stateDefinition)){
            let channel;
            if (typeof val === "function") {
                channel = val();
            } else {
                channel = val;
            }
            if (this.channels[key] !== undefined) {
                if (this.channels[key] !== channel) {
                    if (channel.lc_graph_name !== "LastValue") {
                        throw new Error(`Channel "${key}" already exists with a different type.`);
                    }
                }
            } else {
                this.channels[key] = channel;
            }
        }
    }
    addNode(...args) {
        function isMultipleNodes(args) {
            return args.length >= 1 && typeof args[0] !== "string";
        }
        const nodes = isMultipleNodes(args) // eslint-disable-line no-nested-ternary
         ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]).map(([key, action])=>[
                key,
                action,
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                action[Symbol.for("langgraph.state.node")] ?? undefined
            ]) : [
            [
                args[0],
                args[1],
                args[2]
            ]
        ];
        if (nodes.length === 0) {
            throw new Error("No nodes provided in `addNode`");
        }
        for (const [key, action, options] of nodes){
            if (key in this.channels) {
                throw new Error(`${key} is already being used as a state attribute (a.k.a. a channel), cannot also be used as a node name.`);
            }
            for (const reservedChar of [
                constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR,
                constants_js_1.CHECKPOINT_NAMESPACE_END
            ]){
                if (key.includes(reservedChar)) {
                    throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
                }
            }
            this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
            if (key in this.nodes) {
                throw new Error(`Node \`${key}\` already present.`);
            }
            if (key === constants_js_1.END || key === constants_js_1.START) {
                throw new Error(`Node \`${key}\` is reserved.`);
            }
            let inputSpec = this._schemaDefinition;
            if (options?.input !== undefined) {
                if ((0, types_1.isInteropZodObject)(options.input)) {
                    inputSpec = this._metaRegistry.getChannelsForSchema(options.input);
                } else if (options.input.spec !== undefined) {
                    inputSpec = options.input.spec;
                }
            }
            if (inputSpec !== undefined) {
                this._addSchema(inputSpec);
            }
            let runnable;
            if (runnables_1.Runnable.isRunnable(action)) {
                runnable = action;
            } else if (typeof action === "function") {
                runnable = new utils_js_1.RunnableCallable({
                    func: action,
                    name: key,
                    trace: false
                });
            } else {
                runnable = (0, runnables_1._coerceToRunnable)(action);
            }
            let cachePolicy = options?.cachePolicy;
            if (typeof cachePolicy === "boolean") {
                cachePolicy = cachePolicy ? {} : undefined;
            }
            const nodeSpec = {
                runnable: runnable,
                retryPolicy: options?.retryPolicy,
                cachePolicy,
                metadata: options?.metadata,
                input: inputSpec ?? this._schemaDefinition,
                subgraphs: (0, subgraph_js_1.isPregelLike)(runnable) ? [
                    runnable
                ] : options?.subgraphs,
                ends: options?.ends,
                defer: options?.defer
            };
            this.nodes[key] = nodeSpec;
        }
        return this;
    }
    addEdge(startKey, endKey) {
        if (typeof startKey === "string") {
            return super.addEdge(startKey, endKey);
        }
        if (this.compiled) {
            console.warn("Adding an edge to a graph that has already been compiled. This will " + "not be reflected in the compiled graph.");
        }
        for (const start of startKey){
            if (start === constants_js_1.END) {
                throw new Error("END cannot be a start node");
            }
            if (!Object.keys(this.nodes).some((node)=>node === start)) {
                throw new Error(`Need to add a node named "${start}" first`);
            }
        }
        if (endKey === constants_js_1.END) {
            throw new Error("END cannot be an end node");
        }
        if (!Object.keys(this.nodes).some((node)=>node === endKey)) {
            throw new Error(`Need to add a node named "${endKey}" first`);
        }
        this.waitingEdges.add([
            startKey,
            endKey
        ]);
        return this;
    }
    addSequence(nodes) {
        const parsedNodes = Array.isArray(nodes) ? nodes : Object.entries(nodes).map(([key, action])=>[
                key,
                action,
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                action[Symbol.for("langgraph.state.node")] ?? undefined
            ]);
        if (parsedNodes.length === 0) {
            throw new Error("Sequence requires at least one node.");
        }
        let previousNode;
        for (const [key, action, options] of parsedNodes){
            if (key in this.nodes) {
                throw new Error(`Node names must be unique: node with the name "${key}" already exists.`);
            }
            const validKey = key;
            this.addNode(validKey, action, options);
            if (previousNode != null) {
                this.addEdge(previousNode, validKey);
            }
            previousNode = validKey;
        }
        return this;
    }
    compile({ checkpointer, store, cache, interruptBefore, interruptAfter, name, description } = {}) {
        // validate the graph
        this.validate([
            ...Array.isArray(interruptBefore) ? interruptBefore : [],
            ...Array.isArray(interruptAfter) ? interruptAfter : []
        ]);
        // prepare output channels
        const outputKeys = Object.keys(this._schemaDefinitions.get(this._outputDefinition));
        const outputChannels = outputKeys.length === 1 && outputKeys[0] === ROOT ? ROOT : outputKeys;
        const streamKeys = Object.keys(this.channels);
        const streamChannels = streamKeys.length === 1 && streamKeys[0] === ROOT ? ROOT : streamKeys;
        // create empty compiled graph
        const compiled = new CompiledStateGraph({
            builder: this,
            checkpointer,
            interruptAfter,
            interruptBefore,
            autoValidate: false,
            nodes: {},
            channels: {
                ...this.channels,
                [constants_js_1.START]: new ephemeral_value_js_1.EphemeralValue()
            },
            inputChannels: constants_js_1.START,
            outputChannels,
            streamChannels,
            streamMode: "updates",
            store,
            cache,
            name,
            description
        });
        // attach nodes, edges and branches
        compiled.attachNode(constants_js_1.START);
        for (const [key, node] of Object.entries(this.nodes)){
            compiled.attachNode(key, node);
        }
        compiled.attachBranch(constants_js_1.START, constants_js_1.SELF, _getControlBranch(), {
            withReader: false
        });
        for (const [key] of Object.entries(this.nodes)){
            compiled.attachBranch(key, constants_js_1.SELF, _getControlBranch(), {
                withReader: false
            });
        }
        for (const [start, end] of this.edges){
            compiled.attachEdge(start, end);
        }
        for (const [starts, end] of this.waitingEdges){
            compiled.attachEdge(starts, end);
        }
        for (const [start, branches] of Object.entries(this.branches)){
            for (const [name, branch] of Object.entries(branches)){
                compiled.attachBranch(start, name, branch);
            }
        }
        return compiled.validate();
    }
}
exports.StateGraph = StateGraph;
function _getChannels(schema) {
    const channels = {};
    for (const [name, val] of Object.entries(schema)){
        if (name === ROOT) {
            channels[name] = (0, annotation_js_1.getChannel)(val);
        } else {
            const key = name;
            channels[name] = (0, annotation_js_1.getChannel)(val);
        }
    }
    return channels;
}
/**
 * Final result from building and compiling a {@link StateGraph}.
 * Should not be instantiated directly, only using the StateGraph `.compile()`
 * instance method.
 */ class CompiledStateGraph extends graph_js_1.CompiledGraph {
    constructor({ description, ...rest }){
        super(rest);
        /**
         * The description of the compiled graph.
         * This is used by the supervisor agent to describe the handoff to the agent.
         */ Object.defineProperty(this, "description", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        /** @internal */ Object.defineProperty(this, "_metaRegistry", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: meta_js_1.schemaMetaRegistry
        });
        this.description = description;
    }
    attachNode(key, node) {
        let outputKeys;
        if (key === constants_js_1.START) {
            // Get input schema keys excluding managed values
            outputKeys = Object.entries(this.builder._schemaDefinitions.get(this.builder._inputDefinition)).map(([k])=>k);
        } else {
            outputKeys = Object.keys(this.builder.channels);
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        function _getRoot(input) {
            if ((0, constants_js_1.isCommand)(input)) {
                if (input.graph === constants_js_1.Command.PARENT) {
                    return null;
                }
                return input._updateAsTuples();
            } else if (Array.isArray(input) && input.length > 0 && input.some((i)=>(0, constants_js_1.isCommand)(i))) {
                const updates = [];
                for (const i of input){
                    if ((0, constants_js_1.isCommand)(i)) {
                        if (i.graph === constants_js_1.Command.PARENT) {
                            continue;
                        }
                        updates.push(...i._updateAsTuples());
                    } else {
                        updates.push([
                            ROOT,
                            i
                        ]);
                    }
                }
                return updates;
            } else if (input != null) {
                return [
                    [
                        ROOT,
                        input
                    ]
                ];
            }
            return null;
        }
        // to avoid name collision below
        const nodeKey = key;
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        function _getUpdates(input) {
            if (!input) {
                return null;
            } else if ((0, constants_js_1.isCommand)(input)) {
                if (input.graph === constants_js_1.Command.PARENT) {
                    return null;
                }
                return input._updateAsTuples().filter(([k])=>outputKeys.includes(k));
            } else if (Array.isArray(input) && input.length > 0 && input.some(constants_js_1.isCommand)) {
                const updates = [];
                for (const item of input){
                    if ((0, constants_js_1.isCommand)(item)) {
                        if (item.graph === constants_js_1.Command.PARENT) {
                            continue;
                        }
                        updates.push(...item._updateAsTuples().filter(([k])=>outputKeys.includes(k)));
                    } else {
                        const itemUpdates = _getUpdates(item);
                        if (itemUpdates) {
                            updates.push(...itemUpdates ?? []);
                        }
                    }
                }
                return updates;
            } else if (typeof input === "object" && !Array.isArray(input)) {
                return Object.entries(input).filter(([k])=>outputKeys.includes(k));
            } else {
                const typeofInput = Array.isArray(input) ? "array" : typeof input;
                throw new errors_js_1.InvalidUpdateError(`Expected node "${nodeKey.toString()}" to return an object or an array containing at least one Command object, received ${typeofInput}`, {
                    lc_error_code: "INVALID_GRAPH_NODE_RETURN_VALUE"
                });
            }
        }
        const stateWriteEntries = [
            {
                value: write_js_1.PASSTHROUGH,
                mapper: new utils_js_1.RunnableCallable({
                    func: outputKeys.length && outputKeys[0] === ROOT ? _getRoot : _getUpdates,
                    trace: false,
                    recurse: false
                })
            }
        ];
        // add node and output channel
        if (key === constants_js_1.START) {
            this.nodes[key] = new read_js_1.PregelNode({
                tags: [
                    constants_js_1.TAG_HIDDEN
                ],
                triggers: [
                    constants_js_1.START
                ],
                channels: [
                    constants_js_1.START
                ],
                writers: [
                    new write_js_1.ChannelWrite(stateWriteEntries, [
                        constants_js_1.TAG_HIDDEN
                    ])
                ]
            });
        } else {
            const inputDefinition = node?.input ?? this.builder._schemaDefinition;
            const inputValues = Object.fromEntries(Object.keys(this.builder._schemaDefinitions.get(inputDefinition)).map((k)=>[
                    k,
                    k
                ]));
            const isSingleInput = Object.keys(inputValues).length === 1 && ROOT in inputValues;
            const branchChannel = `branch:to:${key}`;
            this.channels[branchChannel] = node?.defer ? new last_value_js_1.LastValueAfterFinish() : new ephemeral_value_js_1.EphemeralValue(false);
            this.nodes[key] = new read_js_1.PregelNode({
                triggers: [
                    branchChannel
                ],
                // read state keys
                channels: isSingleInput ? Object.keys(inputValues) : inputValues,
                // publish to state keys
                writers: [
                    new write_js_1.ChannelWrite(stateWriteEntries, [
                        constants_js_1.TAG_HIDDEN
                    ])
                ],
                mapper: isSingleInput ? undefined : (input)=>{
                    return Object.fromEntries(Object.entries(input).filter(([k])=>k in inputValues));
                },
                bound: node?.runnable,
                metadata: node?.metadata,
                retryPolicy: node?.retryPolicy,
                cachePolicy: node?.cachePolicy,
                subgraphs: node?.subgraphs,
                ends: node?.ends
            });
        }
    }
    attachEdge(starts, end) {
        if (end === constants_js_1.END) return;
        if (typeof starts === "string") {
            this.nodes[starts].writers.push(new write_js_1.ChannelWrite([
                {
                    channel: `branch:to:${end}`,
                    value: null
                }
            ], [
                constants_js_1.TAG_HIDDEN
            ]));
        } else if (Array.isArray(starts)) {
            const channelName = `join:${starts.join("+")}:${end}`;
            // register channel
            this.channels[channelName] = this.builder.nodes[end].defer ? new named_barrier_value_js_1.NamedBarrierValueAfterFinish(new Set(starts)) : new named_barrier_value_js_1.NamedBarrierValue(new Set(starts));
            // subscribe to channel
            this.nodes[end].triggers.push(channelName);
            // publish to channel
            for (const start of starts){
                this.nodes[start].writers.push(new write_js_1.ChannelWrite([
                    {
                        channel: channelName,
                        value: start
                    }
                ], [
                    constants_js_1.TAG_HIDDEN
                ]));
            }
        }
    }
    attachBranch(start, _, branch, options = {
        withReader: true
    }) {
        const branchWriter = async (packets, config)=>{
            const filteredPackets = packets.filter((p)=>p !== constants_js_1.END);
            if (!filteredPackets.length) return;
            const writes = filteredPackets.map((p)=>{
                if ((0, constants_js_1._isSend)(p)) return p;
                return {
                    channel: p === constants_js_1.END ? p : `branch:to:${p}`,
                    value: start
                };
            });
            await write_js_1.ChannelWrite.doWrite({
                ...config,
                tags: (config.tags ?? []).concat([
                    constants_js_1.TAG_HIDDEN
                ])
            }, writes);
        };
        // attach branch publisher
        this.nodes[start].writers.push(branch.run(branchWriter, // reader
        options.withReader ? (config)=>read_js_1.ChannelRead.doRead(config, this.streamChannels ?? this.outputChannels, true) : undefined));
    }
    async _validateInput(input) {
        if (input == null) return input;
        const schema = (()=>{
            const input = this.builder._inputRuntimeDefinition;
            const schema = this.builder._schemaRuntimeDefinition;
            const apply = (schema)=>{
                if (schema == null) return undefined;
                return this._metaRegistry.getExtendedChannelSchemas(schema, {
                    withReducerSchema: true
                });
            };
            if ((0, types_1.isInteropZodObject)(input)) return apply(input);
            if (input === PartialStateSchema) {
                return (0, types_1.interopZodObjectPartial)(apply(schema));
            }
            return undefined;
        })();
        if ((0, constants_js_1.isCommand)(input)) {
            const parsedInput = input;
            if (input.update && schema != null) parsedInput.update = (0, types_1.interopParse)(schema, input.update);
            return parsedInput;
        }
        if (schema != null) return (0, types_1.interopParse)(schema, input);
        return input;
    }
    async _validateContext(config) {
        const configSchema = this.builder._configRuntimeSchema;
        if ((0, types_1.isInteropZodObject)(configSchema)) (0, types_1.interopParse)(configSchema, config);
        return config;
    }
}
exports.CompiledStateGraph = CompiledStateGraph;
function isStateDefinition(obj) {
    return typeof obj === "object" && obj !== null && !Array.isArray(obj) && Object.keys(obj).length > 0 && Object.values(obj).every((v)=>typeof v === "function" || (0, base_js_1.isBaseChannel)(v));
}
function isAnnotationRoot(obj) {
    return typeof obj === "object" && obj !== null && "lc_graph_name" in obj && obj.lc_graph_name === "AnnotationRoot";
}
function isStateGraphArgs(obj) {
    return typeof obj === "object" && obj !== null && obj.channels !== undefined;
}
function isStateGraphArgsWithStateSchema(obj) {
    return typeof obj === "object" && obj !== null && obj.stateSchema !== undefined;
}
function isStateGraphArgsWithInputOutputSchemas(obj) {
    return typeof obj === "object" && obj !== null && // eslint-disable-next-line @typescript-eslint/no-explicit-any
    obj.stateSchema === undefined && obj.input !== undefined && obj.output !== undefined;
}
function isZodStateGraphArgsWithStateSchema(value) {
    if (typeof value !== "object" || value == null) {
        return false;
    }
    if (!("state" in value) || !(0, types_1.isInteropZodObject)(value.state)) {
        return false;
    }
    if ("input" in value && !(0, types_1.isInteropZodObject)(value.input)) {
        return false;
    }
    if ("output" in value && !(0, types_1.isInteropZodObject)(value.output)) {
        return false;
    }
    return true;
}
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function _controlBranch(value) {
    if ((0, constants_js_1._isSend)(value)) {
        return [
            value
        ];
    }
    const commands = [];
    if ((0, constants_js_1.isCommand)(value)) {
        commands.push(value);
    } else if (Array.isArray(value)) {
        commands.push(...value.filter(constants_js_1.isCommand));
    }
    const destinations = [];
    for (const command of commands){
        if (command.graph === constants_js_1.Command.PARENT) {
            throw new errors_js_1.ParentCommand(command);
        }
        if ((0, constants_js_1._isSend)(command.goto)) {
            destinations.push(command.goto);
        } else if (typeof command.goto === "string") {
            destinations.push(command.goto);
        } else {
            if (Array.isArray(command.goto)) {
                destinations.push(...command.goto);
            }
        }
    }
    return destinations;
}
function _getControlBranch() {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const CONTROL_BRANCH_PATH = new utils_js_1.RunnableCallable({
        func: _controlBranch,
        tags: [
            constants_js_1.TAG_HIDDEN
        ],
        trace: false,
        recurse: false,
        name: "<control_branch>"
    });
    return new graph_js_1.Branch({
        path: CONTROL_BRANCH_PATH
    });
}
function typedNode(_state, _options) {
    return (func, options)=>{
        Object.assign(func, {
            [Symbol.for("langgraph.state.node")]: options
        });
        return func;
    };
} //# sourceMappingURL=state.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/message.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.MessageGraph = exports.REMOVE_ALL_MESSAGES = void 0;
exports.messagesStateReducer = messagesStateReducer;
exports.pushMessage = pushMessage;
const messages_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/messages.cjs [app-route] (ecmascript)");
const uuid_1 = __turbopack_context__.r("[project]/node_modules/uuid/dist/esm-node/index.js [app-route] (ecmascript)");
const state_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/state.cjs [app-route] (ecmascript)");
exports.REMOVE_ALL_MESSAGES = "__remove_all__";
/**
 * Prebuilt reducer that combines returned messages.
 * Can handle standard messages and special modifiers like {@link RemoveMessage}
 * instances.
 */ function messagesStateReducer(left, right) {
    const leftArray = Array.isArray(left) ? left : [
        left
    ];
    const rightArray = Array.isArray(right) ? right : [
        right
    ];
    // coerce to message
    const leftMessages = leftArray.map(messages_1.coerceMessageLikeToMessage);
    const rightMessages = rightArray.map(messages_1.coerceMessageLikeToMessage);
    // assign missing ids
    for (const m of leftMessages){
        if (m.id === null || m.id === undefined) {
            m.id = (0, uuid_1.v4)();
            m.lc_kwargs.id = m.id;
        }
    }
    let removeAllIdx;
    for(let i = 0; i < rightMessages.length; i += 1){
        const m = rightMessages[i];
        if (m.id === null || m.id === undefined) {
            m.id = (0, uuid_1.v4)();
            m.lc_kwargs.id = m.id;
        }
        if (m.getType() === "remove" && m.id === exports.REMOVE_ALL_MESSAGES) {
            removeAllIdx = i;
        }
    }
    if (removeAllIdx != null) return rightMessages.slice(removeAllIdx + 1);
    // merge
    const merged = [
        ...leftMessages
    ];
    const mergedById = new Map(merged.map((m, i)=>[
            m.id,
            i
        ]));
    const idsToRemove = new Set();
    for (const m of rightMessages){
        const existingIdx = mergedById.get(m.id);
        if (existingIdx !== undefined) {
            if (m.getType() === "remove") {
                idsToRemove.add(m.id);
            } else {
                idsToRemove.delete(m.id);
                merged[existingIdx] = m;
            }
        } else {
            if (m.getType() === "remove") {
                throw new Error(`Attempting to delete a message with an ID that doesn't exist ('${m.id}')`);
            }
            mergedById.set(m.id, merged.length);
            merged.push(m);
        }
    }
    return merged.filter((m)=>!idsToRemove.has(m.id));
}
/** @ignore */ class MessageGraph extends state_js_1.StateGraph {
    constructor(){
        super({
            channels: {
                __root__: {
                    reducer: messagesStateReducer,
                    default: ()=>[]
                }
            }
        });
    }
}
exports.MessageGraph = MessageGraph;
function pushMessage(message, config, options) {
    let stateKey = options?.stateKey ?? "messages";
    if (options?.stateKey === null) {
        stateKey = undefined;
    }
    // coerce to message
    const validMessage = (0, messages_1.coerceMessageLikeToMessage)(message);
    if (!validMessage.id) throw new Error("Message ID is required.");
    const callbacks = (()=>{
        if (Array.isArray(config.callbacks)) {
            return config.callbacks;
        }
        if (typeof config.callbacks !== "undefined") {
            return config.callbacks.handlers;
        }
        return [];
    })();
    const messagesHandler = callbacks.find((cb)=>"name" in cb && cb.name === "StreamMessagesHandler");
    if (messagesHandler) {
        const metadata = config.metadata ?? {};
        const namespace = (metadata.langgraph_checkpoint_ns ?? "").split("|");
        messagesHandler._emit([
            namespace,
            metadata
        ], validMessage, undefined, false);
    }
    if (stateKey) {
        config.configurable?.__pregel_send?.([
            [
                stateKey,
                validMessage
            ]
        ]);
    }
    return validMessage;
} //# sourceMappingURL=message.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.REMOVE_ALL_MESSAGES = exports.messagesStateReducer = exports.MessageGraph = exports.typedNode = exports.CompiledStateGraph = exports.StateGraph = exports.Graph = exports.AnnotationRoot = exports.Annotation = void 0;
var annotation_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/annotation.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "Annotation", {
    enumerable: true,
    get: function() {
        return annotation_js_1.Annotation;
    }
});
Object.defineProperty(exports, "AnnotationRoot", {
    enumerable: true,
    get: function() {
        return annotation_js_1.AnnotationRoot;
    }
});
var graph_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/graph.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "Graph", {
    enumerable: true,
    get: function() {
        return graph_js_1.Graph;
    }
});
var state_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/state.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "StateGraph", {
    enumerable: true,
    get: function() {
        return state_js_1.StateGraph;
    }
});
Object.defineProperty(exports, "CompiledStateGraph", {
    enumerable: true,
    get: function() {
        return state_js_1.CompiledStateGraph;
    }
});
Object.defineProperty(exports, "typedNode", {
    enumerable: true,
    get: function() {
        return state_js_1.typedNode;
    }
});
var message_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/message.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "MessageGraph", {
    enumerable: true,
    get: function() {
        return message_js_1.MessageGraph;
    }
});
Object.defineProperty(exports, "messagesStateReducer", {
    enumerable: true,
    get: function() {
        return message_js_1.messagesStateReducer;
    }
});
Object.defineProperty(exports, "REMOVE_ALL_MESSAGES", {
    enumerable: true,
    get: function() {
        return message_js_1.REMOVE_ALL_MESSAGES;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/func/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.entrypoint = void 0;
exports.task = task;
exports.getPreviousState = getPreviousState;
const singletons_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/singletons.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/index.cjs [app-route] (ecmascript)");
const read_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/read.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const ephemeral_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/ephemeral_value.cjs [app-route] (ecmascript)");
const call_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/call.cjs [app-route] (ecmascript)");
const last_value_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/last_value.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const write_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/write.cjs [app-route] (ecmascript)");
/**
 * Define a LangGraph task using the `task` function.
 *
 * Tasks can only be called from within an {@link entrypoint} or from within a StateGraph.
 * A task can be called like a regular function with the following differences:
 *
 * - When a checkpointer is enabled, the function inputs and outputs must be serializable.
 * - The wrapped function can only be called from within an entrypoint or StateGraph.
 * - Calling the function produces a promise. This makes it easy to parallelize tasks.
 *
 * @typeParam ArgsT - The type of arguments the task function accepts
 * @typeParam OutputT - The type of value the task function returns
 * @param optionsOrName - Either an {@link TaskOptions} object, or a string for the name of the task
 * @param func - The function that executes this task
 * @returns A proxy function that accepts the same arguments as the original and always returns the result as a Promise
 *
 * @example basic example
 * ```typescript
 * const addOne = task("add", async (a: number) => a + 1);
 *
 * const workflow = entrypoint("example", async (numbers: number[]) => {
 *   const promises = numbers.map(n => addOne(n));
 *   const results = await Promise.all(promises);
 *   return results;
 * });
 *
 * // Call the entrypoint
 * await workflow.invoke([1, 2, 3]); // Returns [2, 3, 4]
 * ```
 *
 * @example using a retry policy
 * ```typescript
 * const addOne = task({
 *     name: "add",
 *     retry: { maxAttempts: 3 }
 *   },
 *   async (a: number) => a + 1
 * );
 *
 * const workflow = entrypoint("example", async (numbers: number[]) => {
 *   const promises = numbers.map(n => addOne(n));
 *   const results = await Promise.all(promises);
 *   return results;
 * });
 * ```
 */ function task(optionsOrName, func) {
    const options = typeof optionsOrName === "string" ? {
        name: optionsOrName,
        retry: undefined,
        cachePolicy: undefined
    } : optionsOrName;
    const { name, retry } = options;
    if ((0, utils_js_1.isAsyncGeneratorFunction)(func) || (0, utils_js_1.isGeneratorFunction)(func)) {
        throw new Error("Generators are disallowed as tasks. For streaming responses, use config.write.");
    }
    const cachePolicy = options.cachePolicy ?? // `cache` was mistakingly used as an alias for `cachePolicy` in v0.3.x,
    // TODO: remove in 1.x
    ("cache" in options ? options.cache : undefined);
    let cache;
    if (typeof cachePolicy === "boolean") {
        cache = cachePolicy ? {} : undefined;
    } else {
        cache = cachePolicy;
    }
    return (...args)=>{
        return (0, call_js_1.call)({
            func,
            name,
            retry,
            cache
        }, ...args);
    };
}
/**
 * Define a LangGraph workflow using the `entrypoint` function.
 *
 * ### Function signature
 *
 * The wrapped function must accept at most **two parameters**. The first parameter
 * is the input to the function. The second (optional) parameter is a
 * {@link LangGraphRunnableConfig} object. If you wish to pass multiple parameters to
 * the function, you can pass them as an object.
 *
 * ### Helper functions
 *
 * #### Streaming
 * To write data to the "custom" stream, use the {@link getWriter} function, or the
 * {@link LangGraphRunnableConfig.writer} property.
 *
 * #### State management
 * The {@link getPreviousState} function can be used to access the previous state
 * that was returned from the last invocation of the entrypoint on the same thread id.
 *
 * If you wish to save state other than the return value, you can use the
 * {@link entrypoint.final} function.
 *
 * @typeParam InputT - The type of input the entrypoint accepts
 * @typeParam OutputT - The type of output the entrypoint produces
 * @param optionsOrName - Either an {@link EntrypointOptions} object, or a string for the name of the entrypoint
 * @param func - The function that executes this entrypoint
 * @returns A {@link Pregel} instance that can be run to execute the workflow
 *
 * @example Using entrypoint and tasks
 * ```typescript
 * import { task, entrypoint } from "@langchain/langgraph";
 * import { MemorySaver } from "@langchain/langgraph-checkpoint";
 * import { interrupt, Command } from "@langchain/langgraph";
 *
 * const composeEssay = task("compose", async (topic: string) => {
 *   await new Promise(r => setTimeout(r, 1000)); // Simulate slow operation
 *   return `An essay about ${topic}`;
 * });
 *
 * const reviewWorkflow = entrypoint({
 *   name: "review",
 *   checkpointer: new MemorySaver()
 * }, async (topic: string) => {
 *   const essay = await composeEssay(topic);
 *   const humanReview = await interrupt({
 *     question: "Please provide a review",
 *     essay
 *   });
 *   return {
 *     essay,
 *     review: humanReview
 *   };
 * });
 *
 * // Example configuration for the workflow
 * const config = {
 *   configurable: {
 *     thread_id: "some_thread"
 *   }
 * };
 *
 * // Topic for the essay
 * const topic = "cats";
 *
 * // Stream the workflow to generate the essay and await human review
 * for await (const result of reviewWorkflow.stream(topic, config)) {
 *   console.log(result);
 * }
 *
 * // Example human review provided after the interrupt
 * const humanReview = "This essay is great.";
 *
 * // Resume the workflow with the provided human review
 * for await (const result of reviewWorkflow.stream(new Command({ resume: humanReview }), config)) {
 *   console.log(result);
 * }
 * ```
 *
 * @example Accessing the previous return value
 * ```typescript
 * import { entrypoint, getPreviousState } from "@langchain/langgraph";
 * import { MemorySaver } from "@langchain/langgraph-checkpoint";
 *
 * const accumulator = entrypoint({
 *   name: "accumulator",
 *   checkpointer: new MemorySaver()
 * }, async (input: string) => {
 *   const previous = getPreviousState<number>();
 *   return previous !== undefined ? `${previous } ${input}` : input;
 * });
 *
 * const config = {
 *   configurable: {
 *     thread_id: "some_thread"
 *   }
 * };
 * await accumulator.invoke("hello", config); // returns "hello"
 * await accumulator.invoke("world", config); // returns "hello world"
 * ```
 *
 * @example Using entrypoint.final to save a value
 * ```typescript
 * import { entrypoint, getPreviousState } from "@langchain/langgraph";
 * import { MemorySaver } from "@langchain/langgraph-checkpoint";
 *
 * const myWorkflow = entrypoint({
 *   name: "accumulator",
 *   checkpointer: new MemorySaver()
 * }, async (num: number) => {
 *   const previous = getPreviousState<number>();
 *
 *   // This will return the previous value to the caller, saving
 *   // 2 * num to the checkpoint, which will be used in the next invocation
 *   // for the `previous` parameter.
 *   return entrypoint.final({
 *     value: previous ?? 0,
 *     save: 2 * num
 *   });
 * });
 *
 * const config = {
 *   configurable: {
 *     thread_id: "some_thread"
 *   }
 * };
 *
 * await myWorkflow.invoke(3, config); // 0 (previous was undefined)
 * await myWorkflow.invoke(1, config); // 6 (previous was 3 * 2 from the previous invocation)
 * ```
 */ exports.entrypoint = function entrypoint(optionsOrName, func) {
    const { name, checkpointer, store, cache } = typeof optionsOrName === "string" ? {
        name: optionsOrName,
        checkpointer: undefined,
        store: undefined
    } : optionsOrName;
    if ((0, utils_js_1.isAsyncGeneratorFunction)(func) || (0, utils_js_1.isGeneratorFunction)(func)) {
        throw new Error("Generators are disallowed as entrypoints. For streaming responses, use config.write.");
    }
    const streamMode = "updates";
    const bound = (0, call_js_1.getRunnableForEntrypoint)(name, func);
    // Helper to check if a value is an EntrypointFinal
    function isEntrypointFinal(value) {
        return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "__pregel_final";
    }
    // Helper function to pluck the return value from EntrypointFinal or passthrough
    const pluckReturnValue = new utils_js_1.RunnableCallable({
        name: "pluckReturnValue",
        func: (value)=>{
            return isEntrypointFinal(value) ? value.value : value;
        }
    });
    // Helper function to pluck the save value from EntrypointFinal or passthrough
    const pluckSaveValue = new utils_js_1.RunnableCallable({
        name: "pluckSaveValue",
        func: (value)=>{
            return isEntrypointFinal(value) ? value.save : value;
        }
    });
    const entrypointNode = new read_js_1.PregelNode({
        bound,
        triggers: [
            constants_js_1.START
        ],
        channels: [
            constants_js_1.START
        ],
        writers: [
            new write_js_1.ChannelWrite([
                {
                    channel: constants_js_1.END,
                    value: write_js_1.PASSTHROUGH,
                    mapper: pluckReturnValue
                },
                {
                    channel: constants_js_1.PREVIOUS,
                    value: write_js_1.PASSTHROUGH,
                    mapper: pluckSaveValue
                }
            ], [
                constants_js_1.TAG_HIDDEN
            ])
        ]
    });
    return new index_js_1.Pregel({
        name,
        checkpointer,
        nodes: {
            [name]: entrypointNode
        },
        channels: {
            [constants_js_1.START]: new ephemeral_value_js_1.EphemeralValue(),
            [constants_js_1.END]: new last_value_js_1.LastValue(),
            [constants_js_1.PREVIOUS]: new last_value_js_1.LastValue()
        },
        inputChannels: constants_js_1.START,
        outputChannels: constants_js_1.END,
        streamChannels: constants_js_1.END,
        streamMode,
        store,
        cache
    });
};
// documented by the EntrypointFunction interface
exports.entrypoint.final = function final({ value, save }) {
    return {
        value,
        save,
        __lg_type: "__pregel_final"
    };
};
/**
 * A helper utility function for use with the functional API that returns the previous
 * state from the checkpoint from the last invocation of the current thread.
 *
 * This function allows workflows to access state that was saved in previous runs
 * using {@link entrypoint.final}.
 *
 * @typeParam StateT - The type of the state that was previously saved
 * @returns The previous saved state from the last invocation of the current thread
 *
 * @example
 * ```typescript
 * const previousState = getPreviousState<{ counter: number }>();
 * const newCount = (previousState?.counter ?? 0) + 1;
 * ```
 */ function getPreviousState() {
    const config = singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    return config.configurable?.[constants_js_1.CONFIG_KEY_PREVIOUS_STATE];
} //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/graph/messages_annotation.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/* __LC_ALLOW_ENTRYPOINT_SIDE_EFFECTS__ */ Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.MessagesZodState = exports.MessagesZodMeta = exports.MessagesAnnotation = void 0;
const v3_1 = __turbopack_context__.r("[project]/node_modules/zod/v3/index.cjs [app-route] (ecmascript)");
const annotation_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/annotation.cjs [app-route] (ecmascript)");
const message_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/message.cjs [app-route] (ecmascript)");
const meta_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/zod/meta.cjs [app-route] (ecmascript)");
/**
 * Prebuilt state annotation that combines returned messages.
 * Can handle standard messages and special modifiers like {@link RemoveMessage}
 * instances.
 *
 * Specifically, importing and using the prebuilt MessagesAnnotation like this:
 *
 * @example
 * ```ts
 * import { MessagesAnnotation, StateGraph } from "@langchain/langgraph";
 *
 * const graph = new StateGraph(MessagesAnnotation)
 *   .addNode(...)
 *   ...
 * ```
 *
 * Is equivalent to initializing your state manually like this:
 *
 * @example
 * ```ts
 * import { BaseMessage } from "@langchain/core/messages";
 * import { Annotation, StateGraph, messagesStateReducer } from "@langchain/langgraph";
 *
 * export const StateAnnotation = Annotation.Root({
 *   messages: Annotation<BaseMessage[]>({
 *     reducer: messagesStateReducer,
 *     default: () => [],
 *   }),
 * });
 *
 * const graph = new StateGraph(StateAnnotation)
 *   .addNode(...)
 *   ...
 * ```
 */ exports.MessagesAnnotation = annotation_js_1.Annotation.Root({
    messages: (0, annotation_js_1.Annotation)({
        reducer: message_js_1.messagesStateReducer,
        default: ()=>[]
    })
});
/**
 * Prebuilt schema meta for Zod state definition.
 *
 * @example
 * ```ts
 * import { z } from "zod/v4-mini";
 * import { MessagesZodState, StateGraph } from "@langchain/langgraph";
 *
 * const AgentState = z.object({
 *   messages: z.custom<BaseMessage[]>().register(registry, MessagesZodMeta),
 * });
 * ```
 */ exports.MessagesZodMeta = {
    reducer: {
        fn: message_js_1.messagesStateReducer
    },
    jsonSchemaExtra: {
        langgraph_type: "messages"
    },
    default: ()=>[]
};
/**
 * Prebuilt state object that uses Zod to combine returned messages.
 * This utility is synonymous with the `MessagesAnnotation` annotation,
 * but uses Zod as the way to express messages state.
 *
 * You can use import and use this prebuilt schema like this:
 *
 * @example
 * ```ts
 * import { MessagesZodState, StateGraph } from "@langchain/langgraph";
 *
 * const graph = new StateGraph(MessagesZodState)
 *   .addNode(...)
 *   ...
 * ```
 *
 * Which is equivalent to initializing the schema object manually like this:
 *
 * @example
 * ```ts
 * import { z } from "zod";
 * import type { BaseMessage, BaseMessageLike } from "@langchain/core/messages";
 * import { StateGraph, messagesStateReducer } from "@langchain/langgraph";
 * import "@langchain/langgraph/zod";
 *
 * const AgentState = z.object({
 *   messages: z
 *     .custom<BaseMessage[]>()
 *     .default(() => [])
 *     .langgraph.reducer(
 *        messagesStateReducer,
 *        z.custom<BaseMessageLike | BaseMessageLike[]>()
 *     ),
 * });
 * const graph = new StateGraph(AgentState)
 *   .addNode(...)
 *   ...
 * ```
 */ exports.MessagesZodState = v3_1.z.object({
    messages: (0, meta_js_1.withLangGraph)(v3_1.z.custom(), exports.MessagesZodMeta)
}); //# sourceMappingURL=messages_annotation.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/web.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

var __createBinding = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = {
            enumerable: true,
            get: function() {
                return m[k];
            }
        };
    }
    Object.defineProperty(o, k2, desc);
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
});
var __exportStar = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__exportStar || function(m, exports1) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports1, p)) __createBinding(exports1, m, p);
};
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.MessagesZodMeta = exports.MessagesZodState = exports.MessagesAnnotation = exports.task = exports.entrypoint = exports.InMemoryStore = exports.AsyncBatchedStore = exports.BaseStore = exports.BaseCheckpointSaver = exports.emptyCheckpoint = exports.copyCheckpoint = exports.MemorySaver = exports.isInterrupted = exports.INTERRUPT = exports.END = exports.START = exports.isCommand = exports.Command = exports.Send = exports.BinaryOperatorAggregate = exports.BaseChannel = exports.Annotation = exports.REMOVE_ALL_MESSAGES = exports.addMessages = exports.messagesStateReducer = exports.typedNode = exports.MessageGraph = exports.CompiledStateGraph = exports.StateGraph = exports.Graph = void 0;
var index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/index.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "Graph", {
    enumerable: true,
    get: function() {
        return index_js_1.Graph;
    }
});
Object.defineProperty(exports, "StateGraph", {
    enumerable: true,
    get: function() {
        return index_js_1.StateGraph;
    }
});
Object.defineProperty(exports, "CompiledStateGraph", {
    enumerable: true,
    get: function() {
        return index_js_1.CompiledStateGraph;
    }
});
Object.defineProperty(exports, "MessageGraph", {
    enumerable: true,
    get: function() {
        return index_js_1.MessageGraph;
    }
});
Object.defineProperty(exports, "typedNode", {
    enumerable: true,
    get: function() {
        return index_js_1.typedNode;
    }
});
Object.defineProperty(exports, "messagesStateReducer", {
    enumerable: true,
    get: function() {
        return index_js_1.messagesStateReducer;
    }
});
Object.defineProperty(exports, "addMessages", {
    enumerable: true,
    get: function() {
        return index_js_1.messagesStateReducer;
    }
});
Object.defineProperty(exports, "REMOVE_ALL_MESSAGES", {
    enumerable: true,
    get: function() {
        return index_js_1.REMOVE_ALL_MESSAGES;
    }
});
Object.defineProperty(exports, "Annotation", {
    enumerable: true,
    get: function() {
        return index_js_1.Annotation;
    }
});
__exportStar(__turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)"), exports);
var index_js_2 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/channels/index.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "BaseChannel", {
    enumerable: true,
    get: function() {
        return index_js_2.BaseChannel;
    }
});
Object.defineProperty(exports, "BinaryOperatorAggregate", {
    enumerable: true,
    get: function() {
        return index_js_2.BinaryOperatorAggregate;
    }
});
var constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "Send", {
    enumerable: true,
    get: function() {
        return constants_js_1.Send;
    }
});
Object.defineProperty(exports, "Command", {
    enumerable: true,
    get: function() {
        return constants_js_1.Command;
    }
});
Object.defineProperty(exports, "isCommand", {
    enumerable: true,
    get: function() {
        return constants_js_1.isCommand;
    }
});
Object.defineProperty(exports, "START", {
    enumerable: true,
    get: function() {
        return constants_js_1.START;
    }
});
Object.defineProperty(exports, "END", {
    enumerable: true,
    get: function() {
        return constants_js_1.END;
    }
});
Object.defineProperty(exports, "INTERRUPT", {
    enumerable: true,
    get: function() {
        return constants_js_1.INTERRUPT;
    }
});
Object.defineProperty(exports, "isInterrupted", {
    enumerable: true,
    get: function() {
        return constants_js_1.isInterrupted;
    }
});
var langgraph_checkpoint_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph-checkpoint/index.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "MemorySaver", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.MemorySaver;
    }
});
Object.defineProperty(exports, "copyCheckpoint", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.copyCheckpoint;
    }
});
Object.defineProperty(exports, "emptyCheckpoint", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.emptyCheckpoint;
    }
});
Object.defineProperty(exports, "BaseCheckpointSaver", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.BaseCheckpointSaver;
    }
});
Object.defineProperty(exports, "BaseStore", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.BaseStore;
    }
});
Object.defineProperty(exports, "AsyncBatchedStore", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.AsyncBatchedStore;
    }
});
Object.defineProperty(exports, "InMemoryStore", {
    enumerable: true,
    get: function() {
        return langgraph_checkpoint_1.InMemoryStore;
    }
});
var index_js_3 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/func/index.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "entrypoint", {
    enumerable: true,
    get: function() {
        return index_js_3.entrypoint;
    }
});
Object.defineProperty(exports, "task", {
    enumerable: true,
    get: function() {
        return index_js_3.task;
    }
});
var messages_annotation_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/messages_annotation.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "MessagesAnnotation", {
    enumerable: true,
    get: function() {
        return messages_annotation_js_1.MessagesAnnotation;
    }
});
Object.defineProperty(exports, "MessagesZodState", {
    enumerable: true,
    get: function() {
        return messages_annotation_js_1.MessagesZodState;
    }
});
Object.defineProperty(exports, "MessagesZodMeta", {
    enumerable: true,
    get: function() {
        return messages_annotation_js_1.MessagesZodMeta;
    }
}); //# sourceMappingURL=web.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/interrupt.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.interrupt = interrupt;
const singletons_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/singletons.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const hash_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/hash.cjs [app-route] (ecmascript)");
/**
 * Interrupts the execution of a graph node.
 * This function can be used to pause execution of a node, and return the value of the `resume`
 * input when the graph is re-invoked using `Command`.
 * Multiple interrupts can be called within a single node, and each will be handled sequentially.
 *
 * When an interrupt is called:
 * 1. If there's a `resume` value available (from a previous `Command`), it returns that value.
 * 2. Otherwise, it throws a `GraphInterrupt` with the provided value
 * 3. The graph can be resumed by passing a `Command` with a `resume` value
 *
 * Because the `interrupt` function propagates by throwing a special `GraphInterrupt` error,
 * you should avoid using `try/catch` blocks around the `interrupt` function,
 * or if you do, ensure that the `GraphInterrupt` error is thrown again within your `catch` block.
 *
 * @param value - The value to include in the interrupt. This will be available in task.interrupts[].value
 * @returns The `resume` value provided when the graph is re-invoked with a Command
 *
 * @example
 * ```typescript
 * // Define a node that uses multiple interrupts
 * const nodeWithInterrupts = () => {
 *   // First interrupt - will pause execution and include {value: 1} in task values
 *   const answer1 = interrupt({ value: 1 });
 *
 *   // Second interrupt - only called after first interrupt is resumed
 *   const answer2 = interrupt({ value: 2 });
 *
 *   // Use the resume values
 *   return { myKey: answer1 + " " + answer2 };
 * };
 *
 * // Resume the graph after first interrupt
 * await graph.stream(new Command({ resume: "answer 1" }));
 *
 * // Resume the graph after second interrupt
 * await graph.stream(new Command({ resume: "answer 2" }));
 * // Final result: { myKey: "answer 1 answer 2" }
 * ```
 *
 * @throws {Error} If called outside the context of a graph
 * @throws {GraphInterrupt} When no resume value is available
 */ // eslint-disable-next-line @typescript-eslint/no-explicit-any
function interrupt(value) {
    const config = singletons_1.AsyncLocalStorageProviderSingleton.getRunnableConfig();
    if (!config) {
        throw new Error("Called interrupt() outside the context of a graph.");
    }
    const conf = config.configurable;
    if (!conf) {
        throw new Error("No configurable found in config");
    }
    const checkpointer = conf[constants_js_1.CONFIG_KEY_CHECKPOINTER];
    if (!checkpointer) throw new errors_js_1.GraphValueError("No checkpointer set");
    // Track interrupt index
    const scratchpad = conf[constants_js_1.CONFIG_KEY_SCRATCHPAD];
    scratchpad.interruptCounter += 1;
    const idx = scratchpad.interruptCounter;
    // Find previous resume values
    if (scratchpad.resume.length > 0 && idx < scratchpad.resume.length) {
        conf[constants_js_1.CONFIG_KEY_SEND]?.([
            [
                constants_js_1.RESUME,
                scratchpad.resume
            ]
        ]);
        return scratchpad.resume[idx];
    }
    // Find current resume value
    if (scratchpad.nullResume !== undefined) {
        if (scratchpad.resume.length !== idx) {
            throw new Error(`Resume length mismatch: ${scratchpad.resume.length} !== ${idx}`);
        }
        const v = scratchpad.consumeNullResume();
        scratchpad.resume.push(v);
        conf[constants_js_1.CONFIG_KEY_SEND]?.([
            [
                constants_js_1.RESUME,
                scratchpad.resume
            ]
        ]);
        return v;
    }
    // No resume value found
    const ns = conf[constants_js_1.CONFIG_KEY_CHECKPOINT_NS]?.split(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR);
    const id = ns ? (0, hash_js_1.XXH3)(ns.join(constants_js_1.CHECKPOINT_NAMESPACE_SEPARATOR)) : undefined;
    throw new errors_js_1.GraphInterrupt([
        {
            id,
            value
        }
    ]);
} //# sourceMappingURL=interrupt.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

/* __LC_ALLOW_ENTRYPOINT_SIDE_EFFECTS__ */ var __createBinding = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = {
            enumerable: true,
            get: function() {
                return m[k];
            }
        };
    }
    Object.defineProperty(o, k2, desc);
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
});
var __exportStar = /*TURBOPACK member replacement*/ __turbopack_context__.e && /*TURBOPACK member replacement*/ __turbopack_context__.e.__exportStar || function(m, exports1) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports1, p)) __createBinding(exports1, m, p);
};
Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.getCurrentTaskInput = exports.getPreviousState = exports.getConfig = exports.getWriter = exports.getStore = exports.interrupt = void 0;
const async_local_storage_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/setup/async_local_storage.cjs [app-route] (ecmascript)");
// Initialize global async local storage instance for tracing
(0, async_local_storage_js_1.initializeAsyncLocalStorageSingleton)();
__exportStar(__turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/web.cjs [app-route] (ecmascript)"), exports);
var interrupt_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/interrupt.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "interrupt", {
    enumerable: true,
    get: function() {
        return interrupt_js_1.interrupt;
    }
});
var config_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/config.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "getStore", {
    enumerable: true,
    get: function() {
        return config_js_1.getStore;
    }
});
Object.defineProperty(exports, "getWriter", {
    enumerable: true,
    get: function() {
        return config_js_1.getWriter;
    }
});
Object.defineProperty(exports, "getConfig", {
    enumerable: true,
    get: function() {
        return config_js_1.getConfig;
    }
});
var index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/func/index.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "getPreviousState", {
    enumerable: true,
    get: function() {
        return index_js_1.getPreviousState;
    }
});
var config_js_2 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/pregel/utils/config.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "getCurrentTaskInput", {
    enumerable: true,
    get: function() {
        return config_js_2.getCurrentTaskInput;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {

module.exports = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/index.cjs [app-route] (ecmascript)");
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_executor.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ToolExecutor = void 0;
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const INVALID_TOOL_MSG_TEMPLATE = `{requestedToolName} is not a valid tool, try one of {availableToolNamesString}.`;
/** @deprecated Use {@link ToolNode} instead. */ class ToolExecutor extends runnables_1.RunnableBinding {
    constructor(fields){
        const fieldsWithDefaults = {
            invalidToolMsgTemplate: INVALID_TOOL_MSG_TEMPLATE,
            ...fields
        };
        const bound = runnables_1.RunnableLambda.from(async (input, config)=>this._execute(input, config));
        super({
            bound,
            config: {}
        });
        Object.defineProperty(this, "lc_graph_name", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: "ToolExecutor"
        });
        Object.defineProperty(this, "tools", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "toolMap", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "invalidToolMsgTemplate", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        this.tools = fieldsWithDefaults.tools;
        this.invalidToolMsgTemplate = fieldsWithDefaults.invalidToolMsgTemplate;
        this.toolMap = this.tools.reduce((acc, tool)=>{
            acc[tool.name] = tool;
            return acc;
        }, {});
    }
    /**
     * Execute a tool invocation
     *
     * @param {ToolInvocationInterface} toolInvocation The tool to invoke and the input to pass to it.
     * @param {RunnableConfig | undefined} config Optional configuration to pass to the tool when invoked.
     * @returns Either the result of the tool invocation (`string` or `ToolMessage`, set by the `ToolOutput` generic) or a string error message.
     */ async _execute(toolInvocation, config) {
        if (!(toolInvocation.tool in this.toolMap)) {
            return this.invalidToolMsgTemplate.replace("{requestedToolName}", toolInvocation.tool).replace("{availableToolNamesString}", Object.keys(this.toolMap).join(", "));
        } else {
            const tool = this.toolMap[toolInvocation.tool];
            const output = await tool.invoke(toolInvocation.toolInput, config);
            return output;
        }
    }
}
exports.ToolExecutor = ToolExecutor; //# sourceMappingURL=tool_executor.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/agent_executor.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.createAgentExecutor = createAgentExecutor;
const tool_executor_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_executor.cjs [app-route] (ecmascript)");
const state_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/state.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
/** @ignore */ function createAgentExecutor({ agentRunnable, tools }) {
    let toolExecutor;
    if (!Array.isArray(tools)) {
        toolExecutor = tools;
    } else {
        toolExecutor = new tool_executor_js_1.ToolExecutor({
            tools
        });
    }
    // Define logic that will be used to determine which conditional edge to go down
    const shouldContinue = (data)=>{
        if (data.agentOutcome && "returnValues" in data.agentOutcome) {
            return "end";
        }
        return "continue";
    };
    const runAgent = async (data, config)=>{
        const agentOutcome = await agentRunnable.invoke(data, config);
        return {
            agentOutcome
        };
    };
    const executeTools = async (data, config)=>{
        const agentAction = data.agentOutcome;
        if (!agentAction || "returnValues" in agentAction) {
            throw new Error("Agent has not been run yet");
        }
        const output = await toolExecutor.invoke(agentAction, config);
        return {
            steps: [
                {
                    action: agentAction,
                    observation: output
                }
            ]
        };
    };
    // Define a new graph
    const workflow = new state_js_1.StateGraph({
        channels: {
            input: null,
            agentOutcome: null,
            steps: {
                reducer: (x, y)=>x.concat(y),
                default: ()=>[]
            }
        }
    })// Define the two nodes we will cycle between
    .addNode("agent", runAgent).addNode("action", executeTools)// Set the entrypoint as `agent`
    // This means that this node is the first one called
    .addEdge(constants_js_1.START, "agent")// We now add a conditional edge
    .addConditionalEdges(// First, we define the start node. We use `agent`.
    // This means these are the edges taken after the `agent` node is called.
    "agent", // Next, we pass in the function that will determine which node is called next.
    shouldContinue, // Finally we pass in a mapping.
    // The keys are strings, and the values are other nodes.
    // END is a special node marking that the graph should finish.
    // What will happen is we will call `should_continue`, and then the output of that
    // will be matched against the keys in this mapping.
    // Based on which one it matches, that node will then be called.
    {
        // If `tools`, then we call the tool node.
        continue: "action",
        // Otherwise we finish.
        end: constants_js_1.END
    })// We now add a normal edge from `tools` to `agent`.
    // This means that after `tools` is called, `agent` node is called next.
    .addEdge("action", "agent");
    return workflow.compile();
} //# sourceMappingURL=agent_executor.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/chat_agent_executor.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.createFunctionCallingExecutor = createFunctionCallingExecutor;
const function_calling_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/utils/function_calling.cjs [app-route] (ecmascript)");
const messages_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/messages.cjs [app-route] (ecmascript)");
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const tool_executor_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_executor.cjs [app-route] (ecmascript)");
const state_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/state.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
/** @deprecated Use {@link createReactAgent} instead with tool calling. */ function createFunctionCallingExecutor({ model, tools }) {
    let toolExecutor;
    let toolClasses;
    if (!Array.isArray(tools)) {
        toolExecutor = tools;
        toolClasses = tools.tools;
    } else {
        toolExecutor = new tool_executor_js_1.ToolExecutor({
            tools
        });
        toolClasses = tools;
    }
    if (!("bind" in model) || typeof model.bind !== "function") {
        throw new Error("Model must be bindable");
    }
    const toolsAsOpenAIFunctions = toolClasses.map((tool)=>(0, function_calling_1.convertToOpenAIFunction)(tool));
    const newModel = model.bind({
        functions: toolsAsOpenAIFunctions
    });
    // Define the function that determines whether to continue or not
    const shouldContinue = (state)=>{
        const { messages } = state;
        const lastMessage = messages[messages.length - 1];
        // If there is no function call, then we finish
        if (!("function_call" in lastMessage.additional_kwargs) || !lastMessage.additional_kwargs.function_call) {
            return "end";
        }
        // Otherwise if there is, we continue
        return "continue";
    };
    // Define the function that calls the model
    const callModel = async (state, config)=>{
        const { messages } = state;
        const response = await newModel.invoke(messages, config);
        // We return a list, because this will get added to the existing list
        return {
            messages: [
                response
            ]
        };
    };
    // Define the function to execute tools
    const _getAction = (state)=>{
        const { messages } = state;
        // Based on the continue condition
        // we know the last message involves a function call
        const lastMessage = messages[messages.length - 1];
        if (!lastMessage) {
            throw new Error("No messages found.");
        }
        if (!lastMessage.additional_kwargs.function_call) {
            throw new Error("No function call found in message.");
        }
        // We construct an AgentAction from the function_call
        return {
            tool: lastMessage.additional_kwargs.function_call.name,
            toolInput: JSON.stringify(lastMessage.additional_kwargs.function_call.arguments),
            log: ""
        };
    };
    const callTool = async (state, config)=>{
        const action = _getAction(state);
        // We call the tool_executor and get back a response
        const response = await toolExecutor.invoke(action, config);
        // We use the response to create a FunctionMessage
        const functionMessage = new messages_1.FunctionMessage({
            content: response,
            name: action.tool
        });
        // We return a list, because this will get added to the existing list
        return {
            messages: [
                functionMessage
            ]
        };
    };
    // We create the AgentState that we will pass around
    // This simply involves a list of messages
    // We want steps to return messages to append to the list
    // So we annotate the messages attribute with operator.add
    const schema = {
        messages: {
            value: (x, y)=>x.concat(y),
            default: ()=>[]
        }
    };
    // Define a new graph
    const workflow = new state_js_1.StateGraph({
        channels: schema
    })// Define the two nodes we will cycle between
    .addNode("agent", new runnables_1.RunnableLambda({
        func: callModel
    })).addNode("action", new runnables_1.RunnableLambda({
        func: callTool
    }))// Set the entrypoint as `agent`
    // This means that this node is the first one called
    .addEdge(constants_js_1.START, "agent")// We now add a conditional edge
    .addConditionalEdges(// First, we define the start node. We use `agent`.
    // This means these are the edges taken after the `agent` node is called.
    "agent", // Next, we pass in the function that will determine which node is called next.
    shouldContinue, // Finally we pass in a mapping.
    // The keys are strings, and the values are other nodes.
    // END is a special node marking that the graph should finish.
    // What will happen is we will call `should_continue`, and then the output of that
    // will be matched against the keys in this mapping.
    // Based on which one it matches, that node will then be called.
    {
        // If `tools`, then we call the tool node.
        continue: "action",
        // Otherwise we finish.
        end: constants_js_1.END
    })// We now add a normal edge from `tools` to `agent`.
    // This means that after `tools` is called, `agent` node is called next.
    .addEdge("action", "agent");
    // Finally, we compile it!
    // This compiles it into a LangChain Runnable,
    // meaning you can use it as you would any other runnable
    return workflow.compile();
} //# sourceMappingURL=chat_agent_executor.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_node.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.ToolNode = void 0;
exports.toolsCondition = toolsCondition;
const messages_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/messages.cjs [app-route] (ecmascript)");
const utils_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/utils.cjs [app-route] (ecmascript)");
const errors_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/errors.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const isBaseMessageArray = (input)=>Array.isArray(input) && input.every(messages_1.isBaseMessage);
const isMessagesState = (input)=>typeof input === "object" && input != null && "messages" in input && isBaseMessageArray(input.messages);
const isSendInput = (input)=>typeof input === "object" && input != null && "lg_tool_call" in input;
/**
 * A node that runs the tools requested in the last AIMessage. It can be used
 * either in StateGraph with a "messages" key or in MessageGraph. If multiple
 * tool calls are requested, they will be run in parallel. The output will be
 * a list of ToolMessages, one for each tool call.
 *
 * @example
 * ```ts
 * import { ToolNode } from "@langchain/langgraph/prebuilt";
 * import { tool } from "@langchain/core/tools";
 * import { z } from "zod";
 * import { AIMessage } from "@langchain/core/messages";
 *
 * const getWeather = tool((input) => {
 *   if (["sf", "san francisco"].includes(input.location.toLowerCase())) {
 *     return "It's 60 degrees and foggy.";
 *   } else {
 *     return "It's 90 degrees and sunny.";
 *   }
 * }, {
 *   name: "get_weather",
 *   description: "Call to get the current weather.",
 *   schema: z.object({
 *     location: z.string().describe("Location to get the weather for."),
 *   }),
 * });
 *
 * const tools = [getWeather];
 * const toolNode = new ToolNode(tools);
 *
 * const messageWithSingleToolCall = new AIMessage({
 *   content: "",
 *   tool_calls: [
 *     {
 *       name: "get_weather",
 *       args: { location: "sf" },
 *       id: "tool_call_id",
 *       type: "tool_call",
 *     }
 *   ]
 * })
 *
 * await toolNode.invoke({ messages: [messageWithSingleToolCall] });
 * // Returns tool invocation responses as:
 * // { messages: ToolMessage[] }
 * ```
 *
 * @example
 * ```ts
 * import {
 *   StateGraph,
 *   MessagesAnnotation,
 * } from "@langchain/langgraph";
 * import { ToolNode } from "@langchain/langgraph/prebuilt";
 * import { tool } from "@langchain/core/tools";
 * import { z } from "zod";
 * import { ChatAnthropic } from "@langchain/anthropic";
 *
 * const getWeather = tool((input) => {
 *   if (["sf", "san francisco"].includes(input.location.toLowerCase())) {
 *     return "It's 60 degrees and foggy.";
 *   } else {
 *     return "It's 90 degrees and sunny.";
 *   }
 * }, {
 *   name: "get_weather",
 *   description: "Call to get the current weather.",
 *   schema: z.object({
 *     location: z.string().describe("Location to get the weather for."),
 *   }),
 * });
 *
 * const tools = [getWeather];
 * const modelWithTools = new ChatAnthropic({
 *   model: "claude-3-haiku-20240307",
 *   temperature: 0
 * }).bindTools(tools);
 *
 * const toolNodeForGraph = new ToolNode(tools)
 *
 * const shouldContinue = (state: typeof MessagesAnnotation.State) => {
 *   const { messages } = state;
 *   const lastMessage = messages[messages.length - 1];
 *   if ("tool_calls" in lastMessage && Array.isArray(lastMessage.tool_calls) && lastMessage.tool_calls?.length) {
 *     return "tools";
 *   }
 *   return "__end__";
 * }
 *
 * const callModel = async (state: typeof MessagesAnnotation.State) => {
 *   const { messages } = state;
 *   const response = await modelWithTools.invoke(messages);
 *   return { messages: response };
 * }
 *
 * const graph = new StateGraph(MessagesAnnotation)
 *   .addNode("agent", callModel)
 *   .addNode("tools", toolNodeForGraph)
 *   .addEdge("__start__", "agent")
 *   .addConditionalEdges("agent", shouldContinue)
 *   .addEdge("tools", "agent")
 *   .compile();
 *
 * const inputs = {
 *   messages: [{ role: "user", content: "what is the weather in SF?" }],
 * };
 *
 * const stream = await graph.stream(inputs, {
 *   streamMode: "values",
 * });
 *
 * for await (const { messages } of stream) {
 *   console.log(messages);
 * }
 * // Returns the messages in the state at each step of execution
 * ```
 */ // eslint-disable-next-line @typescript-eslint/no-explicit-any
class ToolNode extends utils_js_1.RunnableCallable {
    constructor(tools, options){
        const { name, tags, handleToolErrors } = options ?? {};
        super({
            name,
            tags,
            func: (input, config)=>this.run(input, config)
        });
        Object.defineProperty(this, "tools", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        Object.defineProperty(this, "handleToolErrors", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: true
        });
        Object.defineProperty(this, "trace", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: false
        });
        this.tools = tools;
        this.handleToolErrors = handleToolErrors ?? this.handleToolErrors;
    }
    async runTool(call, config) {
        const tool = this.tools.find((tool)=>tool.name === call.name);
        try {
            if (tool === undefined) {
                throw new Error(`Tool "${call.name}" not found.`);
            }
            const output = await tool.invoke({
                ...call,
                type: "tool_call"
            }, config);
            if ((0, messages_1.isBaseMessage)(output) && output.getType() === "tool" || (0, constants_js_1.isCommand)(output)) {
                return output;
            }
            return new messages_1.ToolMessage({
                status: "success",
                name: tool.name,
                content: typeof output === "string" ? output : JSON.stringify(output),
                tool_call_id: call.id
            });
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        } catch (e) {
            if (!this.handleToolErrors) throw e;
            if ((0, errors_js_1.isGraphInterrupt)(e)) {
                // `NodeInterrupt` errors are a breakpoint to bring a human into the loop.
                // As such, they are not recoverable by the agent and shouldn't be fed
                // back. Instead, re-throw these errors even when `handleToolErrors = true`.
                throw e;
            }
            return new messages_1.ToolMessage({
                status: "error",
                content: `Error: ${e.message}\n Please fix your mistakes.`,
                name: call.name,
                tool_call_id: call.id ?? ""
            });
        }
    }
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    async run(input, config) {
        let outputs;
        if (isSendInput(input)) {
            outputs = [
                await this.runTool(input.lg_tool_call, config)
            ];
        } else {
            let messages;
            if (isBaseMessageArray(input)) {
                messages = input;
            } else if (isMessagesState(input)) {
                messages = input.messages;
            } else {
                throw new Error("ToolNode only accepts BaseMessage[] or { messages: BaseMessage[] } as input.");
            }
            const toolMessageIds = new Set(messages.filter((msg)=>msg.getType() === "tool").map((msg)=>msg.tool_call_id));
            let aiMessage;
            for(let i = messages.length - 1; i >= 0; i -= 1){
                const message = messages[i];
                if (message.getType() === "ai") {
                    aiMessage = message;
                    break;
                }
            }
            if (aiMessage?.getType() !== "ai") {
                throw new Error("ToolNode only accepts AIMessages as input.");
            }
            outputs = await Promise.all(aiMessage.tool_calls?.filter((call)=>call.id == null || !toolMessageIds.has(call.id)).map((call)=>this.runTool(call, config)) ?? []);
        }
        // Preserve existing behavior for non-command tool outputs for backwards compatibility
        if (!outputs.some(constants_js_1.isCommand)) {
            return Array.isArray(input) ? outputs : {
                messages: outputs
            };
        }
        // Handle mixed Command and non-Command outputs
        const combinedOutputs = [];
        let parentCommand = null;
        for (const output of outputs){
            if ((0, constants_js_1.isCommand)(output)) {
                if (output.graph === constants_js_1.Command.PARENT && Array.isArray(output.goto) && output.goto.every((send)=>(0, constants_js_1._isSend)(send))) {
                    if (parentCommand) {
                        parentCommand.goto.push(...output.goto);
                    } else {
                        parentCommand = new constants_js_1.Command({
                            graph: constants_js_1.Command.PARENT,
                            goto: output.goto
                        });
                    }
                } else {
                    combinedOutputs.push(output);
                }
            } else {
                combinedOutputs.push(Array.isArray(input) ? [
                    output
                ] : {
                    messages: [
                        output
                    ]
                });
            }
        }
        if (parentCommand) {
            combinedOutputs.push(parentCommand);
        }
        return combinedOutputs;
    }
}
exports.ToolNode = ToolNode;
function toolsCondition(state) {
    const message = Array.isArray(state) ? state[state.length - 1] : state.messages[state.messages.length - 1];
    if (message !== undefined && "tool_calls" in message && (message.tool_calls?.length ?? 0) > 0) {
        return "tools";
    } else {
        return constants_js_1.END;
    }
} //# sourceMappingURL=tool_node.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/agentName.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports._addInlineAgentName = _addInlineAgentName;
exports._removeInlineAgentName = _removeInlineAgentName;
exports.withAgentName = withAgentName;
const messages_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/messages.cjs [app-route] (ecmascript)");
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const NAME_PATTERN = /<name>(.*?)<\/name>/s;
const CONTENT_PATTERN = /<content>(.*?)<\/content>/s;
/**
 * Attach formatted agent names to the messages passed to and from a language model.
 *
 * This is useful for making a message history with multiple agents more coherent.
 *
 * NOTE: agent name is consumed from the message.name field.
 * If you're using an agent built with createReactAgent, name is automatically set.
 * If you're building a custom agent, make sure to set the name on the AI message returned by the LLM.
 *
 * @param message - Message to add agent name formatting to
 * @returns Message with agent name formatting
 *
 * @internal
 */ function _addInlineAgentName(message) {
    const isAI = (0, messages_1.isBaseMessage)(message) && ((0, messages_1.isAIMessage)(message) || (0, messages_1.isBaseMessageChunk)(message) && (0, messages_1.isAIMessageChunk)(message));
    if (!isAI || !message.name) {
        return message;
    }
    const { name } = message;
    if (typeof message.content === "string") {
        return new messages_1.AIMessage({
            ...Object.keys(message.lc_kwargs ?? {}).length > 0 ? message.lc_kwargs : message,
            content: `<name>${name}</name><content>${message.content}</content>`,
            name: undefined
        });
    }
    const updatedContent = [];
    let textBlockCount = 0;
    for (const contentBlock of message.content){
        if (typeof contentBlock === "string") {
            textBlockCount += 1;
            updatedContent.push(`<name>${name}</name><content>${contentBlock}</content>`);
        } else if (typeof contentBlock === "object" && "type" in contentBlock && contentBlock.type === "text") {
            textBlockCount += 1;
            updatedContent.push({
                ...contentBlock,
                text: `<name>${name}</name><content>${contentBlock.text}</content>`
            });
        } else {
            updatedContent.push(contentBlock);
        }
    }
    if (!textBlockCount) {
        updatedContent.unshift({
            type: "text",
            text: `<name>${name}</name><content></content>`
        });
    }
    return new messages_1.AIMessage({
        ...message.lc_kwargs,
        content: updatedContent,
        name: undefined
    });
}
/**
 * Remove explicit name and content XML tags from the AI message content.
 *
 * Examples:
 *
 * @example
 * ```typescript
 * removeInlineAgentName(new AIMessage({ content: "<name>assistant</name><content>Hello</content>", name: "assistant" }))
 * // AIMessage with content: "Hello"
 *
 * removeInlineAgentName(new AIMessage({ content: [{type: "text", text: "<name>assistant</name><content>Hello</content>"}], name: "assistant" }))
 * // AIMessage with content: [{type: "text", text: "Hello"}]
 * ```
 *
 * @internal
 */ function _removeInlineAgentName(message) {
    if (!(0, messages_1.isAIMessage)(message) || !message.content) {
        return message;
    }
    let updatedContent = [];
    let updatedName;
    if (Array.isArray(message.content)) {
        updatedContent = message.content.filter((block)=>{
            if (block.type === "text") {
                const nameMatch = block.text.match(NAME_PATTERN);
                const contentMatch = block.text.match(CONTENT_PATTERN);
                // don't include empty content blocks that were added because there was no text block to modify
                if (nameMatch && (!contentMatch || contentMatch[1] === "")) {
                    // capture name from text block
                    // eslint-disable-next-line prefer-destructuring
                    updatedName = nameMatch[1];
                    return false;
                }
                return true;
            }
            return true;
        }).map((block)=>{
            if (block.type === "text") {
                const nameMatch = block.text.match(NAME_PATTERN);
                const contentMatch = block.text.match(CONTENT_PATTERN);
                if (!nameMatch || !contentMatch) {
                    return block;
                }
                // capture name from text block
                // eslint-disable-next-line prefer-destructuring
                updatedName = nameMatch[1];
                return {
                    ...block,
                    text: contentMatch[1]
                };
            }
            return block;
        });
    } else {
        const content = message.content;
        const nameMatch = content.match(NAME_PATTERN);
        const contentMatch = content.match(CONTENT_PATTERN);
        if (!nameMatch || !contentMatch) {
            return message;
        }
        // eslint-disable-next-line prefer-destructuring
        updatedName = nameMatch[1];
        // eslint-disable-next-line prefer-destructuring
        updatedContent = contentMatch[1];
    }
    return new messages_1.AIMessage({
        ...Object.keys(message.lc_kwargs ?? {}).length > 0 ? message.lc_kwargs : message,
        content: updatedContent,
        name: updatedName
    });
}
/**
 * Attach formatted agent names to the messages passed to and from a language model.
 *
 * This is useful for making a message history with multiple agents more coherent.
 *
 * NOTE: agent name is consumed from the message.name field.
 * If you're using an agent built with createReactAgent, name is automatically set.
 * If you're building a custom agent, make sure to set the name on the AI message returned by the LLM.
 *
 * @param model - Language model to add agent name formatting to
 * @param agentNameMode - How to expose the agent name to the LLM
 *   - "inline": Add the agent name directly into the content field of the AI message using XML-style tags.
 *     Example: "How can I help you" -> "<name>agent_name</name><content>How can I help you?</content>".
 */ function withAgentName(model, agentNameMode) {
    let processInputMessage;
    let processOutputMessage;
    if (agentNameMode === "inline") {
        processInputMessage = _addInlineAgentName;
        processOutputMessage = _removeInlineAgentName;
    } else {
        throw new Error(`Invalid agent name mode: ${agentNameMode}. Needs to be one of: "inline"`);
    }
    function processInputMessages(messages) {
        return messages.map(processInputMessage);
    }
    return runnables_1.RunnableSequence.from([
        runnables_1.RunnableLambda.from(processInputMessages),
        model,
        runnables_1.RunnableLambda.from(processOutputMessage)
    ]);
} //# sourceMappingURL=agentName.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/react_agent_executor.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.createReactAgentAnnotation = void 0;
exports._shouldBindTools = _shouldBindTools;
exports._bindTools = _bindTools;
exports._getModel = _getModel;
exports.createReactAgent = createReactAgent;
const messages_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/messages.cjs [app-route] (ecmascript)");
const runnables_1 = __turbopack_context__.r("[project]/node_modules/@langchain/core/runnables.cjs [app-route] (ecmascript)");
const index_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/index.cjs [app-route] (ecmascript)");
const tool_node_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_node.cjs [app-route] (ecmascript)");
const annotation_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/annotation.cjs [app-route] (ecmascript)");
const message_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/graph/message.cjs [app-route] (ecmascript)");
const constants_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/constants.cjs [app-route] (ecmascript)");
const agentName_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/agentName.cjs [app-route] (ecmascript)");
function _convertMessageModifierToPrompt(messageModifier) {
    // Handle string or SystemMessage
    if (typeof messageModifier === "string" || (0, messages_1.isBaseMessage)(messageModifier) && messageModifier._getType() === "system") {
        return messageModifier;
    }
    // Handle callable function
    if (typeof messageModifier === "function") {
        return async (state)=>messageModifier(state.messages);
    }
    // Handle Runnable
    if (runnables_1.Runnable.isRunnable(messageModifier)) {
        return runnables_1.RunnableLambda.from((state)=>state.messages).pipe(messageModifier);
    }
    throw new Error(`Unexpected type for messageModifier: ${typeof messageModifier}`);
}
const PROMPT_RUNNABLE_NAME = "prompt";
function _getPromptRunnable(prompt) {
    let promptRunnable;
    if (prompt == null) {
        promptRunnable = runnables_1.RunnableLambda.from((state)=>state.messages).withConfig({
            runName: PROMPT_RUNNABLE_NAME
        });
    } else if (typeof prompt === "string") {
        const systemMessage = new messages_1.SystemMessage(prompt);
        promptRunnable = runnables_1.RunnableLambda.from((state)=>{
            return [
                systemMessage,
                ...state.messages ?? []
            ];
        }).withConfig({
            runName: PROMPT_RUNNABLE_NAME
        });
    } else if ((0, messages_1.isBaseMessage)(prompt) && prompt._getType() === "system") {
        promptRunnable = runnables_1.RunnableLambda.from((state)=>[
                prompt,
                ...state.messages
            ]).withConfig({
            runName: PROMPT_RUNNABLE_NAME
        });
    } else if (typeof prompt === "function") {
        promptRunnable = runnables_1.RunnableLambda.from(prompt).withConfig({
            runName: PROMPT_RUNNABLE_NAME
        });
    } else if (runnables_1.Runnable.isRunnable(prompt)) {
        promptRunnable = prompt;
    } else {
        throw new Error(`Got unexpected type for 'prompt': ${typeof prompt}`);
    }
    return promptRunnable;
}
function isClientTool(tool) {
    return runnables_1.Runnable.isRunnable(tool);
}
function _getPrompt(prompt, stateModifier, messageModifier) {
    // Check if multiple modifiers exist
    const definedCount = [
        prompt,
        stateModifier,
        messageModifier
    ].filter((x)=>x != null).length;
    if (definedCount > 1) {
        throw new Error("Expected only one of prompt, stateModifier, or messageModifier, got multiple values");
    }
    let finalPrompt = prompt;
    if (stateModifier != null) {
        finalPrompt = stateModifier;
    } else if (messageModifier != null) {
        finalPrompt = _convertMessageModifierToPrompt(messageModifier);
    }
    return _getPromptRunnable(finalPrompt);
}
function _isBaseChatModel(model) {
    return "invoke" in model && typeof model.invoke === "function" && "_modelType" in model;
}
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function _isConfigurableModel(model) {
    return "_queuedMethodOperations" in model && "_model" in model && typeof model._model === "function";
}
function _isChatModelWithBindTools(llm) {
    if (!_isBaseChatModel(llm)) return false;
    return "bindTools" in llm && typeof llm.bindTools === "function";
}
async function _shouldBindTools(llm, tools) {
    // If model is a RunnableSequence, find a RunnableBinding or BaseChatModel in its steps
    let model = llm;
    if (runnables_1.RunnableSequence.isRunnableSequence(model)) {
        model = model.steps.find((step)=>runnables_1.RunnableBinding.isRunnableBinding(step) || _isBaseChatModel(step) || _isConfigurableModel(step)) || model;
    }
    if (_isConfigurableModel(model)) {
        model = await model._model();
    }
    // If not a RunnableBinding, we should bind tools
    if (!runnables_1.RunnableBinding.isRunnableBinding(model)) {
        return true;
    }
    let boundTools = (()=>{
        // check if model.kwargs contain the tools key
        if (model.kwargs != null && typeof model.kwargs === "object" && "tools" in model.kwargs && Array.isArray(model.kwargs.tools)) {
            return model.kwargs.tools ?? null;
        }
        // Some models can bind the tools via `withConfig()` instead of `bind()`
        if (model.config != null && typeof model.config === "object" && "tools" in model.config && Array.isArray(model.config.tools)) {
            return model.config.tools ?? null;
        }
        return null;
    })();
    // google-style
    if (boundTools != null && boundTools.length === 1 && "functionDeclarations" in boundTools[0]) {
        boundTools = boundTools[0].functionDeclarations;
    }
    // If no tools in kwargs, we should bind tools
    if (boundTools == null) return true;
    // Check if tools count matches
    if (tools.length !== boundTools.length) {
        throw new Error("Number of tools in the model.bindTools() and tools passed to createReactAgent must match");
    }
    const toolNames = new Set(tools.flatMap((tool)=>isClientTool(tool) ? tool.name : []));
    const boundToolNames = new Set();
    for (const boundTool of boundTools){
        let boundToolName;
        // OpenAI-style tool
        if ("type" in boundTool && boundTool.type === "function") {
            boundToolName = boundTool.function.name;
        } else if ("name" in boundTool) {
            boundToolName = boundTool.name;
        } else if ("toolSpec" in boundTool && "name" in boundTool.toolSpec) {
            boundToolName = boundTool.toolSpec.name;
        } else {
            continue;
        }
        if (boundToolName) {
            boundToolNames.add(boundToolName);
        }
    }
    const missingTools = [
        ...toolNames
    ].filter((x)=>!boundToolNames.has(x));
    if (missingTools.length > 0) {
        throw new Error(`Missing tools '${missingTools}' in the model.bindTools().` + `Tools in the model.bindTools() must match the tools passed to createReactAgent.`);
    }
    return false;
}
const _simpleBindTools = (llm, toolClasses)=>{
    if (_isChatModelWithBindTools(llm)) {
        return llm.bindTools(toolClasses);
    }
    if (runnables_1.RunnableBinding.isRunnableBinding(llm) && _isChatModelWithBindTools(llm.bound)) {
        const newBound = llm.bound.bindTools(toolClasses);
        if (runnables_1.RunnableBinding.isRunnableBinding(newBound)) {
            return new runnables_1.RunnableBinding({
                bound: newBound.bound,
                config: {
                    ...llm.config,
                    ...newBound.config
                },
                kwargs: {
                    ...llm.kwargs,
                    ...newBound.kwargs
                },
                configFactories: newBound.configFactories ?? llm.configFactories
            });
        }
        return new runnables_1.RunnableBinding({
            bound: newBound,
            config: llm.config,
            kwargs: llm.kwargs,
            configFactories: llm.configFactories
        });
    }
    return null;
};
async function _bindTools(llm, toolClasses) {
    const model = _simpleBindTools(llm, toolClasses);
    if (model) return model;
    if (_isConfigurableModel(llm)) {
        const model = _simpleBindTools(await llm._model(), toolClasses);
        if (model) return model;
    }
    if (runnables_1.RunnableSequence.isRunnableSequence(llm)) {
        const modelStep = llm.steps.findIndex((step)=>runnables_1.RunnableBinding.isRunnableBinding(step) || _isBaseChatModel(step) || _isConfigurableModel(step));
        if (modelStep >= 0) {
            const model = _simpleBindTools(llm.steps[modelStep], toolClasses);
            if (model) {
                const nextSteps = llm.steps.slice();
                nextSteps.splice(modelStep, 1, model);
                return runnables_1.RunnableSequence.from(nextSteps);
            }
        }
    }
    throw new Error(`llm ${llm} must define bindTools method.`);
}
async function _getModel(llm) {
    // If model is a RunnableSequence, find a RunnableBinding or BaseChatModel in its steps
    let model = llm;
    if (runnables_1.RunnableSequence.isRunnableSequence(model)) {
        model = model.steps.find((step)=>runnables_1.RunnableBinding.isRunnableBinding(step) || _isBaseChatModel(step) || _isConfigurableModel(step)) || model;
    }
    if (_isConfigurableModel(model)) {
        model = await model._model();
    }
    // Get the underlying model from a RunnableBinding
    if (runnables_1.RunnableBinding.isRunnableBinding(model)) {
        model = model.bound;
    }
    if (!_isBaseChatModel(model)) {
        throw new Error(`Expected \`llm\` to be a ChatModel or RunnableBinding (e.g. llm.bind_tools(...)) with invoke() and generate() methods, got ${model.constructor.name}`);
    }
    return model;
}
const createReactAgentAnnotation = ()=>annotation_js_1.Annotation.Root({
        messages: (0, annotation_js_1.Annotation)({
            reducer: message_js_1.messagesStateReducer,
            default: ()=>[]
        }),
        structuredResponse: annotation_js_1.Annotation
    });
exports.createReactAgentAnnotation = createReactAgentAnnotation;
const PreHookAnnotation = annotation_js_1.Annotation.Root({
    llmInputMessages: (0, annotation_js_1.Annotation)({
        reducer: (_, update)=>(0, message_js_1.messagesStateReducer)([], update),
        default: ()=>[]
    })
});
/**
 * Creates a StateGraph agent that relies on a chat model utilizing tool calling.
 *
 * @example
 * ```ts
 * import { ChatOpenAI } from "@langchain/openai";
 * import { tool } from "@langchain/core/tools";
 * import { z } from "zod";
 * import { createReactAgent } from "@langchain/langgraph/prebuilt";
 *
 * const model = new ChatOpenAI({
 *   model: "gpt-4o",
 * });
 *
 * const getWeather = tool((input) => {
 *   if (["sf", "san francisco"].includes(input.location.toLowerCase())) {
 *     return "It's 60 degrees and foggy.";
 *   } else {
 *     return "It's 90 degrees and sunny.";
 *   }
 * }, {
 *   name: "get_weather",
 *   description: "Call to get the current weather.",
 *   schema: z.object({
 *     location: z.string().describe("Location to get the weather for."),
 *   })
 * })
 *
 * const agent = createReactAgent({ llm: model, tools: [getWeather] });
 *
 * const inputs = {
 *   messages: [{ role: "user", content: "what is the weather in SF?" }],
 * };
 *
 * const stream = await agent.stream(inputs, { streamMode: "values" });
 *
 * for await (const { messages } of stream) {
 *   console.log(messages);
 * }
 * // Returns the messages in the state at each step of execution
 * ```
 */ function createReactAgent(params) {
    const { llm, tools, messageModifier, stateModifier, prompt, stateSchema, contextSchema, checkpointSaver, checkpointer, interruptBefore, interruptAfter, store, responseFormat, preModelHook, postModelHook, name, description, version = "v1", includeAgentName } = params;
    let toolClasses;
    let toolNode;
    if (!Array.isArray(tools)) {
        toolClasses = tools.tools;
        toolNode = tools;
    } else {
        toolClasses = tools;
        toolNode = new tool_node_js_1.ToolNode(toolClasses.filter(isClientTool));
    }
    let cachedStaticModel = null;
    const _getStaticModel = async (llm)=>{
        if (cachedStaticModel) return cachedStaticModel;
        let modelWithTools;
        if (await _shouldBindTools(llm, toolClasses)) {
            modelWithTools = await _bindTools(llm, toolClasses);
        } else {
            modelWithTools = llm;
        }
        const promptRunnable = _getPrompt(prompt, stateModifier, messageModifier);
        const modelRunnable = includeAgentName === "inline" ? (0, agentName_js_1.withAgentName)(modelWithTools, includeAgentName) : modelWithTools;
        cachedStaticModel = promptRunnable.pipe(modelRunnable);
        return cachedStaticModel;
    };
    const _getDynamicModel = async (llm, state, config)=>{
        const model = await llm(state, config);
        return _getPrompt(prompt, stateModifier, messageModifier).pipe(includeAgentName === "inline" ? (0, agentName_js_1.withAgentName)(model, includeAgentName) : model);
    };
    // If any of the tools are configured to return_directly after running,
    // our graph needs to check if these were called
    const shouldReturnDirect = new Set(toolClasses.filter(isClientTool).filter((tool)=>"returnDirect" in tool && tool.returnDirect).map((tool)=>tool.name));
    function getModelInputState(state) {
        const { messages, llmInputMessages, ...rest } = state;
        if (llmInputMessages != null && llmInputMessages.length > 0) {
            return {
                messages: llmInputMessages,
                ...rest
            };
        }
        return {
            messages,
            ...rest
        };
    }
    const generateStructuredResponse = async (state, config)=>{
        if (responseFormat == null) {
            throw new Error("Attempted to generate structured output with no passed response schema. Please contact us for help.");
        }
        const messages = [
            ...state.messages
        ];
        let modelWithStructuredOutput;
        const model = typeof llm === "function" ? await llm(state, config) : await _getModel(llm);
        if (!_isBaseChatModel(model)) {
            throw new Error(`Expected \`llm\` to be a ChatModel with .withStructuredOutput() method, got ${model.constructor.name}`);
        }
        if (typeof responseFormat === "object" && "schema" in responseFormat) {
            const { prompt, schema, ...options } = responseFormat;
            modelWithStructuredOutput = model.withStructuredOutput(schema, options);
            if (prompt != null) {
                messages.unshift(new messages_1.SystemMessage({
                    content: prompt
                }));
            }
        } else {
            modelWithStructuredOutput = model.withStructuredOutput(responseFormat);
        }
        const response = await modelWithStructuredOutput.invoke(messages, config);
        return {
            structuredResponse: response
        };
    };
    const callModel = async (state, config)=>{
        // NOTE: we're dynamically creating the model runnable here
        // to ensure that we can validate ConfigurableModel properly
        const modelRunnable = typeof llm === "function" ? await _getDynamicModel(llm, state, config) : await _getStaticModel(llm);
        // TODO: Auto-promote streaming.
        const response = await modelRunnable.invoke(getModelInputState(state), config);
        // add agent name to the AIMessage
        // TODO: figure out if we can avoid mutating the message directly
        response.name = name;
        response.lc_kwargs.name = name;
        return {
            messages: [
                response
            ]
        };
    };
    const schema = stateSchema ?? (0, exports.createReactAgentAnnotation)();
    const workflow = new index_js_1.StateGraph(schema, contextSchema).addNode("tools", toolNode);
    if (!("messages" in workflow._schemaDefinition)) {
        throw new Error("Missing required `messages` key in state schema.");
    }
    const allNodeWorkflows = workflow;
    const conditionalMap = (map)=>{
        return Object.fromEntries(Object.entries(map).filter(([_, v])=>v != null));
    };
    let entrypoint = "agent";
    let inputSchema;
    if (preModelHook != null) {
        allNodeWorkflows.addNode("pre_model_hook", preModelHook).addEdge("pre_model_hook", "agent");
        entrypoint = "pre_model_hook";
        inputSchema = annotation_js_1.Annotation.Root({
            ...workflow._schemaDefinition,
            ...PreHookAnnotation.spec
        });
    } else {
        entrypoint = "agent";
    }
    allNodeWorkflows.addNode("agent", callModel, {
        input: inputSchema
    }).addEdge(constants_js_1.START, entrypoint);
    if (postModelHook != null) {
        allNodeWorkflows.addNode("post_model_hook", postModelHook).addEdge("agent", "post_model_hook").addConditionalEdges("post_model_hook", (state)=>{
            const { messages } = state;
            const toolMessageIds = new Set(messages.filter(messages_1.isToolMessage).map((msg)=>msg.tool_call_id));
            let lastAiMessage;
            for(let i = messages.length - 1; i >= 0; i -= 1){
                const message = messages[i];
                if ((0, messages_1.isAIMessage)(message)) {
                    lastAiMessage = message;
                    break;
                }
            }
            const pendingToolCalls = lastAiMessage?.tool_calls?.filter((i)=>i.id == null || !toolMessageIds.has(i.id)) ?? [];
            const lastMessage = messages.at(-1);
            if (pendingToolCalls.length > 0) {
                if (version === "v2") {
                    return pendingToolCalls.map((toolCall)=>new constants_js_1.Send("tools", {
                            ...state,
                            lg_tool_call: toolCall
                        }));
                }
                return "tools";
            }
            if (lastMessage && (0, messages_1.isToolMessage)(lastMessage)) return entrypoint;
            if (responseFormat != null) return "generate_structured_response";
            return constants_js_1.END;
        }, conditionalMap({
            tools: "tools",
            [entrypoint]: entrypoint,
            generate_structured_response: responseFormat != null ? "generate_structured_response" : null,
            [constants_js_1.END]: responseFormat != null ? null : constants_js_1.END
        }));
    }
    if (responseFormat !== undefined) {
        workflow.addNode("generate_structured_response", generateStructuredResponse).addEdge("generate_structured_response", constants_js_1.END);
    }
    if (postModelHook == null) {
        allNodeWorkflows.addConditionalEdges("agent", (state)=>{
            const { messages } = state;
            const lastMessage = messages[messages.length - 1];
            // if there's no function call, we finish
            if (!(0, messages_1.isAIMessage)(lastMessage) || !lastMessage.tool_calls?.length) {
                if (responseFormat != null) return "generate_structured_response";
                return constants_js_1.END;
            }
            // there are function calls, we continue
            if (version === "v2") {
                return lastMessage.tool_calls.map((toolCall)=>new constants_js_1.Send("tools", {
                        ...state,
                        lg_tool_call: toolCall
                    }));
            }
            return "tools";
        }, conditionalMap({
            tools: "tools",
            generate_structured_response: responseFormat != null ? "generate_structured_response" : null,
            [constants_js_1.END]: responseFormat != null ? null : constants_js_1.END
        }));
    }
    if (shouldReturnDirect.size > 0) {
        allNodeWorkflows.addConditionalEdges("tools", (state)=>{
            // Check the last consecutive tool calls
            for(let i = state.messages.length - 1; i >= 0; i -= 1){
                const message = state.messages[i];
                if (!(0, messages_1.isToolMessage)(message)) break;
                // Check if this tool is configured to return directly
                if (message.name !== undefined && shouldReturnDirect.has(message.name)) {
                    return constants_js_1.END;
                }
            }
            return entrypoint;
        }, conditionalMap({
            [entrypoint]: entrypoint,
            [constants_js_1.END]: constants_js_1.END
        }));
    } else {
        allNodeWorkflows.addEdge("tools", entrypoint);
    }
    return allNodeWorkflows.compile({
        checkpointer: checkpointer ?? checkpointSaver,
        interruptBefore,
        interruptAfter,
        store,
        name,
        description
    });
} //# sourceMappingURL=react_agent_executor.js.map
}),
"[project]/node_modules/@langchain/langgraph/dist/prebuilt/index.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {
"use strict";

Object.defineProperty(exports, "__esModule", {
    value: true
});
exports.withAgentName = exports.toolsCondition = exports.ToolNode = exports.ToolExecutor = exports.createReactAgentAnnotation = exports.createReactAgent = exports.createFunctionCallingExecutor = exports.createAgentExecutor = void 0;
var agent_executor_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/agent_executor.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "createAgentExecutor", {
    enumerable: true,
    get: function() {
        return agent_executor_js_1.createAgentExecutor;
    }
});
var chat_agent_executor_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/chat_agent_executor.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "createFunctionCallingExecutor", {
    enumerable: true,
    get: function() {
        return chat_agent_executor_js_1.createFunctionCallingExecutor;
    }
});
var react_agent_executor_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/react_agent_executor.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "createReactAgent", {
    enumerable: true,
    get: function() {
        return react_agent_executor_js_1.createReactAgent;
    }
});
Object.defineProperty(exports, "createReactAgentAnnotation", {
    enumerable: true,
    get: function() {
        return react_agent_executor_js_1.createReactAgentAnnotation;
    }
});
var tool_executor_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_executor.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "ToolExecutor", {
    enumerable: true,
    get: function() {
        return tool_executor_js_1.ToolExecutor;
    }
});
var tool_node_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/tool_node.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "ToolNode", {
    enumerable: true,
    get: function() {
        return tool_node_js_1.ToolNode;
    }
});
Object.defineProperty(exports, "toolsCondition", {
    enumerable: true,
    get: function() {
        return tool_node_js_1.toolsCondition;
    }
});
var agentName_js_1 = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/agentName.cjs [app-route] (ecmascript)");
Object.defineProperty(exports, "withAgentName", {
    enumerable: true,
    get: function() {
        return agentName_js_1.withAgentName;
    }
}); //# sourceMappingURL=index.js.map
}),
"[project]/node_modules/@langchain/langgraph/prebuilt.cjs [app-route] (ecmascript)", ((__turbopack_context__, module, exports) => {

module.exports = __turbopack_context__.r("[project]/node_modules/@langchain/langgraph/dist/prebuilt/index.cjs [app-route] (ecmascript)");
}),
];

//# sourceMappingURL=node_modules_%40langchain_langgraph_151fe9fe._.js.map